<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Courses</title><link href="http://lucypark.kr/courses/" rel="alternate"></link><link href="http://lucypark.kr/courses/feeds/2015-dm.atom.xml" rel="self"></link><id>http://lucypark.kr/courses/</id><updated>2015-05-08T09:00:00+02:00</updated><entry><title>Artificial neural networks</title><link href="http://lucypark.kr/courses/2015-dm/artificial-neural-networks.html" rel="alternate"></link><updated>2015-05-08T09:00:00+02:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-05-08:courses/2015-dm/artificial-neural-networks.html</id><summary type="html">&lt;h2&gt;So, is there a one-size-fits-all algorithm?&lt;/h2&gt;
&lt;p&gt;No!
The best algorithm depends on the characteristics of the trainin data.&lt;/p&gt;
&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;Logistic Regression&lt;/td&gt;&lt;td&gt;Decision Tree&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Does it require variables to be normally distributed?&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Does it suffer multicollinearity issue? &lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Does it do as well with categorical variables?&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Does it conduct variable selection without stepwise?&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Does it apply to sparse data?&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;ul&gt;
&lt;li&gt;http://www.quora.com/What-are-the-advantages-of-different-classification-algorithms&lt;/li&gt;
&lt;/ul&gt;</summary></entry><entry><title>Multiple linear regression</title><link href="http://lucypark.kr/courses/2015-dm/multiple-linear-regression.html" rel="alternate"></link><updated>2015-03-13T09:00:00+01:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-13:courses/2015-dm/multiple-linear-regression.html</id><summary type="html">&lt;h4&gt;공지사항&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Assignment 제출방식 변경: 2015-dm@googlegroups.com -&amp;gt; e-class&lt;/li&gt;
&lt;li&gt;Assignment 개수 변경: 4 -&amp;gt; 3&lt;/li&gt;
&lt;li&gt;Project proposal 제출: 다음주 수요일(3/18)까지 e-class로&lt;/li&gt;
&lt;li&gt;Project team 구성: 다음주 수요일(3/18)까지 e-class로&lt;/li&gt;
&lt;li&gt;수업 시간 변경: 09:00 -&amp;gt; 09:30&lt;ul&gt;
&lt;li&gt;저는 9시까지 올 것이니 질문 있으신 분들은 미리 와주세요&lt;/li&gt;
&lt;li&gt;9시 반에 출석 부르고 바로 수업 시작할 것&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Data mining process&lt;/h2&gt;
&lt;p&gt;&lt;img src="images/process.png" width="500px"&gt;&lt;/p&gt;
&lt;h2&gt;학습(learning)이란 무엇을 의미하는가?&lt;/h2&gt;
&lt;p&gt;&lt;img src="images/partition.png" width="500px"&gt;&lt;/p&gt;
&lt;h2&gt;목적에 따른 분류: Descriptive modeling vs Predictive modeling&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Descriptive modeling &lt;ul&gt;
&lt;li&gt;Look back to the past&lt;/li&gt;
&lt;li&gt;To extract compact and easily understood information from large, sometimes gigantic database.&lt;/li&gt;
&lt;li&gt;OLAP (online analytical processing), SQL (structured query language)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Predictive modeling&lt;ul&gt;
&lt;li&gt;Predict the future&lt;/li&gt;
&lt;li&gt;Identify strong links between variables of data.&lt;/li&gt;
&lt;li&gt;To predict the unknown consequence (dependent variable) based on the information provided (independent variable)&lt;/li&gt;
&lt;li&gt;$y = f(x_1, x_2, ..., x_n) + \epsilon$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;학습데이터에 따른 분류: Supervised learning vs Unsupervised learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Supervised learning&lt;ul&gt;
&lt;li&gt;Goal: predict a single "target" or "outcome" variable $y$&lt;/li&gt;
&lt;li&gt;Finds relations between $X$ and $y$&lt;/li&gt;
&lt;li&gt;Train (learn) data where target value is known.&lt;/li&gt;
&lt;li&gt;Score data where target value is not known.&lt;/li&gt;
&lt;li&gt;입출력(input-output)의 쌍으로 구성된 training set으로부터 입력을 출력을 사상하는 함수를 학습하는 과정.&lt;/li&gt;
&lt;li&gt;즉, 입력벡터를 x, 그에 대응하는 출력벡터(i.e., label)를 y라고 할 때, training set은 D={(x,y)}로 주어지게 되며, 모델은 이 training set에 기반하여 관측하지 않은 새로운 데이터 x'가 들어왔을 때 그에 해당되는 label, y'을 추론하는 방법을 배우게 된다.&lt;/li&gt;
&lt;li&gt;교사학습은 주로 분류(classification)와 회귀분석(regression) 문제 해결에 적합하다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Unsupervised learning
    - Explores intrinsic characteristics.&lt;ul&gt;
&lt;li&gt;Estimates underlying distribution.&lt;/li&gt;
&lt;li&gt;Segment data into meaningful groups or detect patterns.&lt;/li&gt;
&lt;li&gt;There is no target (outcome) variable to predict or classify.&lt;/li&gt;
&lt;li&gt;출력값 없이 오직 입력값만 주어지며, 이러한 입력값들의 공통적인 특성을 파악하여 학습하는 과정.&lt;/li&gt;
&lt;li&gt;즉, training set은 D={(x)}로 주어지게 된다.&lt;/li&gt;
&lt;li&gt;비교사학습은 주로 군집화(clustering), 밀도추정(density estimation), 차원축소(dimension reduction) 등에 사용된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;cf. semi-supervised learning&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Data mining techniques&lt;/h2&gt;
&lt;p&gt;&lt;img src="http://image.slidesharecdn.com/20121102seminar-121102055512-phpapp01/95/introduction-to-data-mining-for-newbies-15-1024.jpg?cb=1351855294" width="500px"&gt;&lt;/p&gt;
&lt;h2&gt;Bias-variance decomposition&lt;/h2&gt;
&lt;p&gt;http://scott.fortmann-roe.com/docs/BiasVariance.html&lt;/p&gt;
&lt;h2&gt;Simple linear regression&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;$x$: 독립변수&lt;/li&gt;
&lt;li&gt;$y$: 종속변수&lt;/li&gt;
&lt;li&gt;$a, b$: 파라미터&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$y = ax + b$$&lt;/p&gt;
&lt;h2&gt;Multiple linear regression (MLR)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;$X$: 독립변수들&lt;/li&gt;
&lt;li&gt;$y$: 종속변수&lt;/li&gt;
&lt;li&gt;$A, b$: 파라미터&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$y = AX + b$$&lt;/p&gt;
&lt;h3&gt;MLR in Python&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;데이터 import 하기&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;먼저 파이썬에서 MLR을 시행하기 위해서 &lt;a href="http://scikit-learn.org/"&gt;scikit-learn&lt;/a&gt; 패키지를 사용해보자.&lt;/li&gt;
&lt;li&gt;보통은 데이터를 어디선가 다운로드 받고, 정제한 후 읽어들어야겠지만, scikit-learn 패키지에 이미 몇 가지 데이터셋이 준비되어 있으니 그 중 한 가지인 diabetes(당뇨병) 데이터셋을 써보자.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;파이썬에서 패키지를 사용하기 위해서는 &lt;code&gt;import some_package&lt;/code&gt;을 입력하면 되고, 하나의 큰 패키지에서 일부만을 사용할 때는 &lt;code&gt;from some_package import a_subpackage&lt;/code&gt;를 입력하면 된다.
우리는 먼저 scikit-learn의 일부인 &lt;code&gt;dataset&lt;/code&gt; subpackage 사용할 것이니 &lt;code&gt;from sklearn import datasets&lt;/code&gt;를 하고, 데이터를 로딩해보자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;
&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_diabetes&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;우리가 다른 곳에서 (ex: &lt;a href="http://archive.ics.uci.edu/ml/"&gt;UCI Datasets&lt;/a&gt;) 데이터를 다운로드 받았다면 별도의 전처리 과정을 거쳐야했겠지만 친절하게도 scikit-learn은 데이터를 이미 전처리해서 data (X), target (y)로 나누어 놓았다. 이를 각각 &lt;code&gt;X&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;에 넣어보자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;  &lt;span class="c"&gt;# returns [&amp;#39;target&amp;#39;, &amp;#39;data&amp;#39;]&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;target&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;다른 작업을 진행하기 이전에 X, y 데이터에 대한 탐색을 해보자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;      &lt;span class="c"&gt;# returns (442, 10)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Simple linear regression&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;먼저 하나의 변수를 정해 simple linear regression부터 해보자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="n"&gt;X2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newaxis&lt;/span&gt;&lt;span class="p"&gt;][:,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;변수를 선택하고 나면 X2, y를 각각 training set, validation set으로 나눈다. 현재 데이터의 개수가 442개이므로 validation set을 약 10%인 40개로 해보자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;X2_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X2_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X2&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;X2&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Train&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LinearRegression&lt;/span&gt;
&lt;span class="n"&gt;slr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LinearRegression&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;slr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X2_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# The coefficients&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Coefficients: &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;slr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coef_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# mean square error&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;RSS: &lt;/span&gt;&lt;span class="si"&gt;%.2f&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;slr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X2_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c"&gt;# Explained variance score: 1 is perfect prediction&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Variance score: &lt;/span&gt;&lt;span class="si"&gt;%.2f&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;slr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X2_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Plot&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X2_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X2_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;slr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X2_test&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;blue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;linewidth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xticks&lt;/span&gt;&lt;span class="p"&gt;(())&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;yticks&lt;/span&gt;&lt;span class="p"&gt;(())&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Multiple linear regression&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Data partitioning&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Train&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LinearRegression&lt;/span&gt;
&lt;span class="n"&gt;mlr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LinearRegression&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;mlr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# The coefficients&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Coefficients: &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mlr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coef_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# mean square error&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;RSS: &lt;/span&gt;&lt;span class="si"&gt;%.2f&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;mlr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c"&gt;# Explained variance score: 1 is perfect prediction&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Variance score: &lt;/span&gt;&lt;span class="si"&gt;%.2f&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;mlr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary></entry><entry><title>k-NN</title><link href="http://lucypark.kr/courses/2015-dm/knn.html" rel="alternate"></link><updated>2015-03-09T21:55:00+01:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-09:courses/2015-dm/knn.html</id><summary type="html">&lt;h2&gt;k-NN&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;k-NN?&lt;/li&gt;
&lt;li&gt;k-Nearest Neighbors?&lt;/li&gt;
&lt;li&gt;k개의 가까운 이웃?&lt;/li&gt;
&lt;li&gt;아이디어: 내 주변의 이웃 k개를 봐서 내가 어떤 값을 가질지 투표하자!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="http://www.google.co.kr/url?sa=i&amp;source=images&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=0CAgQjRw&amp;url=http%3A%2F%2Fen.wikipedia.org%2Fwiki%2FK-nearest_neighbors_algorithm&amp;ei=qpj9VLysDpa48gWm_ICwBA&amp;psig=AFQjCNHynUZvcUaYRxIAPILc9ZlKegbEkw&amp;ust=1425992234365421" width="400px"&gt;&lt;/p&gt;
&lt;p&gt;k-NN에서 가장 중요한 문제: 두 점 사이의 거리가 가까운지 먼지 어떻게 판단할 것인가? (distance를 정의하는 문제)&lt;/p&gt;
&lt;p&gt;코드 출처: http://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html#example-neighbors-plot-classification-py&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;데이터 입력하기&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;
&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_iris&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;   &lt;span class="c"&gt;# take the first two features&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;파라미터 설정하기&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;k = 15
weights = &amp;#39;uniform&amp;#39;     # uniform, distance 중 택일
algorihtm = &amp;#39;auto&amp;#39;      # ball_tree, kd_tree, brute 중 택일
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Train&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;neighbors&lt;/span&gt;
&lt;span class="n"&gt;knn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;neighbors&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;KNeighborsClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;algorithm&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;knn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Plot&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.colors&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ListedColormap&lt;/span&gt;
&lt;span class="n"&gt;cmap_light&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ListedColormap&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;#FFAAAA&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;#AAFFAA&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;#AAAAFF&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;cmap_bold&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ListedColormap&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;#FF0000&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;#00FF00&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;#0000FF&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="n"&gt;x_min&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_max&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;min&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;max&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;y_min&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_max&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;min&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;max&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="n"&gt;h&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mo"&gt;02&lt;/span&gt; &lt;span class="c"&gt;# step size in the mesh&lt;/span&gt;

&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;yy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;meshgrid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_min&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_max&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                     &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_min&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_max&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;Z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;knn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;c_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()])&lt;/span&gt;

&lt;span class="c"&gt;# Put the result into a color plot&lt;/span&gt;
&lt;span class="n"&gt;Z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Z&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pcolormesh&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Z&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cmap_light&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# Plot also the training points&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cmap_bold&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;xx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;max&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;max&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ol&gt;</summary></entry><entry><title>Assignments</title><link href="http://lucypark.kr/courses/2015-dm/assignments.html" rel="alternate"></link><updated>2015-03-06T09:00:00+01:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-06:courses/2015-dm/assignments.html</id><summary type="html">&lt;p&gt;For assignment guidelines, visit the class &lt;a href="http://eclass.seoultech.ac.kr"&gt;e-class&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Assignment 0: 자기소개서 쓰기&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;마감일: 2015-03-11 23:59&lt;/li&gt;
&lt;li&gt;제출처: e-class&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A4 용지 1페이지 이내로 자기소개서를 작성해봅시다.
형식은 자유이지만 아래의 내용은 꼭 포함시켜주시기 바랍니다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;이름, 전화번호, 메일주소, 사진&lt;/li&gt;
&lt;li&gt;성격, 취미, 특기, 동아리 활동 등&lt;/li&gt;
&lt;li&gt;프로그래밍 경력 (사용 가능한 언어, 상중하 수준, 언어를 이용해 진행한 일)&lt;/li&gt;
&lt;li&gt;데이터마이닝 수업을 듣게 된 이유, 수업을 통해 얻고 싶은 것&lt;/li&gt;
&lt;li&gt;졸업 후 계획, 가고 싶은 학교 또는 회사 &lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Project proposal&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;마감일: 2015-03-18 23:59&lt;/li&gt;
&lt;li&gt;제출처: e-class&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;팀프로젝트에서 진행할 데이터마이닝 아이디어 한 가지를 제안해주세요.
제안서는 A4 용지 1페이지 이내로 작성하고 PDF로 변환하여 올려주시기 바랍니다.&lt;/p&gt;
&lt;p&gt;프로젝트에 대한 자세한 사항은 다음 링크를 참고해주세요:
http://www.lucypark.kr/courses/2015-dm/course-introduction.html#term-project-40&lt;/p&gt;</summary><category term="assignments"></category></entry><entry><title>Course Introduction</title><link href="http://lucypark.kr/courses/2015-dm/course-introduction.html" rel="alternate"></link><updated>2015-03-06T09:00:00+01:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-06:courses/2015-dm/course-introduction.html</id><summary type="html">&lt;h2&gt;About the instructor&lt;/h2&gt;
&lt;p&gt;&lt;img src="http://lucypark.kr/courses/images/me.jpg" width="150px" class="pull-right"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Eunjeong (Lucy) Park&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dm.snu.ac.kr/~epark"&gt;PhDc for data mining&lt;/a&gt; at Seoul National University&lt;/li&gt;
&lt;li&gt;a.k.a., &lt;a href="http://lucypark.kr"&gt;lucypark&lt;/a&gt;, &lt;a href="http://twitter.com/echojuliett"&gt;echojuliett&lt;/a&gt;, &lt;a href="http://github.com/e9t"&gt;e9t&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Course logistics&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Course objective: &lt;strong&gt;Understanding data mining algorithms&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Course website&lt;ul&gt;
&lt;li&gt;Schedule/Lecture notes: &lt;a href="http://lucypark.kr/courses/2015-dm"&gt;http://lucypark.kr/courses/2015-dm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Everything else: &lt;a href="http://eclass.seoultech.ac.kr/"&gt;e-class&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Office hours&lt;ul&gt;
&lt;li&gt;Right after every class&lt;/li&gt;
&lt;li&gt;You are welcome to ask any kind of questions&lt;/li&gt;
&lt;li&gt;You are also encouraged to &lt;a href="mailto:2015-dm@dm.snu.ac.kr"&gt;book ahead&lt;/a&gt;, or your meeting may have to be deferred to another time&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Grading&lt;ul&gt;
&lt;li&gt;Assignments (30%): Three graded assignments for you to submit online&lt;/li&gt;
&lt;li&gt;Final exam (30%): In-class exam covering the whole semester&lt;/li&gt;
&lt;li&gt;Term project (40%): Group work solving a real world problem&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Assignments (30%)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Three graded take-home assignments for you to submit online&lt;/li&gt;
&lt;li&gt;Instead of taking a mid-term exam, we will have assignments for reviewing purposes&lt;/li&gt;
&lt;li&gt;Assignments consist of a quiz and a programming task&lt;ul&gt;
&lt;li&gt;Frankly, the quiz is not for assessment but for you to review and/or preview class materials&lt;/li&gt;
&lt;li&gt;Programming tasks will cover what you have studied during class. You will have done most of the work in class already. What you're going to do at home is to wrap up your work and document it.&lt;/li&gt;
&lt;li&gt;Will be open early, and can be submitted at any time&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Note the submission date&lt;/em&gt;&lt;ul&gt;
&lt;li&gt;The assignments will still be open even after the due date but you won't get any credit for solving it&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Final exam (30%)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;In-class exam covering the whole semester&lt;/li&gt;
&lt;li&gt;Consists of an easy 80%, a relatively hard 20%&lt;ul&gt;
&lt;li&gt;If you have fully understood the contents of the assignments, the easy 80% wouldn't be a problem&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Term Project (40%)&lt;/h3&gt;
&lt;h4&gt;Proposal (10/40)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Individual work&lt;/li&gt;
&lt;li&gt;Submit 1 data mining project idea within 1 page (Due: 2015-03-18 23:59)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Progress presentation (15/40)&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Fix the team with a team leader at e-class (Due: 2015-03-18 23:59)&lt;/li&gt;
&lt;li&gt;Choose a topic (Due: 2015-03-29 23:59)&lt;ul&gt;
&lt;li&gt;Among your teammates' proposals, select one topic and conduct a project as a group&lt;/li&gt;
&lt;li&gt;You can also choose topics among &lt;a href="http://kaggle.com"&gt;Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Submitting slides (Due: 2015-04-30 23:59)&lt;ul&gt;
&lt;li&gt;Submit presentation slides to the e-class&lt;/li&gt;
&lt;li&gt;No page limits&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Presentation day (2015-05-01)&lt;ul&gt;
&lt;li&gt;You will present your project progress in front of the class (Max. 10 min)&lt;/li&gt;
&lt;li&gt;Peer assessment&lt;ul&gt;
&lt;li&gt;You will also be grading your peers' work on presentation day&lt;/li&gt;
&lt;li&gt;You will be given three votes&lt;/li&gt;
&lt;li&gt;You can give one vote to three teams, or give all votes to one team&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Be brief yet clear&lt;/li&gt;
&lt;li&gt;A good presentation contains the following:&lt;ol&gt;
&lt;li&gt;What questions you had&lt;/li&gt;
&lt;li&gt;What approach you chose to alleviate such questions&lt;/li&gt;
&lt;li&gt;What results you achieved&lt;/li&gt;
&lt;li&gt;What questions you further got and what you plan to do next&lt;/li&gt;
&lt;li&gt;Tricks and tips you want to share with the class&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Record the feedback&lt;ul&gt;
&lt;li&gt;One can make the slides&lt;/li&gt;
&lt;li&gt;Another can prepare for the presentation&lt;/li&gt;
&lt;li&gt;And another can do the presentation&lt;/li&gt;
&lt;li&gt;Yet another can take feedback notes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Final report (15/40)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Present what your group has done throughout the whole project in more than 10 pages (Due: 2015-06-14 23:59)&lt;/li&gt;
&lt;li&gt;You will also be grading your teammates, based on their contributions&lt;/li&gt;
&lt;li&gt;Extra credit will be given to those who submit and/or rank in an open tournament (ex: &lt;a href="http://kaggle.com"&gt;Kaggle&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;More advice on your projects&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;The best topics are the topics you are actually interested in&lt;ul&gt;
&lt;li&gt;You should be able to "&lt;a href="http://en.wikipedia.org/wiki/Eating_your_own_dog_food"&gt;dogfood&lt;/a&gt;" your own analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Don't be afraid to shift the project's direction&lt;ul&gt;
&lt;li&gt;However, shifting too much will give you less time for real work -- balance!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Feel free to use project results in your graduation project or paper&lt;ul&gt;
&lt;li&gt;Grab two rabbits at once!&lt;/li&gt;
&lt;li&gt;These projects have potential to become something in your portfolio&lt;/li&gt;
&lt;li&gt;May be a plus when you get a job, or apply for grad school&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Asking questions&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Never hesitate in asking questions&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Private questions: &lt;a href="mailto:2015-dm@dm.snu.ac.kr"&gt;2015-dm@dm.snu.ac.kr&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Personal questions and/or requests&lt;/li&gt;
&lt;li&gt;Assignment submissions that regard privacy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Public questions: Everything else you want to ask goes to e-class&lt;ul&gt;
&lt;li&gt;Using any language of your choice (ex: English, Korean, Java, ...)&lt;/li&gt;
&lt;li&gt;Asking good questions&lt;ul&gt;
&lt;li&gt;Provide as much details as you can&lt;/li&gt;
&lt;li&gt;However, be "brief" and "clear"&lt;/li&gt;
&lt;li&gt;In case of programming questions, explicitly list versions of software being used (including packages and OSs)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary><category term="lectures"></category><category term="intro"></category></entry><entry><title>데이터마이닝을 소개합니다</title><link href="http://lucypark.kr/courses/2015-dm/data-mining.html" rel="alternate"></link><updated>2015-03-06T09:00:00+01:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-06:courses/2015-dm/data-mining.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;이번 시간이 끝나고 나면:
데이터마이닝에 대해 정의할 수 있게 됩니다. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;한 마디로 "데이터마이닝"은?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;대용량의 데이터에 담긴 의미있는 규칙을 찾는 일&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;그런데 &lt;a href="http://en.wikipedia.org/wiki/Data_mining"&gt;데이터마이닝(data mining)&lt;/a&gt;은...&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;많은 자료 속에 숨어있는 일정한 패턴(규칙)을 발견하는 일이기에 &lt;a href="http://en.wikipedia.org/wiki/Pattern_recognition"&gt;패턴인식(pattern recognition)&lt;/a&gt;의 영역과 맞닿아 있으며&lt;/li&gt;
&lt;li&gt;컴퓨터를 학습(훈련)시키는 &lt;a href="http://en.wikipedia.org/wiki/Machine_learning"&gt;기계학습(machine learning)&lt;/a&gt;과도 유사합니다&lt;/li&gt;
&lt;li&gt;좀더 발전적인 개념으로는 &lt;a href="http://en.wikipedia.org/wiki/Artificial_intelligence"&gt;인공지능(artificial Intelligence)&lt;/a&gt;도 있어요&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="center"&gt;
&lt;script type="text/javascript" src="//www.google.com/trends/embed.js?hl=en-US&amp;q=data+mining,+pattern+recognition,+machine+learning,+artificial+intelligence&amp;date=1/2014+12m&amp;cmpt=q&amp;tz&amp;tz&amp;content=1&amp;cid=TIMESERIES_GRAPH_0&amp;export=5&amp;w=680&amp;h=330"&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;div class="caption"&gt;2014년 기준 데이터마이닝, 패턴인식, 기계학습, 인공지능에 대한 구글 트렌드. 음? 그렇다면 &lt;a href="http://www.google.com/trends/explore#q=data%20mining%2C%20pattern%20recognition%2C%20machine%20learning%2C%20artificial%20intelligence%2C%20big%20data&amp;cmpt=q&amp;tz="&gt;빅데이터(big data)&lt;/a&gt;는? 데이터사이언스(data science)는?&lt;/div&gt;

&lt;p&gt;이 영역들은 각기 다른 탄생 배경을 가지고, 엄밀하게는 철학과 목적이 상당히 다르기도 하지만, 방법론의 측면에서는 상당히 유사해서 각 영역끼리 서로 배우는 점도 많지요.
사실 공부도 같은 책으로 많이 해요.
(심도있는 공부를 원하시는 분들은 아래 책들도 한 번 찾아보세요!)&lt;/p&gt;
&lt;p&gt;&lt;img src="http://ecx.images-amazon.com/images/I/612j5Uo43eL._AA160_.jpg" height="200px"&gt;
&lt;img src="http://ecx.images-amazon.com/images/I/41LeU3HcBdL._AA160_.jpg" height="200px"&gt;
&lt;img src="http://ecx.images-amazon.com/images/I/419Ml9MDMaL._AA160_.jpg" height="200px"&gt;
&lt;img src="http://ecx.images-amazon.com/images/I/51MucLjt9IL._AA160_.jpg" height="200px"&gt;&lt;/p&gt;
&lt;style&gt;
iframe {
    width: 700px;
    height: 330px;
}
&lt;/style&gt;

&lt;h2&gt;데이터가 우리 삶을 돕는 다섯 가지 방법&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://readme.skplanet.com/?p=8870"&gt;미래 교통정보 예측: SK Planet T map&lt;/a&gt;&lt;br&gt;
    &lt;img src="http://i1.daumcdn.net/thumb/R750x0/?fname=http%3A%2F%2Fcfile26.uf.tistory.com%2Fimage%2F2204B946524405E408A53F" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://watcha.net"&gt;영화 추천: Frograms Watcha&lt;/a&gt;&lt;br&gt;
    &lt;img src="images/watcha.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://google.com"&gt;문서 랭킹: Google&lt;/a&gt;&lt;br&gt;
    &lt;img src="images/google.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://labs.naver.com/tech.html#multimedia_recognition"&gt;음악 인식: Naver 앱 음악 및 와인라벨 인식&lt;/a&gt;&lt;br&gt;
    &lt;img src="images/naver.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.apple.com/ios/siri/"&gt;질의응답 (QA): Apple Siri&lt;/a&gt;&lt;br&gt;
    &lt;img src="images/siri0.jpg" width="30%"&gt;
    &lt;img src="images/siri1.jpg" width="30%"&gt;
    &lt;img src="images/siri2.jpg" width="30%"&gt;&lt;/p&gt;
&lt;p&gt;cf. IBM Watson&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;데이터가 우리 삶을 바꿀 가지 방법&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Jarvis and Samantha&lt;br&gt;
    &lt;img src="images/jarvis.png" width="40%"&gt;
    &lt;img src="images/samantha.png" width="40%"&gt;
    &lt;!--
    &lt;iframe width="560" height="315" src="https://www.youtube.com/embed/ZwOxM0-byvc" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;
    --&gt;&lt;/li&gt;
&lt;li&gt;IOT&lt;br&gt;
    &lt;iframe width="560" height="315" src="https://www.youtube.com/embed/NjYTzvAVozo?list=PLl-15sUN2G4eEY2VOqxMEazASNrlMF5FP" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;데이터마이너가 되면 좋은 점&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;세상의 다양한 면을, 다양한 관점에서 살펴볼 수 있습니다&lt;ul&gt;
&lt;li&gt;마케팅부터 시작해서,&lt;/li&gt;
&lt;li&gt;주가의 흐름을 예측하거나(금융),&lt;/li&gt;
&lt;li&gt;DNA 분석이나 MRI 영상을 분석하기도 하며(의료),&lt;/li&gt;
&lt;li&gt;디지털 카메라에서 얼굴 인식(기계)을 하기도 합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;사실상 직업이 매일 바뀌는 것이나 다름없음&lt;/li&gt;
&lt;li&gt;물론 그 외에도 우리가 상상할 수 있는 대부분의 영역에 데이터마이닝이 적용된다는 사실!&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;다음 시간 예고:
데이터마이닝을 할 때 가장 중요한 것은? Asking the right question.&lt;/p&gt;
&lt;/blockquote&gt;</summary><category term="seoultech"></category><category term="lectures"></category></entry><entry><title>Data Mining (Spring 2015)</title><link href="http://lucypark.kr/courses/2015-dm/index.html" rel="alternate"></link><updated>2015-03-02T00:00:00+01:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-02:courses/2015-dm/index.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;Welcome to Data Mining class of 2015!
Here you'll find all course materials, guides and schedules.
For discussions, please visit the class &lt;a href="http://eclass.seoultech.ac.kr/"&gt;e-class&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;데이터마이닝(data mining)이란 대용량 데이터베이스에 존재하는 데이터에서 관계, 패턴, 규칙 등을 찾아내고 모형화해서 의사결정을 돕는 유용한 정보로 변환하는 일련의 과정이다.
본 강좌에서는 기술 모델링(descriptive modeling)과 예측 모델링(predictive modeling)에 사용되는 탐색적 통계, 기계학습, 범주형 자료분석 기법들을 공부하고 응용사례 연구와 패키지를 이용한 프로젝트를 수행한다.&lt;/p&gt;
&lt;h3&gt;Prerequisites&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;한 가지 이상의 프로그래밍 언어에 대한 친숙함 (ex: R, Python, Java, etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;What you will learn&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;데이터마이닝의 기본 개념, 구축 프로세스 학습 및 비즈니스 활용 사례 인식&lt;/li&gt;
&lt;li&gt;데이터마이닝의 주요 방법론의 이론적 토대 학습 및 응용 분야 학습&lt;/li&gt;
&lt;li&gt;데이터마이닝 분야에서 널리 사용되는 오픈소스 데이터 분석 언어인 &lt;a href="https://python.org/"&gt;파이썬&lt;/a&gt; 사용 방법 학습&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Grading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Assignments (30%)&lt;/li&gt;
&lt;li&gt;Final exam (30%)&lt;/li&gt;
&lt;li&gt;Term Project (40%)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Schedule&lt;/h2&gt;
&lt;p&gt;For assignment guidelines, visit the class &lt;a href="http://eclass.seoultech.ac.kr"&gt;e-class&lt;/a&gt;.&lt;/p&gt;
&lt;table id="schedule" class="table table-bordered"&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;th&gt;date&lt;/th&gt;&lt;th&gt;lecture&lt;/th&gt;&lt;/tr&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/06&lt;/td&gt;&lt;td&gt;&lt;a href="course-introduction.html"&gt;Course introduction&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="data-mining.html"&gt;Data mining&lt;/a&gt;&lt;li&gt;Assignment 0 (Due: 3/11) + Project proposal (Due: 3/18)&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;3/11&lt;/td&gt;&lt;td&gt;Due date: Assignment 0&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/13&lt;/td&gt;&lt;td&gt;지도학습 1: Multiple linear regression&lt;ul&gt;&lt;li&gt;&lt;a href="../tips/introduction-to-python.html"&gt;Introduction to Python&lt;/a&gt;&lt;li&gt;How to write a data mining proposal&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;3/18&lt;/td&gt;&lt;td&gt;Due date: Project proposal, Fix project teams&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/20&lt;/td&gt;&lt;td&gt;지도학습 2: Logistic regression&lt;ul&gt;&lt;li&gt;Assignment 1 (Due: 4/2)&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/27&lt;/td&gt;&lt;td&gt;지도학습 3: Decision tree + k-NN&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;4/02&lt;/td&gt;&lt;td&gt;Due date: Assignment 1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/03&lt;/td&gt;&lt;td&gt;텍스트 마이닝 1: Bag of words&lt;ul&gt;&lt;li&gt;Assignment 2 (Due: 4/16)&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/10&lt;/td&gt;&lt;td&gt;텍스트 마이닝 2: TF-IDF&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;4/16&lt;/td&gt;&lt;td&gt;Due date: Assignment 2&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/17&lt;/td&gt;&lt;td&gt;비지도학습 1: k-means + hierarchical clustering&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/24&lt;/td&gt;&lt;td&gt;비지도학습 2: Market basket analysis&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;4/30&lt;/td&gt;&lt;td&gt;Due date: Project presentation slides&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/01&lt;/td&gt;&lt;td&gt;Project presentations&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/08&lt;/td&gt;&lt;td&gt;지도학습 5: Artificial neural networks&lt;ul&gt;&lt;li&gt;Assignment 3 (Due: 6/4)&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/15&lt;/td&gt;&lt;td&gt;지도학습 6: Support vector machines&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/22&lt;/td&gt;&lt;td&gt;데이터 시각화&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/29&lt;/td&gt;&lt;td&gt;변수 선택과 차원 축소&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;6/04&lt;/td&gt;&lt;td&gt;Due date: Assignment 3&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;6/05&lt;/td&gt;&lt;td&gt;대용량 데이터마이닝&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;6/12&lt;/td&gt;&lt;td&gt;Final Exam&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;6/14&lt;/td&gt;&lt;td&gt;Due date: Project final report&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;</summary><category term="data"></category><category term="seoultech"></category><category term="lecturer"></category><category term="syllabus"></category></entry></feed>