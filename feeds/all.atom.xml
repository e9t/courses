<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Courses</title><link href="http://lucypark.kr/courses/" rel="alternate"></link><link href="http://lucypark.kr/courses/feeds/all.atom.xml" rel="self"></link><id>http://lucypark.kr/courses/</id><updated>2015-05-22T15:00:00+09:00</updated><entry><title>Map/reduce</title><link href="http://lucypark.kr/courses/2015-ba/map-reduce.html" rel="alternate"></link><updated>2015-05-22T15:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-05-22:courses/2015-ba/map-reduce.html</id><summary type="html">&lt;p&gt;&lt;img src="images/mapreduce.jpg" width="300px"&gt;
&lt;img alt="source" src="https://twitter.com/tgrall/status/520810627867348992/photo/1" /&gt;&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;https://class.coursera.org/datasci-001/lecture&lt;/p&gt;</summary></entry><entry><title>Support vector machines</title><link href="http://lucypark.kr/courses/2015-dm/svm.html" rel="alternate"></link><updated>2015-05-22T09:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-05-22:courses/2015-dm/svm.html</id><summary type="html">&lt;h2&gt;Class overview&lt;/h2&gt;
&lt;p&gt;You learning to teach the computer to learn from data&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How?&lt;ul&gt;
&lt;li&gt;Find a &lt;em&gt;general rule&lt;/em&gt; (i.e., 일반화 성능 향상, 오버피팅 방지)&lt;/li&gt;
&lt;li&gt;That explains data given only as a sample of limited size&lt;/li&gt;
&lt;li&gt;According to some measurement of accuracy or error&lt;/li&gt;
&lt;li&gt;한마디로, finding &lt;a href="https://www.goodreads.com/book/show/13588394-the-signal-and-the-noise"&gt;signals among the noise&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;지금까지 배운 방법론들&lt;ul&gt;
&lt;li&gt;Supervised learning&lt;ul&gt;
&lt;li&gt;Data are sample of input-output pairs&lt;/li&gt;
&lt;li&gt;Find input-output mapping&lt;/li&gt;
&lt;li&gt;Regression, classification, etc&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Unsupervised learning&lt;ul&gt;
&lt;li&gt;Data are sample of objects&lt;/li&gt;
&lt;li&gt;Find some common structure&lt;/li&gt;
&lt;li&gt;Clustering, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Text mining&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;오늘 배울 것: 여전히 핫한 알고리즘, SVM, and yet another supervised learning algorithm&lt;/li&gt;
&lt;li&gt;앞으로 남은 세 시간:&lt;ul&gt;
&lt;li&gt;&lt;code&gt;classes[-3]&lt;/code&gt;: Semisupervised learning + A touch of visualization&lt;/li&gt;
&lt;li&gt;&lt;code&gt;classes[-2]&lt;/code&gt;: Big data technologies: Hadoop &amp;amp; spark + Tips for your exam&lt;/li&gt;
&lt;li&gt;&lt;code&gt;classes[-1]&lt;/code&gt;: 대망의 기말고사&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;SVM: Support vector machines&lt;/h2&gt;
&lt;script type="text/javascript" src="//www.google.com/trends/embed.js?hl=en-US&amp;q=neural+networks,+svm,+deep+learning&amp;cmpt=q&amp;tz&amp;tz&amp;content=1&amp;cid=TIMESERIES_GRAPH_0&amp;export=5&amp;w=500&amp;h=330"&gt;&lt;/script&gt;

&lt;!-- cf. &lt;s&gt;single valuable man ?&lt;/s&gt; --&gt;

&lt;h3&gt;Classification examples&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Sheep vector machines&lt;ul&gt;
&lt;li&gt;Using the existing sheep distributions (the training set), determine whether the new sheep belongs with the white sheep or the black sheep.&lt;br&gt;
&lt;img src="images/sheep.png" width="300px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Spam filtering&lt;ul&gt;
&lt;li&gt;Using word occurrences in existing email documents, determine whether a new email is spam or ham.&lt;br&gt;
&lt;img src="images/spam.png" width="500px"&gt;&lt;/li&gt;
&lt;li&gt;Instance space: $x \in X$  ($|X| = n$ data points)&lt;ul&gt;
&lt;li&gt;Binary or real-valued feature vector $x$ of word occurrences&lt;/li&gt;
&lt;li&gt;$d$ features (words + other things, d~100,000+)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Class: $y \in Y$&lt;ul&gt;
&lt;li&gt;$y$: Spam (+1), Ham (-1)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;table class="table"&gt;&lt;tr&gt;&lt;th&gt;viagra&lt;/th&gt;&lt;th&gt;learning&lt;/th&gt;&lt;th&gt;the&lt;/th&gt;&lt;th&gt;dating&lt;/th&gt;&lt;th&gt;nigeria&lt;/th&gt;&lt;th&gt;is_spam&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;-1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/p&gt;
&lt;h3&gt;Linear binary classification&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;There may exist many solutions that separate the classes exactly&lt;/li&gt;
&lt;li&gt;Usually, we find the one that will give the smallest generalization error&lt;/li&gt;
&lt;li&gt;This is the problem of choosing the or &lt;strong&gt;decision boundary&lt;/strong&gt;, or &lt;strong&gt;hyperplane&lt;/strong&gt;&lt;br&gt;
    &lt;img src="images/decision_boundary.png" width="400px"&gt;&lt;/li&gt;
&lt;li&gt;Input: Binary/real valued vectors $x$ and labels $y$&lt;/li&gt;
&lt;li&gt;Goal: Find real valued vector $w$&lt;br&gt;
&lt;img src="images/goal.png" width="400px"&gt;&lt;/li&gt;
&lt;li&gt;Each feature has a weight $w_i$&lt;ul&gt;
&lt;li&gt;Prediction is based on the weighted sum: $f(x) = \sum w_i x_i = w \cdot x$&lt;/li&gt;
&lt;li&gt;If the f(x) is&lt;ul&gt;
&lt;li&gt;Positive: Predict +1 (i.e., is sheep, is spam)&lt;/li&gt;
&lt;li&gt;Negative: Predict -1 (i.e., is not sheep, is ham)&lt;br&gt;
&lt;img src="images/predict.png" width="400px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;SVM, the maximal margin classifier&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Idea:&lt;ul&gt;
&lt;li&gt;Distance from the separating hyperplane corresponds to the "confidence" of prediction&lt;/li&gt;
&lt;li&gt;In the image below, we are more sure about the class of A and B than of C&lt;br&gt;
&lt;img src="images/abc.png" width="200px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SVM finds the decision boundary with concept of maximizing this distance, or &lt;strong&gt;margins&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;Margin $\gamma$: The perpendicular distance between the decision boundary and the closest of the data points (left figure below).
&lt;!--
The reason we define margin this way is due to theoretical convenience and existence of
generalization error bounds that depend on the value of margin. - Jurafsky
--&gt;&lt;/li&gt;
&lt;li&gt;Support vectors: Maximizing the margin leads to a particular subset of existing data points (right figure below).&lt;br&gt;
&lt;img src="images/svm.png" width="600px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Why is maximizing $\gamma$ a good idea?&lt;ul&gt;
&lt;li&gt;Remember: Dot product $A \cdot B = |A||B|cos\theta$&lt;br&gt;
&lt;img src="images/cosine.png" width="200px"&gt;&lt;/li&gt;
&lt;li&gt;Let:&lt;ul&gt;
&lt;li&gt;Line $L = w \cdot x + b = 0$&lt;/li&gt;
&lt;li&gt;Weight $w = [w_1, w_2]$&lt;/li&gt;
&lt;li&gt;Point $A = [x_1^{(A)}, x_2^{(A)}]$&lt;/li&gt;
&lt;li&gt;Point $M = [x_1^{{(M)}}, x_2^{{(M)}}]$&lt;br&gt;
&lt;img src="images/margin.png" width="200px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Then the distance between A, L:
    $$\begin{align}
    d(A, L) &amp;amp; = |AH|\\
        &amp;amp; = |(A-M) \cdot w|\\
        &amp;amp; = |(x_1^{(A)} - x_1^{(M)}) w_1 + (x_2^{(A)} - x_2^{(M)}) w_2|\\
        &amp;amp; = x_1^{(A)} w_1 + x_2^{(A)} w_2 + b\\
        &amp;amp; = w \cdot A + b
    \end{align}$$&lt;/li&gt;
&lt;li&gt;Prediction = $sign(w \cdot x + b)$&lt;/li&gt;
&lt;li&gt;"Confidence" = $(w \cdot x + b)y$&lt;/li&gt;
&lt;li&gt;For i-th data point: $\gamma_i = (w \cdot x^{(i)} + b)y^{(i)}$&lt;/li&gt;
&lt;li&gt;Therefore, the objective function becomes:&lt;br&gt;&lt;ul&gt;
&lt;li&gt;max $\gamma$ s.t., $y^{(i)}(w \cdot x^{(i)} + b) \geq \gamma$ ($\forall i$)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Good according to 1) intuition 2) theory and 3) practice&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Normalized weights&lt;ul&gt;
&lt;li&gt;Problem: With this equation, scaling $w$ increases margin! (i.e., $w$ can be arbitrarily large)&lt;ul&gt;
&lt;li&gt;If $(w \cdot x + b)y = \gamma$, then $(2w \cdot x + 2b)y = 2\gamma$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Solution: work with normalized $w$, and require support vectors to be on the margin&lt;ul&gt;
&lt;li&gt;$\gamma = (\frac{w}{|w|} \cdot x + b)y$&lt;/li&gt;
&lt;li&gt;$w \cdot x^{(i)} + b = \pm 1$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Margin maximization == weight minimization?&lt;br&gt;
    &lt;img src="images/maxmin.png" width="300px"&gt;&lt;ul&gt;
&lt;li&gt;We know three things&lt;ul&gt;
&lt;li&gt;$x^{(1)} = x^{(2)} + 2 \gamma \frac{w}{|w|}$&lt;/li&gt;
&lt;li&gt;$w \cdot x^{(1)} + b = +1$&lt;/li&gt;
&lt;li&gt;$w \cdot x^{(2)} + b = -1$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Therefore&lt;ul&gt;
&lt;li&gt;$w \cdot x^{(1)} + b = +1$&lt;/li&gt;
&lt;li&gt;$w (x^{(2)} + 2 \gamma \frac{w}{|w|}) + b = +1$&lt;/li&gt;
&lt;li&gt;$(w \cdot x^{(2)} + b) + 2 \gamma \frac{w}{|w|} = +1$&lt;/li&gt;
&lt;li&gt;$\gamma = \frac{1}{|w|}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;max $\gamma \thickapprox$ max $\frac{1}{|w|} \thickapprox$ min $|w| \thickapprox$ min $\frac{1}{2} |w|^2$&lt;/li&gt;
&lt;li&gt;Which finally gives&lt;ul&gt;
&lt;li&gt;min $\frac{1}{2} |w|^2$ s.t., $y^{(i)}(w \cdot x^{(i)} + b) \geq 1$ ($\forall i$)&lt;/li&gt;
&lt;li&gt;This is called SVM with "hard" constraints&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Soft margin SVMs&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Relax constraints&lt;ul&gt;
&lt;li&gt;Allowing the margin constraints to be violated&lt;/li&gt;
&lt;li&gt;In other words, allow some of the training data points to be misclassified&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;min $\frac{1}{2} |w|^2 + C \sum_{i=1}^n \xi_i$ s.t., $y^{(i)}(w \cdot x^{(i)} + b) \geq 1 - \xi_i$ ($\forall i$)&lt;br&gt;
    &lt;img src="images/xi.png" width="300px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a href="http://en.wikipedia.org/wiki/Kernel_method"&gt;Kernel methods&lt;/a&gt;&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Warning: NOT related to shell/kernels in the OS&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Life is not so easy, not all problems are linearly separable&lt;/li&gt;
&lt;li&gt;If so, choose a mapping to some (high dimensional) dot-product space, namely the &lt;em&gt;feature space&lt;/em&gt;: $\Phi: X \to H$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/feature_space.png" width="400px"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mercer's condition&lt;ul&gt;
&lt;li&gt;If a symmetric function $K(x, y)$ satisfies $\sum_{i,j=1}^{M} a_ia_jK(x_i,x_j) \geq 0$&lt;br&gt;
  for all $M \in \mathbb{N}, x_i, a_i \in \mathbb{R}$&lt;br&gt;
  there exists a mapping function $\Phi$ that maps x into the dot-product feature space and $K(x, y) = &amp;lt;\Phi(x), \Phi(y)&amp;gt;$ and vice versa.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Function $K$ is called the &lt;strong&gt;kernel&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Types of kernels&lt;ul&gt;
&lt;li&gt;Linear kernels: $K(x, y) = &amp;lt;x, y&amp;gt;$&lt;/li&gt;
&lt;li&gt;Polynomial kernels: $K(x, y) = (&amp;lt; x, y&amp;gt; + 1)^d$ for $d = 2$&lt;/li&gt;
&lt;li&gt;RBF kernels: $K(x, y) = exp(-\frac{||x-y||^2}{d^2})$&lt;/li&gt;
&lt;li&gt;...and more!&lt;ul&gt;
&lt;li&gt;Kernels on various objects, such as graphs, strings, texts, etc.&lt;/li&gt;
&lt;li&gt;Enable us to use dot-product algorithms&lt;/li&gt;
&lt;li&gt;Measure of similarity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Programming SVMs&lt;/h2&gt;
&lt;p&gt;Go to the &lt;a href="http://scikit-learn.org/stable/modules/svm.html"&gt;SVM documents&lt;/a&gt; in the Scikit-learn webpage.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SVC: Support vector &lt;em&gt;classification&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;SVR: Support vector &lt;em&gt;regression&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Also see: &lt;a href="http://www.quora.com/What-is-the-difference-between-C-SVM-and-nu-SVM"&gt;What is the difference between C-SVM and nu-SVM?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Wikipedia, &lt;a href="http://en.wikipedia.org/wiki/Support_vector_machine"&gt;Support Vector Machine&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Scikit-learn, &lt;a href="http://scikit-learn.org/stable/modules/svm.html"&gt;Support Vector Machines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Andrew Ng, &lt;a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf"&gt;CS229 Lecture notes: Support vector machines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Petra Kudova, &lt;a href="http://www.cs.cas.cz/petra/slides/svm.pdf"&gt;Learning with kernels and SVM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.support-vector-machines.org/"&gt;support-vector-machines.org&lt;/a&gt; (Sometimes, algorithms have websites of their own! See &lt;a href="https://twitter.com/echojuliett/status/488991816595697664"&gt;here&lt;/a&gt; for more of them.)&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Many contents in courtesy of &lt;a href="http://cs.stanford.edu/people/jure/"&gt;Jure Leskovec&lt;/a&gt; and &lt;a href="http://www.cs.cas.cz/petra/"&gt;Petra Kudova&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</summary><category term="lectures"></category><category term="svm"></category></entry><entry><title>Visualization</title><link href="http://lucypark.kr/courses/2015-ba/visualization2.html" rel="alternate"></link><updated>2015-05-08T00:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-05-08:courses/2015-ba/visualization2.html</id><summary type="html">&lt;p&gt;&lt;img src="images/scientist.png" width="500px"&gt; (&lt;a href="http://www.marketingdistillery.com/2014/08/30/data-science-skill-set-explained/"&gt;source&lt;/a&gt;)&lt;/p&gt;
&lt;h2&gt;[Review] Data visualization&lt;/h2&gt;
&lt;h3&gt;Data types&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Nominal, ordinal, quantitative&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Visual variables&lt;/h3&gt;
&lt;p&gt;&lt;img src="images/cues.png" width="400px"&gt;
&lt;img src="images/together.png" width="100%"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Comparisons
&lt;img src="images/comparison-1.png" width="100%"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(Source: Nathan Yau, &lt;a href="http://flowingdata.com/data-points/DataPoints-Ch3.pdf"&gt;Data points&lt;/a&gt;)&lt;/p&gt;
&lt;h3&gt;Data visualization patterns&lt;/h3&gt;
&lt;p&gt;&lt;img src="images/patterns-1.png" width="500px"&gt;
&lt;img src="images/patterns-2.png" width="500px"&gt;
&lt;img src="images/patterns-3.png" width="500px"&gt;&lt;/p&gt;
&lt;p&gt;(Source: Joel Laumans, &lt;a href="http://piksels.com/wp-content/uploads/2009/01/visualizingdata.pdf"&gt;An introduction to visualizing data&lt;/a&gt;)&lt;/p&gt;
&lt;h2&gt;Map visualizations (Geomapping)&lt;/h2&gt;
&lt;h3&gt;Projections&lt;/h3&gt;
&lt;p&gt;&lt;img src="images/projections-0.png" width="300px"&gt;&lt;br&gt;
&lt;img src="images/projections-1.png" width="400px"&gt;&lt;br&gt;
&lt;img src="images/projections-2.png" width="400px"&gt;&lt;br&gt;
(Source: &lt;a href="http://www.jasondavies.com/maps/"&gt;Jason Davies&lt;/a&gt;)&lt;/p&gt;
&lt;h3&gt;Visual variables for spatial data&lt;/h3&gt;
&lt;p&gt;&lt;img src="images/spatial-variables.png" width="100%"&gt;&lt;/p&gt;
&lt;h3&gt;Examples&lt;/h3&gt;
&lt;h4&gt;Dot map: A dot for every data point&lt;/h4&gt;
&lt;p&gt;&lt;img src="images/dot-map.png" width="400px"&gt;
&lt;img src="images/sushi.png" width="400px"&gt;(&lt;a href="http://bl.ocks.org/e9t/ba9edd99793a5c91eaab"&gt;source&lt;/a&gt;)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How to lie with a dot map&lt;br&gt;
&lt;img src="http://imgs.xkcd.com/comics/heatmap.png" width="400px"&gt;&lt;br&gt;
(Source: &lt;a href="http://xkcd.com/1138/"&gt;xkcd&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;Choropleth map: Attribute uniformly distributed in region&lt;/h4&gt;
&lt;p&gt;&lt;img src="images/choropleth.png" width="400px"&gt;(&lt;a href="http://bl.ocks.org/mbostock/4060606"&gt;source&lt;/a&gt;)
&lt;img src="images/population.png" width="400px"&gt;(&lt;a href="http://bl.ocks.org/e9t/55699e9fa8c3eb7fe40c"&gt;source&lt;/a&gt;)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How to lie with a choropleth&lt;br&gt;
&lt;img src="images/example-1.png" width="300px"&gt;&lt;br&gt;
(Source: &lt;a href="http://elections.huffingtonpost.com/2012/results"&gt;Huffington Post&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;Cartograms: Size of region scaled to attribute value&lt;/h4&gt;
&lt;p&gt;&lt;img src="images/cartogram.png" width="400px"&gt;&lt;/p&gt;
&lt;p&gt;(Source: Shawn Allen, &lt;a href="http://prag.ma/code/d3-cartogram/#intlmig/2011"&gt;Cartograms with d3 &amp;amp; TopoJSON&lt;/a&gt;)&lt;/p&gt;
&lt;!--
#### Others
&lt;img src="images/example-4.png" width="400px"&gt; ([source](http://www.biz-gis.com/index.php?mid=GIS_Essay&amp;document_srl=60689&amp;sort_index=readed_count&amp;order_type=asc))&lt;br&gt;
&lt;img src="images/example-3.png" width="300px"&gt; ([source](http://powertothepeople.kr/comm/bbs/board.php?bo_table=news&amp;wr_id=374&amp;page=5))&lt;br&gt;
--&gt;

&lt;p&gt;(Source: Maneesh Agrawala, &lt;a href="http://vis.berkeley.edu/courses/cs294-10-fa14/wiki/images/3/3f/Lec294-10-20141006.pdf"&gt;D3 Introduction&lt;/a&gt;, Mike Bostock, &lt;a href="http://bost.ocks.org/mike/d3/workshop/"&gt;D3 workshop&lt;/a&gt;)&lt;/p&gt;
&lt;h2&gt;Visualization tools&lt;/h2&gt;
&lt;h3&gt;D3&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Go to &lt;a href="http://d3js.org/"&gt;d3js.org&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;MapBox&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Go to &lt;a href="https://www.mapbox.com"&gt;MapBox&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/mapbox.png" width="500px"&gt;&lt;/p&gt;</summary><category term="lectures"></category></entry><entry><title>Visualization</title><link href="http://lucypark.kr/courses/2015-ba/visualization.html" rel="alternate"></link><updated>2015-05-01T00:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-05-01:courses/2015-ba/visualization.html</id><summary type="html">&lt;h2&gt;What is data visualization?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The visual representation of information&lt;/li&gt;
&lt;li&gt;Goals of data visualization&lt;ul&gt;
&lt;li&gt;Effective, clear communication of information&lt;/li&gt;
&lt;li&gt;Stimulate viewer engagement&lt;/li&gt;
&lt;li&gt;Exploratory data analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Advantages of visualization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;With many numbers and large datasets, need an efficient way to understand a vast amount of data&lt;/li&gt;
&lt;li&gt;The human visual system is the highest-bandwidth channel to the human brain&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: Given the income, college degree percentage of each state, try answering the following questions with either a table and a graphic representation. Which method is better in answering the questions?&lt;br&gt;
- Which state has highest income?&lt;br&gt;
- Relationship between income and education?&lt;br&gt;
- Outliers?&lt;br&gt;
&lt;img src="images/table.png" width="250px"&gt;
&lt;img src="images/graph.png" width="400px"&gt;&lt;br&gt;
(Example by &lt;a href="http://en.wikipedia.org/wiki/Marti_Hearst"&gt;Marti Hearst&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Graphs reveal data that statistics may not&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: &lt;a href="http://en.wikipedia.org/wiki/Anscombe's_quartet"&gt;Anscombe's quartet&lt;/a&gt;&lt;br&gt;
&lt;div class="row"&gt;
&lt;div class="col-md-6"&gt;
&lt;table class="table"&gt;&lt;tr&gt;&lt;th&gt;I&lt;/th&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;II&lt;/th&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;III&lt;/th&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;IV&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;x&lt;/td&gt;&lt;td&gt;y&lt;/td&gt;&lt;td&gt;x&lt;/td&gt;&lt;td&gt;y&lt;/td&gt;&lt;td&gt;x&lt;/td&gt;&lt;td&gt;y&lt;/td&gt;&lt;td&gt;x&lt;/td&gt;&lt;td&gt;y&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;10.0&lt;/td&gt;&lt;td&gt;8.04&lt;/td&gt;&lt;td&gt;10.0&lt;/td&gt;&lt;td&gt;9.14&lt;/td&gt;&lt;td&gt;10.0&lt;/td&gt;&lt;td&gt;7.46&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;6.58&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;6.95&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;8.14&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;6.77&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;5.76&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;13.0&lt;/td&gt;&lt;td&gt;7.58&lt;/td&gt;&lt;td&gt;13.0&lt;/td&gt;&lt;td&gt;8.74&lt;/td&gt;&lt;td&gt;13.0&lt;/td&gt;&lt;td&gt;12.74&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;7.71&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;9.0&lt;/td&gt;&lt;td&gt;8.81&lt;/td&gt;&lt;td&gt;9.0&lt;/td&gt;&lt;td&gt;8.77&lt;/td&gt;&lt;td&gt;9.0&lt;/td&gt;&lt;td&gt;7.11&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;8.84&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;11.0&lt;/td&gt;&lt;td&gt;8.33&lt;/td&gt;&lt;td&gt;11.0&lt;/td&gt;&lt;td&gt;9.26&lt;/td&gt;&lt;td&gt;11.0&lt;/td&gt;&lt;td&gt;7.81&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;8.47&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;14.0&lt;/td&gt;&lt;td&gt;9.96&lt;/td&gt;&lt;td&gt;14.0&lt;/td&gt;&lt;td&gt;8.10&lt;/td&gt;&lt;td&gt;14.0&lt;/td&gt;&lt;td&gt;8.84&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;7.04&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;6.0&lt;/td&gt;&lt;td&gt;7.24&lt;/td&gt;&lt;td&gt;6.0&lt;/td&gt;&lt;td&gt;6.13&lt;/td&gt;&lt;td&gt;6.0&lt;/td&gt;&lt;td&gt;6.08&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;5.25&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;4.0&lt;/td&gt;&lt;td&gt;4.26&lt;/td&gt;&lt;td&gt;4.0&lt;/td&gt;&lt;td&gt;3.10&lt;/td&gt;&lt;td&gt;4.0&lt;/td&gt;&lt;td&gt;5.39&lt;/td&gt;&lt;td&gt;19.0&lt;/td&gt;&lt;td&gt;12.50&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;12.0&lt;/td&gt;&lt;td&gt;10.84&lt;/td&gt;&lt;td&gt;12.0&lt;/td&gt;&lt;td&gt;9.13&lt;/td&gt;&lt;td&gt;12.0&lt;/td&gt;&lt;td&gt;8.15&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;5.56&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;7.0&lt;/td&gt;&lt;td&gt;4.82&lt;/td&gt;&lt;td&gt;7.0&lt;/td&gt;&lt;td&gt;7.26&lt;/td&gt;&lt;td&gt;7.0&lt;/td&gt;&lt;td&gt;6.42&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;7.91&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5.0&lt;/td&gt;&lt;td&gt;5.68&lt;/td&gt;&lt;td&gt;5.0&lt;/td&gt;&lt;td&gt;4.74&lt;/td&gt;&lt;td&gt;5.0&lt;/td&gt;&lt;td&gt;5.73&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;6.89&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class="col-md-6"&gt;
Simple summary statistics are all identical for four datasets
&lt;img src="images/stats.png"&gt;
However, the four datasets vary considerably when graphed
&lt;img src="images/anscombe.png"&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Data visualization process&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Classify datatypes&lt;ul&gt;
&lt;li&gt;Nominal (ex: fruits - apples, oranges, ...)&lt;ul&gt;
&lt;li&gt;Operations: ==, !=&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Ordinal (ex: quality of meat - grade A, AA, AAA, ...)&lt;ul&gt;
&lt;li&gt;Operations: ==, !=, &amp;lt;=, &amp;gt;=&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Quantitative&lt;ul&gt;
&lt;li&gt;Interval (ex: dates - May 1st, 2015, location - LAT 38.9 LON 127)&lt;ul&gt;
&lt;li&gt;Only differences may compared&lt;/li&gt;
&lt;li&gt;Operations: ==, !=, &amp;lt;=, &amp;gt;=, -&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Ratio (ex: length - 160cm)&lt;ul&gt;
&lt;li&gt;Origin is meaningful&lt;/li&gt;
&lt;li&gt;Operations: ==, !=, &amp;lt;=, &amp;gt;=, -, /&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Map datasets to visual attributes that represent data types most effectively (also known as &lt;em&gt;data encoding&lt;/em&gt;)&lt;ul&gt;
&lt;li&gt;Bertin's visual variables (Bertin, &lt;em&gt;Semiology of Graphics&lt;/em&gt;, 1967|1983)
    &lt;div class="row"&gt;
    &lt;div class="col-md-8"&gt;&lt;ul&gt;
&lt;li&gt;Position&lt;/li&gt;
&lt;li&gt;Size&lt;/li&gt;
&lt;li&gt;Value&lt;/li&gt;
&lt;li&gt;Texture&lt;/li&gt;
&lt;li&gt;Color&lt;/li&gt;
&lt;li&gt;Orientation&lt;/li&gt;
&lt;li&gt;Shape
&lt;/div&gt;
&lt;div class="col-md-4"&gt;
&lt;img src="images/bertin.png"&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Data encoding&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Objective&lt;ul&gt;
&lt;li&gt;Assume 7 visual encodings and n data attributes&lt;/li&gt;
&lt;li&gt;Pick the best encoding from the exponential number of possibilities&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Principle of Consistency&lt;ul&gt;
&lt;li&gt;The properties of the image (visual variables) should match the properties of the data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Principle of Importance Ordering&lt;ul&gt;
&lt;li&gt;Encode the most important information in the most effective way&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mackinlay’s expressiveness criteria&lt;ul&gt;
&lt;li&gt;A set of facts is expressible in a visual language if the sentences (i.e. the visualizations) in the language express all the facts in the set of data, and only the facts in the data. &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mackinlay’s effectiveness criteria&lt;ul&gt;
&lt;li&gt;A visualization is more effective than another visualization if the information conveyed by one visualization is more readily perceived than the information in the other visualization.&lt;br&gt;
&lt;img src="http://www.softviscollection.org/intro/a-thousand-words/images/ali-mackinlay.png" width="500px"&gt;
&lt;img src="images/viz-accuracy.png" width="400px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Bertin's visual variables and their syntactics. Figure derived from Bertin (1967|1983), MacEachren (1995), and MacEachren et al. (2012)&lt;br&gt;
&lt;img src="images/va.png" width="500px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Data combinations and dimensions&lt;/h2&gt;
&lt;h3&gt;Univariate data (1D)&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Line plot&lt;br&gt;&lt;img src="http://matplotlib.org/_images/spectrum_demo.png"&gt;&lt;/li&gt;
&lt;li&gt;Bar plot&lt;br&gt;&lt;img src="http://matplotlib.org/_images/xcorr_demo.png"&gt;&lt;/li&gt;
&lt;li&gt;Box-and-whisker plot&lt;br&gt;&lt;img src="images/baw.gif" alt="http://www.statgraphics.com/eda.htm"&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Bivariate data (2D)&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;2D scatter plot&lt;br&gt;&lt;img src="http://upload.wikimedia.org/wikipedia/commons/0/0f/Oldfaithful3.png"&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Trivariate data (3D)&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Use 3D scatter plot&lt;br&gt;&lt;img src="http://scikit-learn.org/stable/_images/plot_pca_iris_001.png"&gt;&lt;/li&gt;
&lt;li&gt;Map two variables [x, y] in 2D space + Map third variable [z] with another visual attribute (ex: color, shape, size)&lt;br&gt;&lt;img src="images/trivariate.png" width="200px"&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Multivariate data (&amp;gt;3D)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;How many variables can be depicted in a image?&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;"With up to three rows, a data table can be constructed directly as a single image. However, an image has only three dimensions. And this barrier is impassible." -- Bertin&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Examples&lt;/h2&gt;
&lt;h3&gt;&lt;a href="http://en.wikipedia.org/wiki/Iris_flower_data_set"&gt;Iris dataset&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img src="images/irisdata.png" width="400px"&gt;
&lt;img src="http://www.nature.com/nmeth/journal/v9/n10/images/nmeth.2186-F1.jpg" width="400px"&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a href="http://data.heapanalytics.com/how-to-lie-with-data-visualization/"&gt;How to lie with visualization&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Truncated Y-Axis&lt;br&gt;&lt;img src="images/lie1.png" width="400px"&gt;&lt;/li&gt;
&lt;li&gt;Cumulative graphs&lt;br&gt;&lt;img src="images/lie2-1.png" width="300px"&gt;&lt;img src="images/lie2-2.png" width="300px"&gt;&lt;/li&gt;
&lt;li&gt;Ignoring conventions&lt;br&gt;&lt;img src="https://s3.amazonaws.com/heapdatablog/misleading3_pie.png" width="400px"&gt;&lt;img src="https://s3.amazonaws.com/heapdatablog/misleading3_deaths.jpg" width="400px"&gt;&lt;/li&gt;
&lt;li&gt;For more, see &lt;a href="http://viz.wtf/"&gt;WTF visualizations&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Awesome visualization examples&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Words&lt;br&gt;&lt;img src="http://i2.wp.com/flowingdata.com/wp-content/uploads/2008/12/wordle.png?zoom=2&amp;resize=545%2C333" width="400px"&gt;&lt;/li&gt;
&lt;li&gt;Web pages&lt;ul&gt;
&lt;li&gt;&lt;a href="http://internet-map.net/"&gt;http://internet-map.net/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;World refugees&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.therefugeeproject.org/"&gt;http://www.therefugeeproject.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Movie revenues&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.nytimes.com/interactive/2008/02/23/movies/20080223_REVENUE_GRAPHIC.html"&gt;http://www.nytimes.com/interactive/2008/02/23/movies/20080223_REVENUE_GRAPHIC.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Others&lt;ul&gt;
&lt;li&gt;&lt;a href="http://infosthetics.com/"&gt;http://infosthetics.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.visualcomplexity.com/"&gt;http://www.visualcomplexity.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://datavisualization.ch/showcases/"&gt;http://datavisualization.ch/showcases/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;In-class Practice: Worldwide Disasters (1900-2008)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Visualize with the data below&lt;br&gt;&lt;img src="images/assign.png"&gt;&lt;/li&gt;
&lt;li&gt;Evaluation&lt;ul&gt;
&lt;li&gt;Expressiveness&lt;ul&gt;
&lt;li&gt;Do the mappings show the facts and only the facts?&lt;/li&gt;
&lt;li&gt;Are visual mappings consistent? (e.g., respect color mappings)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Effectiveness&lt;ul&gt;
&lt;li&gt;Are perceptually effective encodings used?&lt;/li&gt;
&lt;li&gt;Are the most important data mapped to the most effective visual variables?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cognitive Load (Efficiency)&lt;ul&gt;
&lt;li&gt;Are there extraneous (unmapped) visual elements?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data Transformation&lt;ul&gt;
&lt;li&gt;Are transformations (filter, sort, derive, aggregate) appropriate?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Guides (Non-Data Elements)&lt;ul&gt;
&lt;li&gt;Descriptive, consistent: Title, Label, Caption, Source, Annotations&lt;/li&gt;
&lt;li&gt;Meaningful references: Gridlines, Legend &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;http://selection.datavisualization.ch/&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.computerworld.com/article/2506820/business-intelligence-chart-and-image-gallery-30-free-tools-for-data-visualization-and-analysis.html"&gt;Chart and image gallery: 30+ free tools for data visualization and analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.nytimes.com/interactive/2012/12/30/multimedia/2012-the-year-in-graphics.html"&gt;NYT the year in graphics: 2012&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.nytimes.com/interactive/2014/12/29/us/year-in-interactive-storytelling.html"&gt;NYT the year in graphics: 2014&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Many contents in courtesy of &lt;a href="https://faculty.washington.edu/aragon/"&gt;Cecilia Aragon&lt;/a&gt; and &lt;a href="http://vis.berkeley.edu/~maneesh/"&gt;Maneesh Agrawala&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="lectures"></category></entry><entry><title>파이썬으로 영어와 한국어 텍스트 다루기</title><link href="http://lucypark.kr/courses/2015-dm/text-mining.html" rel="alternate"></link><updated>2015-04-10T09:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-04-10:courses/2015-dm/text-mining.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;We use Python 3 in this tutorial, but provide minimal guidelines for Python 2.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;지난 시간 복습&lt;/h2&gt;
&lt;h3&gt;Terminologies&lt;/h3&gt;
&lt;p&gt;&lt;table class="table"&gt;&lt;tr&gt;&lt;th&gt;English&lt;/th&gt;&lt;th&gt;한국어&lt;/th&gt;&lt;th&gt;Description&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Document&lt;/td&gt;&lt;td&gt;문서&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Corpus&lt;/td&gt;&lt;td&gt;말뭉치&lt;/td&gt;&lt;td&gt;A set of documents&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Token&lt;/td&gt;&lt;td&gt;토큰&lt;/td&gt;&lt;td&gt;Meaningful elements in a text such as words or phrases or symbols&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Morphemes&lt;/td&gt;&lt;td&gt;형태소&lt;/td&gt;&lt;td&gt;Smallest meaningful unit in a language&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;POS&lt;/td&gt;&lt;td&gt;품사&lt;/td&gt;&lt;td&gt;Part-of-speech (ex: Nouns)&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/p&gt;
&lt;h3&gt;Text analysis process&lt;/h3&gt;
&lt;p&gt;&lt;img src="images/text-process.png" width="200px"&gt;&lt;/p&gt;
&lt;p&gt;전처리는 아래의 세부 과정으로 다시 한 번 나뉜다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Load text&lt;/li&gt;
&lt;li&gt;Tokenize text (ex: stemming, morph analyzing)&lt;/li&gt;
&lt;li&gt;Tag tokens (ex: POS, NER)&lt;/li&gt;
&lt;li&gt;Token(Feature) selection and/or filter/rank tokens (ex: stopword removal, TF-IDF)&lt;/li&gt;
&lt;li&gt;...and so on (ex: calculate word/document similarities, cluster documents)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Useful Python Packages for Text Mining and NLP&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nltk.org"&gt;NLTK&lt;/a&gt;: Provides modules for text analysis (mostly language independent)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;설치하기&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pip install nltk
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;주요기능&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.nltk.org/book/ch02.html"&gt;Text corpora&lt;/a&gt;: 특히, 이 튜토리얼에서는 아래의 두 가지 데이터가 필요하니 미리 다운 받아두자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gutenberg&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;maxent_treebank_pos_tagger&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.nltk.org/api/nltk.tag.html"&gt;Word POS, NER classification&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.nltk.org/book/ch06.html"&gt;Document classification&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://konlpy.org"&gt;KoNLPy&lt;/a&gt;: Provides modules for Korean text analysis&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;설치하기&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pip install konlpy
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;주요기능&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://konlpy.org/en/latest/data/#corpora"&gt;Text corpora&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://konlpy.org/en/latest/api/konlpy.tag/"&gt;Word POS classification&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Hannanum&lt;/li&gt;
&lt;li&gt;Kkma&lt;/li&gt;
&lt;li&gt;Mecab&lt;/li&gt;
&lt;li&gt;Komoran&lt;/li&gt;
&lt;li&gt;Twitter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http//radimrehurek.com/gensim/"&gt;Gensim&lt;/a&gt;: Provides modules for topic modeling and calculating similarities among documents&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;설치하기&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pip install -U gensim
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;주요기능&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Topic modeling&lt;ul&gt;
&lt;li&gt;&lt;a href="http://radimrehurek.com/gensim/models/ldamodel.html"&gt;Latent Dirichlet allocation (LDA)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://radimrehurek.com/gensim/models/lsimodel.html"&gt;Latent semantic indexing (LSI)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://radimrehurek.com/gensim/models/hdpmodel.html"&gt;Hierarchical Dirichlet process (HDP)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Word embedding&lt;ul&gt;
&lt;li&gt;&lt;a href="radimrehurek.com/gensim/models/word2vec.html"&gt;word2vec&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/ryanmcgrath/twython"&gt;Twython&lt;/a&gt;: Provides easy access to Twitter API&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;설치하기&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pip install twython
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;사용예시: "Samsung (삼성)" 관련 트윗 받기&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;twython&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twython&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;settings&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;s&lt;/span&gt;    &lt;span class="c"&gt;# Create a file named settings.py, and put oauth KEY values inside&lt;/span&gt;
&lt;span class="n"&gt;twitter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twython&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;APP_KEY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;APP_SECRET&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OAUTH_TOKEN&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OAUTH_TOKEN_SECRET&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tweets&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;twitter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;삼성&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;user&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;screen_name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;created_at&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;statuses&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Text exploration&lt;/h2&gt;
&lt;h3&gt;1. Read document&lt;/h3&gt;
&lt;p&gt;이 튜토리얼에서는 NLTK, KoNLPy에서 제공하는 문서들을 사용한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;영어: &lt;a href="http://www.gutenberg.org/ebooks/158"&gt;Jane Austen의 소설 Emma&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;한국어: &lt;a href="http://pokr.kr/bill/1809890"&gt;대한민국 국회 제 1809890호 의안&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;할 수 있는 사람은, 위의 문서 대신 다른 텍스트 데이터를 로딩하여 사용해보자.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;gutenberg&lt;/span&gt;   &lt;span class="c"&gt;# Docs from project gutenberg.org&lt;/span&gt;
&lt;span class="n"&gt;files_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gutenberg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;      &lt;span class="c"&gt;# Get file ids&lt;/span&gt;
&lt;span class="n"&gt;doc_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gutenberg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;austen-emma.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;    &lt;span class="c"&gt;# Docs from pokr.kr/bill&lt;/span&gt;
&lt;span class="n"&gt;files_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;         &lt;span class="c"&gt;# Get file ids&lt;/span&gt;
&lt;span class="n"&gt;doc_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;1809890.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2. Tokenize&lt;/h3&gt;
&lt;p&gt;문서를 토큰으로 나누는 방법은 다양하다.
여기서는 영어에는 &lt;code&gt;nltk.regexp_tokenize&lt;/code&gt;, 한국어에는 &lt;code&gt;konlpy.tag.Twitter.morph&lt;/code&gt;를 사용해보자.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;regexp_tokenize&lt;/span&gt;
&lt;span class="n"&gt;pattern&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;r&amp;#39;&amp;#39;&amp;#39;(?x) ([A-Z]\.)+ | \w+(-\w+)* | \$?\d+(\.\d+)?%? | \.\.\. | [][.,;&amp;quot;&amp;#39;?():-_`]&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;tokens_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;regexp_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pattern&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.tag&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;tokens_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;morphs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;3. Load tokens with &lt;code&gt;nltk.Text()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;nltk.Text()&lt;/code&gt;는 문서 하나를 편리하게 탐색할 수 있는 다양한 기능을 제공한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt;
&lt;span class="n"&gt;en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean (For Python 2, &lt;code&gt;name&lt;/code&gt; has to be input as u'유니코드'. If you are using Python 2, use u'유니코드' for input of all following Korean text.)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt;
&lt;span class="n"&gt;ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;대한민국 국회 의안 제 1809890호&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c"&gt;# For Python 2, input `name` as u&amp;#39;유니코드&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;지금부터 &lt;code&gt;nltk.Text()&lt;/code&gt;가 제공하는 다양한 기능을 하나씩 살펴보자.
(참고링크: &lt;a href="http://www.nltk.org/api/nltk.html#nltk.text.Text"&gt;class nltk.text.Text API 문서&lt;/a&gt;)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Tokens&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;       &lt;span class="c"&gt;# returns number of tokens (document length)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;  &lt;span class="c"&gt;# returns number of unique tokens&lt;/span&gt;
&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;                  &lt;span class="c"&gt;# returns frequency distribution&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
191061
7927
FreqDist({',': 12018, '.': 8853, 'to': 5127, 'the': 4844, 'and': 4653, 'of': 4278, '"': 4187, 'I': 3177, 'a': 3000, 'was': 2385, ...})
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;       &lt;span class="c"&gt;# returns number of tokens (document length)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;  &lt;span class="c"&gt;# returns number of unique tokens&lt;/span&gt;
&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;                  &lt;span class="c"&gt;# returns frequency distribution&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
1707
476
FreqDist({'.': 61, '의': 46, '육아휴직': 38, '을': 34, '(': 27, ',': 26, '이': 26, ')': 26, '에': 24, '자': 24, ...})
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Plot frequency distributions&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;     &lt;span class="c"&gt;# Plot sorted frequency of top 50 tokens&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/fdist_en.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;     &lt;span class="c"&gt;# Plot sorted frequency of top 50 tokens&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/fdist_ko.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: To save a plot programmably, and not through the GUI, overwrite &lt;code&gt;pylab.show&lt;/code&gt; with &lt;code&gt;pylab.savefig&lt;/code&gt; before drawing the plot (&lt;a href="http://stackoverflow.com/questions/27392390/how-do-i-send-nltk-plots-to-files"&gt;reference&lt;/a&gt;):
&lt;pre&gt;
from matplotlib import pylab
pylab.show = lambda: pylab.savefig('some_filename.png')
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Troubleshooting&lt;/strong&gt;: For those who see rectangles instead of letters in the saved plot file, include the following configurations before drawing the plot:
&lt;pre&gt;
from matplotlib import font_manager, rc
font_fname = 'c:/windows/fonts/gulim.ttc'     # A font of your choice
font_name = font_manager.FontProperties(fname=font_fname).get_name()
rc('font', family=font_name)
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;Some example fonts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mac OS: &lt;code&gt;/Library/Fonts/AppleGothic.ttf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Count&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;        &lt;span class="c"&gt;# Counts occurrences&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
865
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;초등학교&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c"&gt;# Counts occurrences&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
6
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dispersion plot&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dispersion_plot&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Frank&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Jane&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/disp_en.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dispersion_plot&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;육아휴직&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;초등학교&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;공무원&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/disp_ko.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Concordance&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concordance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lines&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
Displaying 5 of 865 matches:
                                     Emma by Jane Austen 1816 ] VOLUME I CHAPT
                                     Emma Woodhouse , handsome , clever , and 
both daughters , but particularly of Emma . Between &lt;em&gt;them&lt;/em&gt; it was more the int
 friend very mutually attached , and Emma doing just what she liked ; highly e
r own . The real evils , indeed , of Emma ' s situation were the power of havi
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean (or, use &lt;a href="http://konlpy.org/en/v0.4.3/api/konlpy/#konlpy.utils.concordance"&gt;konlpy.utils.concordance&lt;/a&gt;)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concordance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;초등학교&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
Displaying 6 of 6 matches:
 ․ 김정훈 김학송 의원 ( 10 인 ) 제안 이유 및 주요 내용 초등학교 저학년 의 경우 에도 부모 의 따뜻한 사랑 과 보살핌 이 필요 한
 을 할 수 있는 자녀 의 나이 는 만 6 세 이하 로 되어 있어 초등학교 저학년 인 자녀 를 돌보기 위해서 는 해당 부모님 은 일자리 를 
 다 . 제 63 조제 2 항제 4 호 중 “ 만 6 세 이하 의 초등학교 취학 전 자녀 를 ” 을 “ 만 8 세 이하 ( 취학 중인 경우 
 전 자녀 를 ” 을 “ 만 8 세 이하 ( 취학 중인 경우 에는 초등학교 2 학년 이하 를 말한 다 ) 의 자녀 를 ” 로 한 다 . 부 
 . ∼ 3 . ( 현행 과 같 음 ) 4 . 만 6 세 이하 의 초등학교 취 4 . 만 8 세 이하 ( 취학 중인 경우 학 전 자녀 를 양
세 이하 ( 취학 중인 경우 학 전 자녀 를 양육 하기 위하 에는 초등학교 2 학년 이하 를 여 필요하거 나 여자 공무원 이 말한 다 ) 의
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find similar words&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Frank&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
she it he i harriet you her jane him that me and all they them there herself was hartfield be
mr mrs emma harriet you it her she he him hartfield them jane that isabella all herself look i me
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;자녀&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;육아휴직&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
논의
None
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Collocations&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;collocations&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
Frank Churchill; Miss Woodhouse; Miss Bates; Jane Fairfax; Miss
Fairfax; every thing; young man; every body; great deal; dare say;
John Knightley; Maple Grove; Miss Smith; Miss Taylor; Robert Martin;
Colonel Campbell; Box Hill; said Emma; Harriet Smith; William Larkins
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;collocations&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
초등학교 저학년; 육아휴직 대상
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For more information on &lt;code&gt;nltk.Text()&lt;/code&gt;, see the &lt;a href="http://www.nltk.org/_modules/nltk/text.html#Text"&gt;source code&lt;/a&gt; or &lt;a href="http://www.nltk.org/api/nltk.html#nltk.text.Text"&gt;API&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Tagging and chunking&lt;/h2&gt;
&lt;p&gt;Until now, we used delimited text, namely &lt;em&gt;tokens&lt;/em&gt;, to explore our sample document.
Now let's classify words into given classes, namely &lt;em&gt;part-of-speech tags&lt;/em&gt;, and chunk text into larger pieces.&lt;/p&gt;
&lt;h3&gt;1. POS tagging&lt;/h3&gt;
&lt;p&gt;There are numerous ways of tagging a text.
Among them, the most frequently used, and developed way of tagging is arguably POS tagging.&lt;/p&gt;
&lt;p&gt;Since one document is too long to observe a parsed structure,
lets use one short sentence for each language.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;The little yellow dog barked at the Persian cat&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;tags_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[('The', 'DT'),
 ('little', 'JJ'),
 ('yellow', 'NN'),
 ('dog', 'NN'),
 ('barked', 'VBD'),
 ('at', 'IN'),
 ('the', 'DT'),
 ('Persian', 'NNP'),
 ('cat', 'NN')]
&lt;/pre&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is also possible to use the famous &lt;a href="http://www.nltk.org/api/nltk.tag.html#module-nltk.tag.stanford"&gt;Stanford POS tagger with NLTK&lt;/a&gt;, with &lt;code&gt;from nltk.tag.stanford import POSTagger&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.tag&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;tags_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;작고 노란 강아지가 페르시안 고양이에게 짖었다&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[('작고', 'Noun'),
 ('노란', 'Adjective'),
 ('강아지', 'Noun'),
 ('가', 'Josa'),
 ('페르시안', 'Noun'),
 ('고양이', 'Noun'),
 ('에게', 'Josa'),
 ('짖었', 'Noun'),
 ('다', 'Josa')]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2. Noun phrase chunking&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.nltk.org/api/nltk.chunk.html#nltk.chunk.regexp.RegexpParser"&gt;&lt;code&gt;nltk.RegexpParser()&lt;/code&gt;&lt;/a&gt; is a great way to start chunking.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;parser_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RegexpParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;NP: {&amp;lt;DT&amp;gt;?&amp;lt;JJ&amp;gt;?&amp;lt;NN.*&amp;gt;*}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tags_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;draw&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/tree_en.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;parser_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RegexpParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;NP: {&amp;lt;Adjective&amp;gt;*&amp;lt;Noun&amp;gt;*}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tags_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;draw&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/tree_ko.png" width="700px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information on chunking, refer to &lt;a href="http://www.nltk.org/book/ch07.html"&gt;Extracting Information from Text&lt;/a&gt; for English, and &lt;a href="http://konlpy.org/en/v0.4.3/examples/chunking/"&gt;Chunking&lt;/a&gt; for Korean.&lt;/p&gt;
&lt;h2&gt;Drawing a word cloud&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;제 1809890호 의안의 빈도분포(frequency distribution)를 다시 살펴보자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
FreqDist({'.': 61, '의': 46, '육아휴직': 38, '을': 34, '(': 27, ',': 26, '이': 26, ')': 26, '에': 24, '자': 24, ...})
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이 빈도분포의 data type과 attribute 목록을 확인해보자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
nltk.probability.FreqDist
&lt;/pre&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nb"&gt;dir&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['B',
 'N',
 ...
 'items',
 ...
 'pop',
 'popitem',
 'pprint',
 'r_Nr',
 'setdefault',
 'subtract',
 'tabulate',
 'unicode_repr',
 'update',
 'values']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;items()&lt;/code&gt;를 사용하면 빈도분포의 item 전체를 set의 형태로 볼 수 있다. 이를 &lt;code&gt;data&lt;/code&gt;라는 이름의 변수에 저장한 후, data type을 관찰하자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
dict_items([('명', 5), ('예상된', 3), ('하나', 1), ('11', 2), ('팀', 2), ...])
&lt;code&gt;&amp;lt;class 'dict_items'&amp;gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이 set을 이제 &lt;code&gt;words.csv&lt;/code&gt;라는 파일에 저장해보자. 데이터 header는 word,freq로 하면 된다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;csv&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;words.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;encoding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;word,freq&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;writer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;csv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;writer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;writer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;writerows&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;다음으로 아래의 코드를 복사하여 &lt;code&gt;words.csv&lt;/code&gt;가 있는 폴더 내에 &lt;code&gt;index.html&lt;/code&gt;라는 이름으로 저장하자.&lt;br&gt;
    &lt;script src="https://gist.github.com/e9t/e462f7462e9d83b03464.js?file=index.html" type="text/javascript"&gt;&lt;/script&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;위와 같은 폴더에서 아래를 실행하자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;server&lt;/span&gt; &lt;span class="mi"&gt;8888&lt;/span&gt;      &lt;span class="c"&gt;# for Python2, `python -m SimpleHTTPServer`&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;마지막으로, 모던 브라우저(ex: 크롬)의 주소창에 &lt;code&gt;http://localhost:8888&lt;/code&gt;를 입력하면 우리의 워드클라우드가 떠있을 것이다!&lt;br&gt;
    &lt;iframe src="http://bl.ocks.org/e9t/raw/e462f7462e9d83b03464/" width="600px" height="600px" frameborder=0&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;더 실험해보고 싶은 경우:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;위의 워드클라우드는 각종 특수문자, 조사 등도 포함되어 정보 전달력이 떨어진다. 워드클라우드에 명사만 표현되게 할 수 있을까?&lt;/li&gt;
&lt;li&gt;다른 임의의 문서로도 워드클라우드를 그릴 수 있나? (ex: 내 데이터마이닝 프로젝트 제안서) 해당 문서를 파이썬으로 읽고, 문서에서 높은 빈도로 등장한 단어를 추출 후, 워드클라우드로 그려보자.&lt;/li&gt;
&lt;li&gt;여러 개의 문서에 대한 워드클라우드를 그릴 수도 있나? 파이썬으로 여러 개의 문서를 한꺼번에 읽어들인 후, 높은 빈도로 등장한 단어를 추출해서 워드클라우드로 그려보자.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary><category term="text"></category><category term="lectures"></category></entry><entry><title>파이썬으로 영어와 한국어 텍스트 다루기</title><link href="http://lucypark.kr/courses/2015-dm/text-mining.html" rel="alternate"></link><updated>2015-04-10T09:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-04-10:courses/2015-dm/text-mining.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;We use Python 3 in this tutorial, but provide minimal guidelines for Python 2.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;지난 시간 복습&lt;/h2&gt;
&lt;h3&gt;Terminologies&lt;/h3&gt;
&lt;p&gt;&lt;table class="table"&gt;&lt;tr&gt;&lt;th&gt;English&lt;/th&gt;&lt;th&gt;한국어&lt;/th&gt;&lt;th&gt;Description&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Document&lt;/td&gt;&lt;td&gt;문서&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Corpus&lt;/td&gt;&lt;td&gt;말뭉치&lt;/td&gt;&lt;td&gt;A set of documents&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Token&lt;/td&gt;&lt;td&gt;토큰&lt;/td&gt;&lt;td&gt;Meaningful elements in a text such as words or phrases or symbols&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Morphemes&lt;/td&gt;&lt;td&gt;형태소&lt;/td&gt;&lt;td&gt;Smallest meaningful unit in a language&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;POS&lt;/td&gt;&lt;td&gt;품사&lt;/td&gt;&lt;td&gt;Part-of-speech (ex: Nouns)&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/p&gt;
&lt;h3&gt;Text analysis process&lt;/h3&gt;
&lt;p&gt;&lt;img src="images/text-process.png" width="200px"&gt;&lt;/p&gt;
&lt;p&gt;전처리는 아래의 세부 과정으로 다시 한 번 나뉜다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Load text&lt;/li&gt;
&lt;li&gt;Tokenize text (ex: stemming, morph analyzing)&lt;/li&gt;
&lt;li&gt;Tag tokens (ex: POS, NER)&lt;/li&gt;
&lt;li&gt;Token(Feature) selection and/or filter/rank tokens (ex: stopword removal, TF-IDF)&lt;/li&gt;
&lt;li&gt;...and so on (ex: calculate word/document similarities, cluster documents)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Useful Python Packages for Text Mining and NLP&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nltk.org"&gt;NLTK&lt;/a&gt;: Provides modules for text analysis (mostly language independent)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;설치하기&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pip install nltk
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;주요기능&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.nltk.org/book/ch02.html"&gt;Text corpora&lt;/a&gt;: 특히, 이 튜토리얼에서는 아래의 두 가지 데이터가 필요하니 미리 다운 받아두자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gutenberg&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;maxent_treebank_pos_tagger&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.nltk.org/api/nltk.tag.html"&gt;Word POS, NER classification&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.nltk.org/book/ch06.html"&gt;Document classification&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://konlpy.org"&gt;KoNLPy&lt;/a&gt;: Provides modules for Korean text analysis&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;설치하기&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pip install konlpy
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;주요기능&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://konlpy.org/en/latest/data/#corpora"&gt;Text corpora&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://konlpy.org/en/latest/api/konlpy.tag/"&gt;Word POS classification&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Hannanum&lt;/li&gt;
&lt;li&gt;Kkma&lt;/li&gt;
&lt;li&gt;Mecab&lt;/li&gt;
&lt;li&gt;Komoran&lt;/li&gt;
&lt;li&gt;Twitter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http//radimrehurek.com/gensim/"&gt;Gensim&lt;/a&gt;: Provides modules for topic modeling and calculating similarities among documents&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;설치하기&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pip install -U gensim
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;주요기능&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Topic modeling&lt;ul&gt;
&lt;li&gt;&lt;a href="http://radimrehurek.com/gensim/models/ldamodel.html"&gt;Latent Dirichlet allocation (LDA)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://radimrehurek.com/gensim/models/lsimodel.html"&gt;Latent semantic indexing (LSI)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://radimrehurek.com/gensim/models/hdpmodel.html"&gt;Hierarchical Dirichlet process (HDP)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Word embedding&lt;ul&gt;
&lt;li&gt;&lt;a href="radimrehurek.com/gensim/models/word2vec.html"&gt;word2vec&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/ryanmcgrath/twython"&gt;Twython&lt;/a&gt;: Provides easy access to Twitter API&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;설치하기&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pip install twython
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;사용예시: "Samsung (삼성)" 관련 트윗 받기&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;twython&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twython&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;settings&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;s&lt;/span&gt;    &lt;span class="c"&gt;# Create a file named settings.py, and put oauth KEY values inside&lt;/span&gt;
&lt;span class="n"&gt;twitter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twython&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;APP_KEY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;APP_SECRET&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OAUTH_TOKEN&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OAUTH_TOKEN_SECRET&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tweets&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;twitter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;삼성&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;user&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;screen_name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;created_at&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;statuses&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Text exploration&lt;/h2&gt;
&lt;h3&gt;1. Read document&lt;/h3&gt;
&lt;p&gt;이 튜토리얼에서는 NLTK, KoNLPy에서 제공하는 문서들을 사용한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;영어: &lt;a href="http://www.gutenberg.org/ebooks/158"&gt;Jane Austen의 소설 Emma&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;한국어: &lt;a href="http://pokr.kr/bill/1809890"&gt;대한민국 국회 제 1809890호 의안&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;할 수 있는 사람은, 위의 문서 대신 다른 텍스트 데이터를 로딩하여 사용해보자.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;gutenberg&lt;/span&gt;   &lt;span class="c"&gt;# Docs from project gutenberg.org&lt;/span&gt;
&lt;span class="n"&gt;files_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gutenberg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;      &lt;span class="c"&gt;# Get file ids&lt;/span&gt;
&lt;span class="n"&gt;doc_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gutenberg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;austen-emma.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;    &lt;span class="c"&gt;# Docs from pokr.kr/bill&lt;/span&gt;
&lt;span class="n"&gt;files_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;         &lt;span class="c"&gt;# Get file ids&lt;/span&gt;
&lt;span class="n"&gt;doc_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;1809890.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2. Tokenize&lt;/h3&gt;
&lt;p&gt;문서를 토큰으로 나누는 방법은 다양하다.
여기서는 영어에는 &lt;code&gt;nltk.regexp_tokenize&lt;/code&gt;, 한국어에는 &lt;code&gt;konlpy.tag.Twitter.morph&lt;/code&gt;를 사용해보자.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;regexp_tokenize&lt;/span&gt;
&lt;span class="n"&gt;pattern&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;r&amp;#39;&amp;#39;&amp;#39;(?x) ([A-Z]\.)+ | \w+(-\w+)* | \$?\d+(\.\d+)?%? | \.\.\. | [][.,;&amp;quot;&amp;#39;?():-_`]&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;tokens_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;regexp_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pattern&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.tag&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;tokens_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;morphs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;3. Load tokens with &lt;code&gt;nltk.Text()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;nltk.Text()&lt;/code&gt;는 문서 하나를 편리하게 탐색할 수 있는 다양한 기능을 제공한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt;
&lt;span class="n"&gt;en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean (For Python 2, &lt;code&gt;name&lt;/code&gt; has to be input as u'유니코드'. If you are using Python 2, use u'유니코드' for input of all following Korean text.)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt;
&lt;span class="n"&gt;ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;대한민국 국회 의안 제 1809890호&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c"&gt;# For Python 2, input `name` as u&amp;#39;유니코드&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;지금부터 &lt;code&gt;nltk.Text()&lt;/code&gt;가 제공하는 다양한 기능을 하나씩 살펴보자.
(참고링크: &lt;a href="http://www.nltk.org/api/nltk.html#nltk.text.Text"&gt;class nltk.text.Text API 문서&lt;/a&gt;)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Tokens&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;       &lt;span class="c"&gt;# returns number of tokens (document length)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;  &lt;span class="c"&gt;# returns number of unique tokens&lt;/span&gt;
&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;                  &lt;span class="c"&gt;# returns frequency distribution&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
191061
7927
FreqDist({',': 12018, '.': 8853, 'to': 5127, 'the': 4844, 'and': 4653, 'of': 4278, '"': 4187, 'I': 3177, 'a': 3000, 'was': 2385, ...})
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;       &lt;span class="c"&gt;# returns number of tokens (document length)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;  &lt;span class="c"&gt;# returns number of unique tokens&lt;/span&gt;
&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;                  &lt;span class="c"&gt;# returns frequency distribution&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
1707
476
FreqDist({'.': 61, '의': 46, '육아휴직': 38, '을': 34, '(': 27, ',': 26, '이': 26, ')': 26, '에': 24, '자': 24, ...})
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Plot frequency distributions&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;     &lt;span class="c"&gt;# Plot sorted frequency of top 50 tokens&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/fdist_en.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;     &lt;span class="c"&gt;# Plot sorted frequency of top 50 tokens&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/fdist_ko.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: To save a plot programmably, and not through the GUI, overwrite &lt;code&gt;pylab.show&lt;/code&gt; with &lt;code&gt;pylab.savefig&lt;/code&gt; before drawing the plot (&lt;a href="http://stackoverflow.com/questions/27392390/how-do-i-send-nltk-plots-to-files"&gt;reference&lt;/a&gt;):
&lt;pre&gt;
from matplotlib import pylab
pylab.show = lambda: pylab.savefig('some_filename.png')
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Troubleshooting&lt;/strong&gt;: For those who see rectangles instead of letters in the saved plot file, include the following configurations before drawing the plot:
&lt;pre&gt;
from matplotlib import font_manager, rc
font_fname = 'c:/windows/fonts/gulim.ttc'     # A font of your choice
font_name = font_manager.FontProperties(fname=font_fname).get_name()
rc('font', family=font_name)
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;Some example fonts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mac OS: &lt;code&gt;/Library/Fonts/AppleGothic.ttf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Count&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;        &lt;span class="c"&gt;# Counts occurrences&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
865
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;초등학교&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c"&gt;# Counts occurrences&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
6
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dispersion plot&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dispersion_plot&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Frank&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Jane&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/disp_en.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dispersion_plot&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;육아휴직&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;초등학교&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;공무원&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/disp_ko.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Concordance&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concordance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lines&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
Displaying 5 of 865 matches:
                                     Emma by Jane Austen 1816 ] VOLUME I CHAPT
                                     Emma Woodhouse , handsome , clever , and 
both daughters , but particularly of Emma . Between &lt;em&gt;them&lt;/em&gt; it was more the int
 friend very mutually attached , and Emma doing just what she liked ; highly e
r own . The real evils , indeed , of Emma ' s situation were the power of havi
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean (or, use &lt;a href="http://konlpy.org/en/v0.4.3/api/konlpy/#konlpy.utils.concordance"&gt;konlpy.utils.concordance&lt;/a&gt;)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concordance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;초등학교&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
Displaying 6 of 6 matches:
 ․ 김정훈 김학송 의원 ( 10 인 ) 제안 이유 및 주요 내용 초등학교 저학년 의 경우 에도 부모 의 따뜻한 사랑 과 보살핌 이 필요 한
 을 할 수 있는 자녀 의 나이 는 만 6 세 이하 로 되어 있어 초등학교 저학년 인 자녀 를 돌보기 위해서 는 해당 부모님 은 일자리 를 
 다 . 제 63 조제 2 항제 4 호 중 “ 만 6 세 이하 의 초등학교 취학 전 자녀 를 ” 을 “ 만 8 세 이하 ( 취학 중인 경우 
 전 자녀 를 ” 을 “ 만 8 세 이하 ( 취학 중인 경우 에는 초등학교 2 학년 이하 를 말한 다 ) 의 자녀 를 ” 로 한 다 . 부 
 . ∼ 3 . ( 현행 과 같 음 ) 4 . 만 6 세 이하 의 초등학교 취 4 . 만 8 세 이하 ( 취학 중인 경우 학 전 자녀 를 양
세 이하 ( 취학 중인 경우 학 전 자녀 를 양육 하기 위하 에는 초등학교 2 학년 이하 를 여 필요하거 나 여자 공무원 이 말한 다 ) 의
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find similar words&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Frank&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
she it he i harriet you her jane him that me and all they them there herself was hartfield be
mr mrs emma harriet you it her she he him hartfield them jane that isabella all herself look i me
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;자녀&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;육아휴직&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
논의
None
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Collocations&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;collocations&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
Frank Churchill; Miss Woodhouse; Miss Bates; Jane Fairfax; Miss
Fairfax; every thing; young man; every body; great deal; dare say;
John Knightley; Maple Grove; Miss Smith; Miss Taylor; Robert Martin;
Colonel Campbell; Box Hill; said Emma; Harriet Smith; William Larkins
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;collocations&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
초등학교 저학년; 육아휴직 대상
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For more information on &lt;code&gt;nltk.Text()&lt;/code&gt;, see the &lt;a href="http://www.nltk.org/_modules/nltk/text.html#Text"&gt;source code&lt;/a&gt; or &lt;a href="http://www.nltk.org/api/nltk.html#nltk.text.Text"&gt;API&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Tagging and chunking&lt;/h2&gt;
&lt;p&gt;Until now, we used delimited text, namely &lt;em&gt;tokens&lt;/em&gt;, to explore our sample document.
Now let's classify words into given classes, namely &lt;em&gt;part-of-speech tags&lt;/em&gt;, and chunk text into larger pieces.&lt;/p&gt;
&lt;h3&gt;1. POS tagging&lt;/h3&gt;
&lt;p&gt;There are numerous ways of tagging a text.
Among them, the most frequently used, and developed way of tagging is arguably POS tagging.&lt;/p&gt;
&lt;p&gt;Since one document is too long to observe a parsed structure,
lets use one short sentence for each language.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;The little yellow dog barked at the Persian cat&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;tags_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[('The', 'DT'),
 ('little', 'JJ'),
 ('yellow', 'NN'),
 ('dog', 'NN'),
 ('barked', 'VBD'),
 ('at', 'IN'),
 ('the', 'DT'),
 ('Persian', 'NNP'),
 ('cat', 'NN')]
&lt;/pre&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is also possible to use the famous &lt;a href="http://www.nltk.org/api/nltk.tag.html#module-nltk.tag.stanford"&gt;Stanford POS tagger with NLTK&lt;/a&gt;, with &lt;code&gt;from nltk.tag.stanford import POSTagger&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.tag&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;tags_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;작고 노란 강아지가 페르시안 고양이에게 짖었다&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[('작고', 'Noun'),
 ('노란', 'Adjective'),
 ('강아지', 'Noun'),
 ('가', 'Josa'),
 ('페르시안', 'Noun'),
 ('고양이', 'Noun'),
 ('에게', 'Josa'),
 ('짖었', 'Noun'),
 ('다', 'Josa')]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2. Noun phrase chunking&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.nltk.org/api/nltk.chunk.html#nltk.chunk.regexp.RegexpParser"&gt;&lt;code&gt;nltk.RegexpParser()&lt;/code&gt;&lt;/a&gt; is a great way to start chunking.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;parser_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RegexpParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;NP: {&amp;lt;DT&amp;gt;?&amp;lt;JJ&amp;gt;?&amp;lt;NN.*&amp;gt;*}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tags_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;draw&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/tree_en.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;parser_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RegexpParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;NP: {&amp;lt;Adjective&amp;gt;*&amp;lt;Noun&amp;gt;*}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tags_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;draw&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/tree_ko.png" width="700px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information on chunking, refer to &lt;a href="http://www.nltk.org/book/ch07.html"&gt;Extracting Information from Text&lt;/a&gt; for English, and &lt;a href="http://konlpy.org/en/v0.4.3/examples/chunking/"&gt;Chunking&lt;/a&gt; for Korean.&lt;/p&gt;
&lt;h2&gt;Drawing a word cloud&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;제 1809890호 의안의 빈도분포(frequency distribution)를 다시 살펴보자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
FreqDist({'.': 61, '의': 46, '육아휴직': 38, '을': 34, '(': 27, ',': 26, '이': 26, ')': 26, '에': 24, '자': 24, ...})
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이 빈도분포의 data type과 attribute 목록을 확인해보자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
nltk.probability.FreqDist
&lt;/pre&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nb"&gt;dir&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['B',
 'N',
 ...
 'items',
 ...
 'pop',
 'popitem',
 'pprint',
 'r_Nr',
 'setdefault',
 'subtract',
 'tabulate',
 'unicode_repr',
 'update',
 'values']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;items()&lt;/code&gt;를 사용하면 빈도분포의 item 전체를 set의 형태로 볼 수 있다. 이를 &lt;code&gt;data&lt;/code&gt;라는 이름의 변수에 저장한 후, data type을 관찰하자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
dict_items([('명', 5), ('예상된', 3), ('하나', 1), ('11', 2), ('팀', 2), ...])
&lt;code&gt;&amp;lt;class 'dict_items'&amp;gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이 set을 이제 &lt;code&gt;words.csv&lt;/code&gt;라는 파일에 저장해보자. 데이터 header는 word,freq로 하면 된다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;csv&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;words.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;encoding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;word,freq&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;writer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;csv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;writer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;writer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;writerows&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;다음으로 아래의 코드를 복사하여 &lt;code&gt;words.csv&lt;/code&gt;가 있는 폴더 내에 &lt;code&gt;index.html&lt;/code&gt;라는 이름으로 저장하자.&lt;br&gt;
    &lt;script src="https://gist.github.com/e9t/e462f7462e9d83b03464.js?file=index.html" type="text/javascript"&gt;&lt;/script&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;위와 같은 폴더에서 아래를 실행하자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;server&lt;/span&gt; &lt;span class="mi"&gt;8888&lt;/span&gt;      &lt;span class="c"&gt;# for Python2, `python -m SimpleHTTPServer`&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;마지막으로, 모던 브라우저(ex: 크롬)의 주소창에 &lt;code&gt;http://localhost:8888&lt;/code&gt;를 입력하면 우리의 워드클라우드가 떠있을 것이다!&lt;br&gt;
    &lt;iframe src="http://bl.ocks.org/e9t/raw/e462f7462e9d83b03464/" width="600px" height="600px" frameborder=0&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;더 실험해보고 싶은 경우:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;위의 워드클라우드는 각종 특수문자, 조사 등도 포함되어 정보 전달력이 떨어진다. 워드클라우드에 명사만 표현되게 할 수 있을까?&lt;/li&gt;
&lt;li&gt;다른 임의의 문서로도 워드클라우드를 그릴 수 있나? (ex: 내 데이터마이닝 프로젝트 제안서) 해당 문서를 파이썬으로 읽고, 문서에서 높은 빈도로 등장한 단어를 추출 후, 워드클라우드로 그려보자.&lt;/li&gt;
&lt;li&gt;여러 개의 문서에 대한 워드클라우드를 그릴 수도 있나? 파이썬으로 여러 개의 문서를 한꺼번에 읽어들인 후, 높은 빈도로 등장한 단어를 추출해서 워드클라우드로 그려보자.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary><category term="text"></category><category term="lectures"></category></entry><entry><title>Bash</title><link href="http://lucypark.kr/courses/2015-ba/bash.html" rel="alternate"></link><updated>2015-04-02T00:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-04-02:courses/2015-ba/bash.html</id><summary type="html">&lt;h2&gt;What is an OS?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;DOS, Windows, Linux, Mac OS, iOS, Android, ...&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Linux?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;OS&lt;/li&gt;
&lt;li&gt;Made by Linus Torvalds&lt;/li&gt;
&lt;li&gt;Inspired by Unix&lt;/li&gt;
&lt;li&gt;Debian, CentOS, Ubuntu, Fedora, Redhat Linux, Gentoo, Arch, Suse, Slackware, Mandriva, PintOS, ...&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Why Linux?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Custom&lt;/li&gt;
&lt;li&gt;Free (in some sense)&lt;/li&gt;
&lt;li&gt;Open source&lt;/li&gt;
&lt;li&gt;Supports multiple users&lt;/li&gt;
&lt;li&gt;Has compatibility with Unix-like OSs&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Files&lt;/h2&gt;
&lt;h3&gt;Directories&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;.&lt;/code&gt;: current directory&lt;/li&gt;
&lt;li&gt;&lt;code&gt;..&lt;/code&gt;: parent directory&lt;/li&gt;
&lt;li&gt;&lt;code&gt;~/&lt;/code&gt;: home directory&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/&lt;/code&gt;: root directory&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/some/absolute/path&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;some/relative/path&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/bash.jpg" width="350px"&gt;&lt;/p&gt;
&lt;h3&gt;Permissions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Read, Write, eXecute&lt;/li&gt;
&lt;li&gt;Owner, Owner group, Others&lt;/li&gt;
&lt;li&gt;rwxrwxrwx&lt;ul&gt;
&lt;li&gt;All permissions for everyone&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- GNU linux history --&gt;

&lt;h2&gt;&lt;a href="https://www.gnu.org/software/bash/manual/html_node/What-is-Bash_003f.html"&gt;What is Bash?&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Bash is a "shell" for the GNU operating system&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/bash.png" width="500px"&gt;&lt;/p&gt;
&lt;h3&gt;Then &lt;a href="https://www.gnu.org/software/bash/manual/html_node/What-is-a-shell_003f.html###What-is-a-shell_003f"&gt;what is a shell?&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A shell is a macro processor that executes commands&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/kernel.png" width="500px"&gt;&lt;/p&gt;
&lt;h3&gt;Is Bash the only shell available?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;No.&lt;/li&gt;
&lt;li&gt;There are many many alternatives, such as &lt;code&gt;sh&lt;/code&gt;, &lt;code&gt;ksh&lt;/code&gt;, &lt;code&gt;csh&lt;/code&gt; or &lt;code&gt;zsh&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;However, &lt;code&gt;bash&lt;/code&gt; is the default shell in GNU systems&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Can I use &lt;code&gt;bash&lt;/code&gt; in GNU systems only?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;No.&lt;/li&gt;
&lt;li&gt;You can also use bash in Windows and other platforms, using portable versions&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Why should I use Bash?&lt;/h2&gt;
&lt;h3&gt;Package managing&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What is a package?&lt;/li&gt;
&lt;li&gt;What is it to manage a package?&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;What kind of package managers are there?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Windows: ???&lt;/li&gt;
&lt;li&gt;Mac: Homebrew&lt;/li&gt;
&lt;li&gt;Ubuntu: apt-get&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!--
Some jokes about package managing:
- https://twitter.com/gardaud/status/357638468572151808
- https://twitter.com/ddprrt/status/529909875347030016
--&gt;

&lt;h3&gt;Data science&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.ecogwiki.com/Hash-based_sampling"&gt;Data sampling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;...&lt;a href="http://jeroenjanssens.com/2013/09/19/seven-command-line-tools-for-data-science.html"&gt;and more&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="programming"></category><category term="seoultech"></category><category term="lectures"></category></entry><entry><title>Mining English and Korean text with Python</title><link href="http://lucypark.kr/courses/2015-ba/text-mining.html" rel="alternate"></link><updated>2015-03-27T15:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-27:courses/2015-ba/text-mining.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;We use Python 3 in this tutorial, but provide minimal guidelines for Python 2.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Terminologies&lt;/h2&gt;
&lt;p&gt;&lt;table class="table"&gt;&lt;tr&gt;&lt;th&gt;English&lt;/th&gt;&lt;th&gt;한국어&lt;/th&gt;&lt;th&gt;Description&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Document&lt;/td&gt;&lt;td&gt;문서&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Corpus&lt;/td&gt;&lt;td&gt;말뭉치&lt;/td&gt;&lt;td&gt;A set of documents&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Token&lt;/td&gt;&lt;td&gt;토큰&lt;/td&gt;&lt;td&gt;Meaningful elements in a text such as words or phrases or symbols&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Morphemes&lt;/td&gt;&lt;td&gt;형태소&lt;/td&gt;&lt;td&gt;Smallest meaningful unit in a language&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;POS&lt;/td&gt;&lt;td&gt;품사&lt;/td&gt;&lt;td&gt;Part-of-speech (ex: Nouns)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Classification&lt;/td&gt;&lt;td&gt;분류&lt;/td&gt;&lt;td&gt;A supervised learning task where $X$ and $y$ are given and $y$ is a set of discrete classes&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Clustering&lt;/td&gt;&lt;td&gt;군집화&lt;/td&gt;&lt;td&gt;An unsupervised learning task where $X$ is given&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/p&gt;
&lt;h2&gt;Text analysis process&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Load text&lt;/li&gt;
&lt;li&gt;Tokenize text (ex: stemming, morph analyzing)&lt;/li&gt;
&lt;li&gt;Tag tokens (ex: POS, NER)&lt;/li&gt;
&lt;li&gt;Token(Feature) selection and/or filter/rank tokens (ex: stopword removal, TF-IDF)&lt;/li&gt;
&lt;li&gt;...and so on (ex: calculate word/document similarities, cluster documents)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Python Packages for Text Mining and NLP&lt;/h2&gt;
&lt;p&gt;...that we use in this tutorial.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nltk.org"&gt;NLTK&lt;/a&gt;: Provides modules for text analysis (mostly language independent)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pip install nltk
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.nltk.org/book/ch02.html"&gt;Text corpora&lt;/a&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gutenberg&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;maxent_treebank_pos_tagger&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.nltk.org/api/nltk.tag.html"&gt;Word POS, NER classification&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.nltk.org/book/ch06.html"&gt;Document classification&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://konlpy.org"&gt;KoNLPy&lt;/a&gt;: Provides modules for Korean text analysis&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pip install konlpy
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;&lt;a href="http://konlpy.org/en/latest/data/#corpora"&gt;Text corpora&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://konlpy.org/en/latest/api/konlpy.tag/"&gt;Word POS classification&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Hannanum&lt;/li&gt;
&lt;li&gt;Kkma&lt;/li&gt;
&lt;li&gt;Mecab&lt;/li&gt;
&lt;li&gt;Komoran&lt;/li&gt;
&lt;li&gt;Twitter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http//radimrehurek.com/gensim/"&gt;Gensim&lt;/a&gt;: Provides modules for topic modeling and calculating similarities among documents&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pip install -U gensim
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Topic modeling&lt;ul&gt;
&lt;li&gt;&lt;a href="http://radimrehurek.com/gensim/models/ldamodel.html"&gt;Latent Dirichlet allocation (LDA)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://radimrehurek.com/gensim/models/lsimodel.html"&gt;Latent semantic indexing (LSI)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://radimrehurek.com/gensim/models/hdpmodel.html"&gt;Hierarchical Dirichlet process (HDP)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Word embedding&lt;ul&gt;
&lt;li&gt;&lt;a href="radimrehurek.com/gensim/models/word2vec.html"&gt;word2vec&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/ryanmcgrath/twython"&gt;Twython&lt;/a&gt;: Provides easy access to Twitter API&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pip install twython
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Example: Getting "Samsung (삼성)" related tweets&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;twython&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twython&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;settings&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;s&lt;/span&gt;    &lt;span class="c"&gt;# Create a file named settings.py, and put oauth KEY values inside&lt;/span&gt;
&lt;span class="n"&gt;twitter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twython&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;APP_KEY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;APP_SECRET&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OAUTH_TOKEN&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OAUTH_TOKEN_SECRET&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tweets&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;twitter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;삼성&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;user&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;screen_name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;created_at&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;statuses&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Text exploration&lt;/h2&gt;
&lt;h3&gt;1. Read document&lt;/h3&gt;
&lt;p&gt;As example documents, we select
&lt;a href="http://www.gutenberg.org/ebooks/158"&gt;Jane Austen's Emma&lt;/a&gt; for English,
and &lt;a href="http://pokr.kr/bill/1809890"&gt;Korea National Assembly's bill number 1809890&lt;/a&gt; for Korean.
Otherwise, you can use a document of your own with &lt;code&gt;open('some_file.txt').read()&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;gutenberg&lt;/span&gt;   &lt;span class="c"&gt;# Docs from project gutenberg.org&lt;/span&gt;
&lt;span class="n"&gt;files_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gutenberg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;      &lt;span class="c"&gt;# Get file ids&lt;/span&gt;
&lt;span class="n"&gt;doc_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gutenberg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;austen-emma.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;    &lt;span class="c"&gt;# Docs from pokr.kr/bill&lt;/span&gt;
&lt;span class="n"&gt;files_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;         &lt;span class="c"&gt;# Get file ids&lt;/span&gt;
&lt;span class="n"&gt;doc_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;1809890.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2. Tokenize&lt;/h3&gt;
&lt;p&gt;There are numerous ways to tokenize a document.&lt;/p&gt;
&lt;p&gt;Here, we use &lt;code&gt;nltk.regexp_tokenize&lt;/code&gt; for English,
&lt;code&gt;konlpy.tag.Twitter.morph&lt;/code&gt; for Korean text.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;regexp_tokenize&lt;/span&gt;
&lt;span class="n"&gt;pattern&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;r&amp;#39;&amp;#39;&amp;#39;(?x) ([A-Z]\.)+ | \w+(-\w+)* | \$?\d+(\.\d+)?%? | \.\.\. | [][.,;&amp;quot;&amp;#39;?():-_`]&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;tokens_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;regexp_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pattern&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.tag&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;tokens_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;morphs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;3. Load tokens with &lt;code&gt;nltk.Text()&lt;/code&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt;
&lt;span class="n"&gt;en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt;
&lt;span class="n"&gt;ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;대한민국 국회 의안 제 1809890호&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c"&gt;# For Python 2, input `name` as u&amp;#39;유니코드&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;nltk.Text()&lt;/code&gt; is a convenient way to explore a current document.
For Python 2, &lt;code&gt;name&lt;/code&gt; has to be input as u'유니코드'.
If you are using Python 2, use u'유니코드' for input of all following Korean text.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Tokens&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;       &lt;span class="c"&gt;# returns number of tokens (document length)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;  &lt;span class="c"&gt;# returns number of unique tokens&lt;/span&gt;
&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;                  &lt;span class="c"&gt;# returns frequency distribution&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
191061
7927
FreqDist({',': 12018, '.': 8853, 'to': 5127, 'the': 4844, 'and': 4653, 'of': 4278, '"': 4187, 'I': 3177, 'a': 3000, 'was': 2385, ...})
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;       &lt;span class="c"&gt;# returns number of tokens (document length)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;  &lt;span class="c"&gt;# returns number of unique tokens&lt;/span&gt;
&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;                  &lt;span class="c"&gt;# returns frequency distribution&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
1707
476
FreqDist({'.': 61, '의': 46, '육아휴직': 38, '을': 34, '(': 27, ',': 26, '이': 26, ')': 26, '에': 24, '자': 24, ...})
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Plot frequency distributions&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;     &lt;span class="c"&gt;# Plot sorted frequency of top 50 tokens&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/fdist_en.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;     &lt;span class="c"&gt;# Plot sorted frequency of top 50 tokens&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/fdist_ko.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: To save a plot programmably, and not through the GUI, overwrite &lt;code&gt;pylab.show&lt;/code&gt; with &lt;code&gt;pylab.savefig&lt;/code&gt; before drawing the plot (&lt;a href="http://stackoverflow.com/questions/27392390/how-do-i-send-nltk-plots-to-files"&gt;reference&lt;/a&gt;):
&lt;pre&gt;
from matplotlib import pylab
pylab.show = lambda: pylab.savefig('some_filename.png')
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Troubleshooting&lt;/strong&gt;: For those who see rectangles instead of letters in the saved plot file, include the following configurations before drawing the plot:
&lt;pre&gt;
from matplotlib import font_manager, rc
font_fname = 'c:/windows/fonts/gulim.ttc'     # A font of your choice
font_name = font_manager.FontProperties(fname=font_fname).get_name()
rc('font', family=font_name)
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;Some example fonts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mac OS: &lt;code&gt;/Library/Fonts/AppleGothic.ttf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Count&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;        &lt;span class="c"&gt;# Counts occurrences&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
865
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;초등학교&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c"&gt;# Counts occurrences&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
6
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dispersion plot&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dispersion_plot&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Frank&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Jane&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/disp_en.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dispersion_plot&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;육아휴직&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;초등학교&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;공무원&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/disp_ko.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Concordance&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concordance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lines&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
Displaying 5 of 865 matches:
                                     Emma by Jane Austen 1816 ] VOLUME I CHAPT
                                     Emma Woodhouse , handsome , clever , and 
both daughters , but particularly of Emma . Between &lt;em&gt;them&lt;/em&gt; it was more the int
 friend very mutually attached , and Emma doing just what she liked ; highly e
r own . The real evils , indeed , of Emma ' s situation were the power of havi
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean (or, use &lt;a href="http://konlpy.org/en/v0.4.3/api/konlpy/#konlpy.utils.concordance"&gt;konlpy.utils.concordance&lt;/a&gt;)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concordance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;초등학교&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
Displaying 6 of 6 matches:
 ․ 김정훈 김학송 의원 ( 10 인 ) 제안 이유 및 주요 내용 초등학교 저학년 의 경우 에도 부모 의 따뜻한 사랑 과 보살핌 이 필요 한
 을 할 수 있는 자녀 의 나이 는 만 6 세 이하 로 되어 있어 초등학교 저학년 인 자녀 를 돌보기 위해서 는 해당 부모님 은 일자리 를 
 다 . 제 63 조제 2 항제 4 호 중 “ 만 6 세 이하 의 초등학교 취학 전 자녀 를 ” 을 “ 만 8 세 이하 ( 취학 중인 경우 
 전 자녀 를 ” 을 “ 만 8 세 이하 ( 취학 중인 경우 에는 초등학교 2 학년 이하 를 말한 다 ) 의 자녀 를 ” 로 한 다 . 부 
 . ∼ 3 . ( 현행 과 같 음 ) 4 . 만 6 세 이하 의 초등학교 취 4 . 만 8 세 이하 ( 취학 중인 경우 학 전 자녀 를 양
세 이하 ( 취학 중인 경우 학 전 자녀 를 양육 하기 위하 에는 초등학교 2 학년 이하 를 여 필요하거 나 여자 공무원 이 말한 다 ) 의
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find similar words&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Frank&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
she it he i harriet you her jane him that me and all they them there herself was hartfield be
mr mrs emma harriet you it her she he him hartfield them jane that isabella all herself look i me
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;자녀&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;육아휴직&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
논의
None
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Collocations&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;collocations&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
Frank Churchill; Miss Woodhouse; Miss Bates; Jane Fairfax; Miss
Fairfax; every thing; young man; every body; great deal; dare say;
John Knightley; Maple Grove; Miss Smith; Miss Taylor; Robert Martin;
Colonel Campbell; Box Hill; said Emma; Harriet Smith; William Larkins
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;collocations&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
초등학교 저학년; 육아휴직 대상
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;!--
1. Common contexts
    - English

            :::python
            en.common_contexts(['Emma', 'Frank'])

        &lt;pre class="result"&gt;
        that_could that_s for_i and_and and_was between_and on_s of_s to_it in_s
        &lt;/pre&gt;

    - Korean

            :::python
            ko.common_contexts(['육아휴직'])

        &lt;pre class="result"&gt;
        따라서_이 에서_급 p_대상자 받는_자 경우_급여 으로_기간 n_급 위하여_을 인_자 대비하여_자 와_자 따라_신청 표_급여
        에게_자 에는_자 근로자_가능 평균_급여 이며_에 에_자 가_을
        &lt;/pre&gt;
--&gt;

&lt;p&gt;For more information on &lt;code&gt;nltk.Text()&lt;/code&gt;, see the &lt;a href="http://www.nltk.org/_modules/nltk/text.html#Text"&gt;source code&lt;/a&gt; or &lt;a href="http://www.nltk.org/api/nltk.html#nltk.text.Text"&gt;API&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Tagging and chunking&lt;/h2&gt;
&lt;p&gt;Until now, we used delimited text, namely &lt;em&gt;tokens&lt;/em&gt;, to explore our sample document.
Now let's classify words into given classes, namely &lt;em&gt;part-of-speech tags&lt;/em&gt;, and chunk text into larger pieces.&lt;/p&gt;
&lt;h3&gt;1. POS tagging&lt;/h3&gt;
&lt;p&gt;There are numerous ways of tagging a text.
Among them, the most frequently used, and developed way of tagging is arguably POS tagging.&lt;/p&gt;
&lt;p&gt;Since one document is too long to observe a parsed structure,
lets use one short sentence for each language.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;The little yellow dog barked at the Persian cat&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;tags_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[('The', 'DT'),
 ('little', 'JJ'),
 ('yellow', 'NN'),
 ('dog', 'NN'),
 ('barked', 'VBD'),
 ('at', 'IN'),
 ('the', 'DT'),
 ('Persian', 'NNP'),
 ('cat', 'NN')]
&lt;/pre&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is also possible to use the famous &lt;a href="http://www.nltk.org/api/nltk.tag.html#module-nltk.tag.stanford"&gt;Stanford POS tagger with NLTK&lt;/a&gt;, with &lt;code&gt;from nltk.tag.stanford import POSTagger&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.tag&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;tags_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;작고 노란 강아지가 페르시안 고양이에게 짖었다&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[('작고', 'Noun'),
 ('노란', 'Adjective'),
 ('강아지', 'Noun'),
 ('가', 'Josa'),
 ('페르시안', 'Noun'),
 ('고양이', 'Noun'),
 ('에게', 'Josa'),
 ('짖었', 'Noun'),
 ('다', 'Josa')]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2. Noun phrase chunking&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.nltk.org/api/nltk.chunk.html#nltk.chunk.regexp.RegexpParser"&gt;&lt;code&gt;nltk.RegexpParser()&lt;/code&gt;&lt;/a&gt; is a great way to start chunking.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;parser_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RegexpParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;NP: {&amp;lt;DT&amp;gt;?&amp;lt;JJ&amp;gt;?&amp;lt;NN.*&amp;gt;*}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tags_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;draw&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/tree_en.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;parser_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RegexpParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;NP: {&amp;lt;Adjective&amp;gt;*&amp;lt;Noun&amp;gt;*}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tags_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;draw&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/tree_ko.png" width="700px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information on chunking, refer to &lt;a href="http://www.nltk.org/book/ch07.html"&gt;Extracting Information from Text&lt;/a&gt; for English, and &lt;a href="http://konlpy.org/en/v0.4.3/examples/chunking/"&gt;Chunking&lt;/a&gt; for Korean.&lt;/p&gt;
&lt;h2&gt;Topic modeling&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Topic modeling in a nutshell&lt;br&gt;
    &lt;img src="images/topic-modeling.png" width="600px"&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;History&lt;br&gt;
    &lt;img src="images/tm-history.png" width="600px"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LSI: Learns latent topics by performing a matrix decomposition (SVD) on the term-document matrix&lt;/li&gt;
&lt;li&gt;LDA: A generative probabilistic model, that assumes a Dirichelt prior over the latent topics&lt;/li&gt;
&lt;li&gt;HDP: A natural nonparametric generalization of LDA, where the number of topics can be unbounded ant learnt from data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;1. Preprocessing&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Load documents&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;reuters&lt;/span&gt;
&lt;span class="n"&gt;docs_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;reuters&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;reuters&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;
&lt;span class="n"&gt;docs_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tokenize&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;docs_en&lt;/span&gt; &lt;span class="c"&gt;# because we loaded tokenized documents in step 1&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', ...]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.tag&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;pos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stem&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;norm&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;texts_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;docs_ko&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['지방공무원법/Noun', '일부/Noun', '개정/Noun', '법률/Noun', '안/Noun', '(/Punctuation', '정의화/Noun', '의원/Noun', ...]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Encode tokens to integers&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gensim&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;corpora&lt;/span&gt;
&lt;span class="n"&gt;dictionary_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;corpora&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dictionary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;en.dict&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# save dictionary to file for future use&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gensim&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;corpora&lt;/span&gt;
&lt;span class="n"&gt;dictionary_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;corpora&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dictionary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ko.dict&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# save dictionary to file for future use&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Calculate TF-IDF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gensim&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;
&lt;span class="n"&gt;tf_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;doc2bow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;texts_en&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;tfidf_model_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TfidfModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tfidf_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_model_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tf_en&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;corpora&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MmCorpus&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;serialize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;en.mm&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tfidf_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c"&gt;# save corpus to file for future use&lt;/span&gt;

&lt;span class="c"&gt;# print first 10 elements of first document&amp;#39;s tf-idf vector&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="c"&gt;# print top 10 elements of first document&amp;#39;s tf-idf vector&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="c"&gt;# print token of most frequent element&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[(0, 7), (1, 3), (2, 13), (3, 2), (4, 1), (5, 1), (6, 20), (7, 6), (8, 10), (9, 62)]
[(9, 62), (363, 32), (276, 30), (371, 26), (6, 20), (96, 19), (112, 19), (326, 16), (118, 14), (2, 13)]
'.'
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gensim&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;
&lt;span class="n"&gt;tf_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;doc2bow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;texts_ko&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;tfidf_model_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TfidfModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tfidf_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_model_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tf_ko&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;corpora&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MmCorpus&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;serialize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ko.mm&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tfidf_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c"&gt;# save corpus to file for future use&lt;/span&gt;

&lt;span class="c"&gt;# print first 10 elements of first document&amp;#39;s tf-idf vector&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="c"&gt;# print top 10 elements of first document&amp;#39;s tf-idf vector&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="c"&gt;# print token of most frequent element&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;414&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[(0, 10), (1, 27), (2, 1), (3, 26), (4, 3), (5, 26), (6, 4), (7, 2), (8, 1), (9, 1)]
[(414, 71), (14, 61), (309, 38), (314, 38), (313, 28), (1, 27), (3, 26), (5, 26), (353, 22), (13, 21)]
'하다/Verb'
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;2. Train topic models&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;LSI&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nwords&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;lsi_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lsimodel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LsiModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id2word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lsi_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_topics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nwords&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['0.509*"vs" + 0.272*"000" + 0.258*"cts" + 0.243*"loss" + 0.238*"mln"',
'-0.294*"the" + 0.237*"vs" + -0.176*"to" + -0.148*"in" + -0.137*"pct"',
'0.331*"Record" + 0.316*"div" + 0.312*"Pay" + 0.303*"Qtly" + 0.268*"prior"']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nwords&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;lsi_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lsimodel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LsiModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id2word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lsi_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_topics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nwords&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['0.518*"육아휴직/Noun" + 0.257*"만/Noun" + 0.227*"×/Foreign" + 0.214*"대체/Noun" + 0.201*"고용/Noun"',
 '0.449*"파견/Noun" + 0.412*"부대/Noun" + 0.267*"UAE/Alpha" + 0.243*"○/Foreign" + 0.192*"국군/Noun"',
 '0.326*"결혼/Noun" + 0.315*"예고/Noun" + 0.285*"손해/Noun" + 0.205*"ㆍ/Foreign" + 0.197*"원사/Noun"']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LDA&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# optional&lt;/span&gt;
&lt;span class="n"&gt;lda_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ldamodel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LdaModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id2word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lda_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_topics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nwords&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['0.005*the + 0.003*to + 0.003*pct + 0.002*of + 0.002*said',
 '0.005*cts + 0.005*Record + 0.005*div + 0.004*Pay + 0.004*Qtly',
 '0.010*vs + 0.006*mln + 0.006*000 + 0.005*loss + 0.004*cts']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# optional&lt;/span&gt;
&lt;span class="n"&gt;lda_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ldamodel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LdaModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id2word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lda_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_topics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nwords&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['0.001*학위/Noun + 0.001*파견/Noun + 0.001*손해/Noun + 0.001*간호/Noun + 0.001*소말리아/Noun',
 '0.002*파견/Noun + 0.002*부대/Noun + 0.001*UAE/Alpha + 0.001*손해/Noun + 0.001*○/Foreign',
 '0.003*육아휴직/Noun + 0.002*만/Noun + 0.002*×/Foreign + 0.002*대체/Noun + 0.002*고용/Noun']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;HDP&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# optional&lt;/span&gt;
&lt;span class="n"&gt;hdp_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hdpmodel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HdpModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id2word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hdp_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_topics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;topn&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nwords&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['topic 0: 0.005*the + 0.003*to + 0.002*in + 0.002*a + 0.002*of',
 'topic 1: 0.008*vs + 0.005*000 + 0.004*loss + 0.004*mln + 0.004*cts',
 'topic 2: 0.001*the + 0.001*vs + 0.001*in + 0.001*to + 0.001*mln']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# optional&lt;/span&gt;
&lt;span class="n"&gt;hdp_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hdpmodel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HdpModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id2word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hdp_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_topics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;topn&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nwords&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['topic 0: 0.004*소집/Noun + 0.004*도/Josa + 0.004*’/Foreign + 0.004*｢/Foreign + 0.004*9892/Number',
 'topic 1: 0.004*이애주/Noun + 0.004*年/Foreign + 0.004*意思/Foreign + 0.004*마찰/Noun + 0.004*고 려/Noun',
 'topic 2: 0.005*명시/Noun + 0.004*영업정지/Noun + 0.004*세로/Noun + 0.004*중개업/Noun + 0.004*다양하다/Adjective']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;3. Scoring documents&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;bow&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_model_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;doc2bow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lsi_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lda_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hdp_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[(0, 0.1336800876240628),
 (2, -0.030832981664564624),
 (1, -0.39895210562646022)]&lt;/p&gt;
&lt;p&gt;[(2, 0.84087091284115845),
 (0, 0.13882114432084294),
 (1, 0.020307942837998694)]&lt;/p&gt;
&lt;p&gt;[(0, 0.95369717052959579)]
&lt;/pre&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;bow&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_model_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;doc2bow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lsi_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lda_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hdp_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[(0, 0.072924758682943097),
 (2, -0.0029545572070390153),
 (1, -0.13195370933374836)]&lt;/p&gt;
&lt;p&gt;[(0, 0.62957273636869904),
 (2, 0.3270007771486681),
 (1, 0.043426486482632851)]&lt;/p&gt;
&lt;p&gt;[(0, 0.90574410236561731),
 (1, 0.010409702375525492)]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;bow&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_model_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;doc2bow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lsi_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lda_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hdp_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[(0, 0.97829017893328929),
 (1, -0.016909513239922121),
 (2, -0.020121561014425089)]&lt;/p&gt;
&lt;p&gt;[(2, 0.93880436704581616),
 (0, 0.030626827732744354),
 (1, 0.030568805221439507)]&lt;/p&gt;
&lt;p&gt;[(0, 0.94848723192042672),
 (1, 0.014364056233061516),
 (2, 0.010285449586192942)]
&lt;/pre&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;bow&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_model_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;doc2bow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lsi_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lda_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hdp_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[(0, 0.97829017893328929),
 (1, -0.016909513239922121),
 (2, -0.020121561014425089)]&lt;/p&gt;
&lt;p&gt;[(2, 0.93881674048370278),
 (0, 0.0306176131467021),
 (1, 0.030565646369595065)]&lt;/p&gt;
&lt;p&gt;[(0, 0.94848723192042672),
 (1, 0.014364056233061516),
 (2, 0.010285449586192942)]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- Add document/query similarities http://radimrehurek.com/gensim/tut3.html#similarity-interface --&gt;

&lt;blockquote&gt;
&lt;p&gt;Confident with topic modeling? Try a bigger dataset: &lt;a href="http://radimrehurek.com/gensim/wiki.html"&gt;Experiments on the English Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Word embedding&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Objective: Learn feature vectors from documents&lt;ul&gt;
&lt;li&gt;Text is normally represented with one-hot encoding + hand crafted features&lt;/li&gt;
&lt;li&gt;Ex: [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 ]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Word embedding&lt;/strong&gt;: A set of feature unsupervised learning techniques where words are mapped to n-dimensional vectors of real numbers (the continuous space)&lt;ul&gt;
&lt;li&gt;Use local context to get a more syntactic or semantic representation&lt;/li&gt;
&lt;li&gt;Ex: v("cat") = [0.2, -0.4, ..., 0.7], v("mat") = [-0.0, -0.2, ..., -0.1]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Approaches&lt;ul&gt;
&lt;li&gt;Neural networks (Bengio et al., 2001, Mikolov et al., 2013)&lt;/li&gt;
&lt;li&gt;Dimensionality reduction (Lebret et al., 2013)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;word2vec (Mikolov et al., 2013)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A neural network based embedding method for learning distributed vector representations of words&lt;ul&gt;
&lt;li&gt;No hidden layers!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;"an optimized single-machine  can train 100B+ words in one day"&lt;/li&gt;
&lt;li&gt;CBOW &amp;amp; Skip-gram: Two ways of creating the "task" for the neural network&lt;br&gt;
    &lt;img src="images/cbow-skip.png" width="600px"&gt;&lt;/li&gt;
&lt;li&gt;Characteristics&lt;ul&gt;
&lt;li&gt;Places similar words next to each other in a vector space&lt;/li&gt;
&lt;li&gt;Places similar relations in parallel (preserve linguistic regularities)&lt;ul&gt;
&lt;li&gt;ex: France: Paris = Germany: Berlin != Italy: Madrid&lt;br&gt;
    &lt;img src="images/countries.png" width="400px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Linguistic regularities&lt;ul&gt;
&lt;li&gt;v(KING) – v(MAN) + v(WOMAN) = v(QUEEN)&lt;/li&gt;
&lt;li&gt;v(KINGS) – v(KING) + v(QUEEN) = v(QUEENS)&lt;/li&gt;
&lt;li&gt;v(MADRID) – v(SPAIN) + v(FRANCE) = v(PARIS)&lt;/li&gt;
&lt;li&gt;&lt;img src="images/regularities.png" width="400px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Applications&lt;ul&gt;
&lt;li&gt;Machine translation (Socher et al., 2013)&lt;br&gt;
    &lt;img src="images/embedding-mt.png" width="400px"&gt;&lt;/li&gt;
&lt;li&gt;Jointly embedding images and text (Frome et al., 2013, &lt;a href="http://googleresearch.blogspot.co.uk/2014/11/a-picture-is-worth-thousand-coherent.html"&gt;link&lt;/a&gt;)&lt;br&gt;
    &lt;img src="images/google-text.png" width="600px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Some good references to begin with in case you are interested:&lt;ul&gt;
&lt;li&gt;http://radimrehurek.com/2014/02/word2vec-tutorial/&lt;/li&gt;
&lt;li&gt;http://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let's go for it.&lt;/p&gt;
&lt;h3&gt;word2vec toy problem&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Load documents&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;reuters&lt;/span&gt;
&lt;span class="n"&gt;docs_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;reuters&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;reuters&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;
&lt;span class="n"&gt;docs_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tokenize&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;docs_en&lt;/span&gt; &lt;span class="c"&gt;# because we loaded tokenized documents in step 1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.tag&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;pos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;texts_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;docs_ko&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Train&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gensim.models&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;word2vec&lt;/span&gt;
&lt;span class="n"&gt;wv_model_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;word2vec&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Word2Vec&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;wv_model_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;init_sims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;wv_model_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;en_word2vec.model&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gensim.models&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;word2vec&lt;/span&gt;
&lt;span class="n"&gt;wv_model_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;word2vec&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Word2Vec&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;wv_model_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;init_sims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;wv_model_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ko_word2vec.model&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Test&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;wv_model_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;president&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;wv_model_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;secretary&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;wv_model_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;country&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[('chairman', 0.8655247688293457),
 ('vice', 0.8160154819488525),
 ('executive', 0.8094440698623657),
 ('officer', 0.7894954085350037),
 ('Kjell', 0.7766541838645935),
 ('former', 0.7680522203445435),
 ('chief', 0.7660256028175354),
 ('Robert', 0.7623487114906311),
 ('director', 0.7434573173522949),
 ('Roger', 0.7231118679046631)]&lt;/p&gt;
&lt;p&gt;[('assistant', 0.8573123812675476),
 ('Carlos', 0.796258807182312),
 ('Daniel', 0.7900130748748779),
 ('undersecretary', 0.7888025045394897),
 ('representative', 0.7878221273422241),
 ('Deputy', 0.7847912311553955),
 ('NAWG', 0.7829214930534363),
 ('Republican', 0.7773356437683105),
 ('Greek', 0.7752739191055298),
 ('Papandreou', 0.7684933543205261)]&lt;/p&gt;
&lt;p&gt;[('kingdom', 0.8003361225128174),
 ('biggest', 0.765742301940918),
 ('island', 0.7639101147651672),
 ('founding', 0.7143765687942505),
 ('nation', 0.7080289125442505),
 ('fortunes', 0.7054018974304199),
 ('strength', 0.6875098943710327),
 ('challenging', 0.6863174438476562),
 ('actions', 0.6835225820541382),
 ('departure', 0.6834459900856018)]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;wv_model_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;정부&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;wv_model_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;초등학교&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[('경비/Noun', 0.9357226490974426),
 ('선박/Noun', 0.9204540252685547),
 ('연장/Noun', 0.9183653593063354),
 ('임무/Noun', 0.9179578423500061),
 ('우리/Noun', 0.9015840291976929),
 ('목적/Noun', 0.8871368169784546),
 ('기타/Noun', 0.875058650970459),
 ('화/Suffix', 0.8669425249099731),
 ('해역/Noun', 0.8575668334960938),
 ('한국/Noun', 0.8549510836601257)]&lt;/p&gt;
&lt;p&gt;[('취학/Noun', 0.9686248898506165),
 ('중인/Noun', 0.9336546659469604),
 ('하더/Verb', 0.8985729217529297),
 ('정의화/Noun', 0.8843945860862732),
 ('김정훈/Noun', 0.8682949542999268),
 ('지방/Noun', 0.8677719831466675),
 ('조정함/Verb', 0.8617256879806519),
 ('44/Number', 0.8445801734924316),
 ('세/Noun', 0.8318654298782349),
 ('第/Foreign', 0.8222816586494446)]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;word2vec in the real world&lt;/h3&gt;
&lt;p&gt;Not enough? Let's see a real life example.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data source: Naver News &amp;amp; Naver blog&lt;br&gt;
    &lt;img src="images/experiment.png" width="500px"&gt;&lt;/li&gt;
&lt;li&gt;Questions&lt;br&gt;
    &lt;img src="images/questions.png" width="500px"&gt;&lt;/li&gt;
&lt;li&gt;Matching pairs: 그/Noun:남자/Noun = 그녀/Noun:?&lt;br&gt;
    &lt;img src="images/pairs.png" width="500px"&gt;&lt;/li&gt;
&lt;li&gt;Visualization&lt;br&gt;
    &lt;img src="images/tsne1.png" width="600px"&gt;&lt;br&gt;
    &lt;img src="images/tsne2.png" width="600px"&gt;&lt;br&gt;
    &lt;img src="images/tsne3.png" width="600px"&gt;&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!--

## Text classification
### Sentiment analysis
- https://github.com/nltk/nltk/wiki/Sentiment-Analysis

## Machine translation
- http://www.statmt.org/

## Deep learning
- https://github.com/nltk/nltk/wiki/Installing-Third-Party-Software#senna-for-various-nlp-tasks
    - http://ml.nec-labs.com/senna/
--&gt;</summary><category term="text"></category><category term="lectures"></category></entry><entry><title>Mining English and Korean text with Python</title><link href="http://lucypark.kr/courses/2015-ba/text-mining.html" rel="alternate"></link><updated>2015-03-27T15:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-27:courses/2015-ba/text-mining.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;We use Python 3 in this tutorial, but provide minimal guidelines for Python 2.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Terminologies&lt;/h2&gt;
&lt;p&gt;&lt;table class="table"&gt;&lt;tr&gt;&lt;th&gt;English&lt;/th&gt;&lt;th&gt;한국어&lt;/th&gt;&lt;th&gt;Description&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Document&lt;/td&gt;&lt;td&gt;문서&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Corpus&lt;/td&gt;&lt;td&gt;말뭉치&lt;/td&gt;&lt;td&gt;A set of documents&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Token&lt;/td&gt;&lt;td&gt;토큰&lt;/td&gt;&lt;td&gt;Meaningful elements in a text such as words or phrases or symbols&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Morphemes&lt;/td&gt;&lt;td&gt;형태소&lt;/td&gt;&lt;td&gt;Smallest meaningful unit in a language&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;POS&lt;/td&gt;&lt;td&gt;품사&lt;/td&gt;&lt;td&gt;Part-of-speech (ex: Nouns)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Classification&lt;/td&gt;&lt;td&gt;분류&lt;/td&gt;&lt;td&gt;A supervised learning task where $X$ and $y$ are given and $y$ is a set of discrete classes&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Clustering&lt;/td&gt;&lt;td&gt;군집화&lt;/td&gt;&lt;td&gt;An unsupervised learning task where $X$ is given&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/p&gt;
&lt;h2&gt;Text analysis process&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Load text&lt;/li&gt;
&lt;li&gt;Tokenize text (ex: stemming, morph analyzing)&lt;/li&gt;
&lt;li&gt;Tag tokens (ex: POS, NER)&lt;/li&gt;
&lt;li&gt;Token(Feature) selection and/or filter/rank tokens (ex: stopword removal, TF-IDF)&lt;/li&gt;
&lt;li&gt;...and so on (ex: calculate word/document similarities, cluster documents)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Python Packages for Text Mining and NLP&lt;/h2&gt;
&lt;p&gt;...that we use in this tutorial.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nltk.org"&gt;NLTK&lt;/a&gt;: Provides modules for text analysis (mostly language independent)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pip install nltk
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.nltk.org/book/ch02.html"&gt;Text corpora&lt;/a&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gutenberg&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;maxent_treebank_pos_tagger&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.nltk.org/api/nltk.tag.html"&gt;Word POS, NER classification&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.nltk.org/book/ch06.html"&gt;Document classification&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://konlpy.org"&gt;KoNLPy&lt;/a&gt;: Provides modules for Korean text analysis&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pip install konlpy
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;&lt;a href="http://konlpy.org/en/latest/data/#corpora"&gt;Text corpora&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://konlpy.org/en/latest/api/konlpy.tag/"&gt;Word POS classification&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Hannanum&lt;/li&gt;
&lt;li&gt;Kkma&lt;/li&gt;
&lt;li&gt;Mecab&lt;/li&gt;
&lt;li&gt;Komoran&lt;/li&gt;
&lt;li&gt;Twitter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http//radimrehurek.com/gensim/"&gt;Gensim&lt;/a&gt;: Provides modules for topic modeling and calculating similarities among documents&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pip install -U gensim
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Topic modeling&lt;ul&gt;
&lt;li&gt;&lt;a href="http://radimrehurek.com/gensim/models/ldamodel.html"&gt;Latent Dirichlet allocation (LDA)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://radimrehurek.com/gensim/models/lsimodel.html"&gt;Latent semantic indexing (LSI)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://radimrehurek.com/gensim/models/hdpmodel.html"&gt;Hierarchical Dirichlet process (HDP)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Word embedding&lt;ul&gt;
&lt;li&gt;&lt;a href="radimrehurek.com/gensim/models/word2vec.html"&gt;word2vec&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/ryanmcgrath/twython"&gt;Twython&lt;/a&gt;: Provides easy access to Twitter API&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pip install twython
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Example: Getting "Samsung (삼성)" related tweets&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;twython&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twython&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;settings&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;s&lt;/span&gt;    &lt;span class="c"&gt;# Create a file named settings.py, and put oauth KEY values inside&lt;/span&gt;
&lt;span class="n"&gt;twitter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twython&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;APP_KEY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;APP_SECRET&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OAUTH_TOKEN&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OAUTH_TOKEN_SECRET&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tweets&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;twitter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;삼성&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;user&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;screen_name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;created_at&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;statuses&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Text exploration&lt;/h2&gt;
&lt;h3&gt;1. Read document&lt;/h3&gt;
&lt;p&gt;As example documents, we select
&lt;a href="http://www.gutenberg.org/ebooks/158"&gt;Jane Austen's Emma&lt;/a&gt; for English,
and &lt;a href="http://pokr.kr/bill/1809890"&gt;Korea National Assembly's bill number 1809890&lt;/a&gt; for Korean.
Otherwise, you can use a document of your own with &lt;code&gt;open('some_file.txt').read()&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;gutenberg&lt;/span&gt;   &lt;span class="c"&gt;# Docs from project gutenberg.org&lt;/span&gt;
&lt;span class="n"&gt;files_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gutenberg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;      &lt;span class="c"&gt;# Get file ids&lt;/span&gt;
&lt;span class="n"&gt;doc_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gutenberg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;austen-emma.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;    &lt;span class="c"&gt;# Docs from pokr.kr/bill&lt;/span&gt;
&lt;span class="n"&gt;files_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;         &lt;span class="c"&gt;# Get file ids&lt;/span&gt;
&lt;span class="n"&gt;doc_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;1809890.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2. Tokenize&lt;/h3&gt;
&lt;p&gt;There are numerous ways to tokenize a document.&lt;/p&gt;
&lt;p&gt;Here, we use &lt;code&gt;nltk.regexp_tokenize&lt;/code&gt; for English,
&lt;code&gt;konlpy.tag.Twitter.morph&lt;/code&gt; for Korean text.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;regexp_tokenize&lt;/span&gt;
&lt;span class="n"&gt;pattern&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;r&amp;#39;&amp;#39;&amp;#39;(?x) ([A-Z]\.)+ | \w+(-\w+)* | \$?\d+(\.\d+)?%? | \.\.\. | [][.,;&amp;quot;&amp;#39;?():-_`]&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;tokens_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;regexp_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pattern&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.tag&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;tokens_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;morphs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;3. Load tokens with &lt;code&gt;nltk.Text()&lt;/code&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt;
&lt;span class="n"&gt;en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt;
&lt;span class="n"&gt;ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;대한민국 국회 의안 제 1809890호&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c"&gt;# For Python 2, input `name` as u&amp;#39;유니코드&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;nltk.Text()&lt;/code&gt; is a convenient way to explore a current document.
For Python 2, &lt;code&gt;name&lt;/code&gt; has to be input as u'유니코드'.
If you are using Python 2, use u'유니코드' for input of all following Korean text.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Tokens&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;       &lt;span class="c"&gt;# returns number of tokens (document length)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;  &lt;span class="c"&gt;# returns number of unique tokens&lt;/span&gt;
&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;                  &lt;span class="c"&gt;# returns frequency distribution&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
191061
7927
FreqDist({',': 12018, '.': 8853, 'to': 5127, 'the': 4844, 'and': 4653, 'of': 4278, '"': 4187, 'I': 3177, 'a': 3000, 'was': 2385, ...})
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;       &lt;span class="c"&gt;# returns number of tokens (document length)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;  &lt;span class="c"&gt;# returns number of unique tokens&lt;/span&gt;
&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;                  &lt;span class="c"&gt;# returns frequency distribution&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
1707
476
FreqDist({'.': 61, '의': 46, '육아휴직': 38, '을': 34, '(': 27, ',': 26, '이': 26, ')': 26, '에': 24, '자': 24, ...})
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Plot frequency distributions&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;     &lt;span class="c"&gt;# Plot sorted frequency of top 50 tokens&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/fdist_en.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;     &lt;span class="c"&gt;# Plot sorted frequency of top 50 tokens&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/fdist_ko.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: To save a plot programmably, and not through the GUI, overwrite &lt;code&gt;pylab.show&lt;/code&gt; with &lt;code&gt;pylab.savefig&lt;/code&gt; before drawing the plot (&lt;a href="http://stackoverflow.com/questions/27392390/how-do-i-send-nltk-plots-to-files"&gt;reference&lt;/a&gt;):
&lt;pre&gt;
from matplotlib import pylab
pylab.show = lambda: pylab.savefig('some_filename.png')
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Troubleshooting&lt;/strong&gt;: For those who see rectangles instead of letters in the saved plot file, include the following configurations before drawing the plot:
&lt;pre&gt;
from matplotlib import font_manager, rc
font_fname = 'c:/windows/fonts/gulim.ttc'     # A font of your choice
font_name = font_manager.FontProperties(fname=font_fname).get_name()
rc('font', family=font_name)
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;Some example fonts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mac OS: &lt;code&gt;/Library/Fonts/AppleGothic.ttf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Count&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;        &lt;span class="c"&gt;# Counts occurrences&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
865
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;초등학교&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c"&gt;# Counts occurrences&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
6
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dispersion plot&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dispersion_plot&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Frank&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Jane&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/disp_en.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dispersion_plot&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;육아휴직&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;초등학교&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;공무원&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/disp_ko.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Concordance&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concordance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lines&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
Displaying 5 of 865 matches:
                                     Emma by Jane Austen 1816 ] VOLUME I CHAPT
                                     Emma Woodhouse , handsome , clever , and 
both daughters , but particularly of Emma . Between &lt;em&gt;them&lt;/em&gt; it was more the int
 friend very mutually attached , and Emma doing just what she liked ; highly e
r own . The real evils , indeed , of Emma ' s situation were the power of havi
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean (or, use &lt;a href="http://konlpy.org/en/v0.4.3/api/konlpy/#konlpy.utils.concordance"&gt;konlpy.utils.concordance&lt;/a&gt;)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concordance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;초등학교&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
Displaying 6 of 6 matches:
 ․ 김정훈 김학송 의원 ( 10 인 ) 제안 이유 및 주요 내용 초등학교 저학년 의 경우 에도 부모 의 따뜻한 사랑 과 보살핌 이 필요 한
 을 할 수 있는 자녀 의 나이 는 만 6 세 이하 로 되어 있어 초등학교 저학년 인 자녀 를 돌보기 위해서 는 해당 부모님 은 일자리 를 
 다 . 제 63 조제 2 항제 4 호 중 “ 만 6 세 이하 의 초등학교 취학 전 자녀 를 ” 을 “ 만 8 세 이하 ( 취학 중인 경우 
 전 자녀 를 ” 을 “ 만 8 세 이하 ( 취학 중인 경우 에는 초등학교 2 학년 이하 를 말한 다 ) 의 자녀 를 ” 로 한 다 . 부 
 . ∼ 3 . ( 현행 과 같 음 ) 4 . 만 6 세 이하 의 초등학교 취 4 . 만 8 세 이하 ( 취학 중인 경우 학 전 자녀 를 양
세 이하 ( 취학 중인 경우 학 전 자녀 를 양육 하기 위하 에는 초등학교 2 학년 이하 를 여 필요하거 나 여자 공무원 이 말한 다 ) 의
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find similar words&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Frank&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
she it he i harriet you her jane him that me and all they them there herself was hartfield be
mr mrs emma harriet you it her she he him hartfield them jane that isabella all herself look i me
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;자녀&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;육아휴직&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
논의
None
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Collocations&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;collocations&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
Frank Churchill; Miss Woodhouse; Miss Bates; Jane Fairfax; Miss
Fairfax; every thing; young man; every body; great deal; dare say;
John Knightley; Maple Grove; Miss Smith; Miss Taylor; Robert Martin;
Colonel Campbell; Box Hill; said Emma; Harriet Smith; William Larkins
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;collocations&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
초등학교 저학년; 육아휴직 대상
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;!--
1. Common contexts
    - English

            :::python
            en.common_contexts(['Emma', 'Frank'])

        &lt;pre class="result"&gt;
        that_could that_s for_i and_and and_was between_and on_s of_s to_it in_s
        &lt;/pre&gt;

    - Korean

            :::python
            ko.common_contexts(['육아휴직'])

        &lt;pre class="result"&gt;
        따라서_이 에서_급 p_대상자 받는_자 경우_급여 으로_기간 n_급 위하여_을 인_자 대비하여_자 와_자 따라_신청 표_급여
        에게_자 에는_자 근로자_가능 평균_급여 이며_에 에_자 가_을
        &lt;/pre&gt;
--&gt;

&lt;p&gt;For more information on &lt;code&gt;nltk.Text()&lt;/code&gt;, see the &lt;a href="http://www.nltk.org/_modules/nltk/text.html#Text"&gt;source code&lt;/a&gt; or &lt;a href="http://www.nltk.org/api/nltk.html#nltk.text.Text"&gt;API&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Tagging and chunking&lt;/h2&gt;
&lt;p&gt;Until now, we used delimited text, namely &lt;em&gt;tokens&lt;/em&gt;, to explore our sample document.
Now let's classify words into given classes, namely &lt;em&gt;part-of-speech tags&lt;/em&gt;, and chunk text into larger pieces.&lt;/p&gt;
&lt;h3&gt;1. POS tagging&lt;/h3&gt;
&lt;p&gt;There are numerous ways of tagging a text.
Among them, the most frequently used, and developed way of tagging is arguably POS tagging.&lt;/p&gt;
&lt;p&gt;Since one document is too long to observe a parsed structure,
lets use one short sentence for each language.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;The little yellow dog barked at the Persian cat&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;tags_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[('The', 'DT'),
 ('little', 'JJ'),
 ('yellow', 'NN'),
 ('dog', 'NN'),
 ('barked', 'VBD'),
 ('at', 'IN'),
 ('the', 'DT'),
 ('Persian', 'NNP'),
 ('cat', 'NN')]
&lt;/pre&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is also possible to use the famous &lt;a href="http://www.nltk.org/api/nltk.tag.html#module-nltk.tag.stanford"&gt;Stanford POS tagger with NLTK&lt;/a&gt;, with &lt;code&gt;from nltk.tag.stanford import POSTagger&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.tag&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;tags_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;작고 노란 강아지가 페르시안 고양이에게 짖었다&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[('작고', 'Noun'),
 ('노란', 'Adjective'),
 ('강아지', 'Noun'),
 ('가', 'Josa'),
 ('페르시안', 'Noun'),
 ('고양이', 'Noun'),
 ('에게', 'Josa'),
 ('짖었', 'Noun'),
 ('다', 'Josa')]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2. Noun phrase chunking&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.nltk.org/api/nltk.chunk.html#nltk.chunk.regexp.RegexpParser"&gt;&lt;code&gt;nltk.RegexpParser()&lt;/code&gt;&lt;/a&gt; is a great way to start chunking.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;parser_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RegexpParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;NP: {&amp;lt;DT&amp;gt;?&amp;lt;JJ&amp;gt;?&amp;lt;NN.*&amp;gt;*}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tags_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;draw&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/tree_en.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;parser_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RegexpParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;NP: {&amp;lt;Adjective&amp;gt;*&amp;lt;Noun&amp;gt;*}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tags_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;draw&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/tree_ko.png" width="700px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information on chunking, refer to &lt;a href="http://www.nltk.org/book/ch07.html"&gt;Extracting Information from Text&lt;/a&gt; for English, and &lt;a href="http://konlpy.org/en/v0.4.3/examples/chunking/"&gt;Chunking&lt;/a&gt; for Korean.&lt;/p&gt;
&lt;h2&gt;Topic modeling&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Topic modeling in a nutshell&lt;br&gt;
    &lt;img src="images/topic-modeling.png" width="600px"&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;History&lt;br&gt;
    &lt;img src="images/tm-history.png" width="600px"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LSI: Learns latent topics by performing a matrix decomposition (SVD) on the term-document matrix&lt;/li&gt;
&lt;li&gt;LDA: A generative probabilistic model, that assumes a Dirichelt prior over the latent topics&lt;/li&gt;
&lt;li&gt;HDP: A natural nonparametric generalization of LDA, where the number of topics can be unbounded ant learnt from data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;1. Preprocessing&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Load documents&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;reuters&lt;/span&gt;
&lt;span class="n"&gt;docs_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;reuters&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;reuters&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;
&lt;span class="n"&gt;docs_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tokenize&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;docs_en&lt;/span&gt; &lt;span class="c"&gt;# because we loaded tokenized documents in step 1&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', ...]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.tag&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;pos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stem&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;norm&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;texts_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;docs_ko&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['지방공무원법/Noun', '일부/Noun', '개정/Noun', '법률/Noun', '안/Noun', '(/Punctuation', '정의화/Noun', '의원/Noun', ...]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Encode tokens to integers&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gensim&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;corpora&lt;/span&gt;
&lt;span class="n"&gt;dictionary_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;corpora&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dictionary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;en.dict&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# save dictionary to file for future use&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gensim&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;corpora&lt;/span&gt;
&lt;span class="n"&gt;dictionary_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;corpora&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dictionary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ko.dict&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# save dictionary to file for future use&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Calculate TF-IDF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gensim&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;
&lt;span class="n"&gt;tf_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;doc2bow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;texts_en&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;tfidf_model_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TfidfModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tfidf_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_model_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tf_en&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;corpora&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MmCorpus&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;serialize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;en.mm&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tfidf_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c"&gt;# save corpus to file for future use&lt;/span&gt;

&lt;span class="c"&gt;# print first 10 elements of first document&amp;#39;s tf-idf vector&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="c"&gt;# print top 10 elements of first document&amp;#39;s tf-idf vector&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="c"&gt;# print token of most frequent element&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[(0, 7), (1, 3), (2, 13), (3, 2), (4, 1), (5, 1), (6, 20), (7, 6), (8, 10), (9, 62)]
[(9, 62), (363, 32), (276, 30), (371, 26), (6, 20), (96, 19), (112, 19), (326, 16), (118, 14), (2, 13)]
'.'
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gensim&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;
&lt;span class="n"&gt;tf_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;doc2bow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;texts_ko&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;tfidf_model_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TfidfModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tfidf_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_model_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tf_ko&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;corpora&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MmCorpus&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;serialize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ko.mm&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tfidf_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c"&gt;# save corpus to file for future use&lt;/span&gt;

&lt;span class="c"&gt;# print first 10 elements of first document&amp;#39;s tf-idf vector&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="c"&gt;# print top 10 elements of first document&amp;#39;s tf-idf vector&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="c"&gt;# print token of most frequent element&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;414&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[(0, 10), (1, 27), (2, 1), (3, 26), (4, 3), (5, 26), (6, 4), (7, 2), (8, 1), (9, 1)]
[(414, 71), (14, 61), (309, 38), (314, 38), (313, 28), (1, 27), (3, 26), (5, 26), (353, 22), (13, 21)]
'하다/Verb'
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;2. Train topic models&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;LSI&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nwords&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;lsi_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lsimodel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LsiModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id2word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lsi_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_topics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nwords&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['0.509*"vs" + 0.272*"000" + 0.258*"cts" + 0.243*"loss" + 0.238*"mln"',
'-0.294*"the" + 0.237*"vs" + -0.176*"to" + -0.148*"in" + -0.137*"pct"',
'0.331*"Record" + 0.316*"div" + 0.312*"Pay" + 0.303*"Qtly" + 0.268*"prior"']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nwords&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;lsi_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lsimodel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LsiModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id2word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lsi_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_topics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nwords&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['0.518*"육아휴직/Noun" + 0.257*"만/Noun" + 0.227*"×/Foreign" + 0.214*"대체/Noun" + 0.201*"고용/Noun"',
 '0.449*"파견/Noun" + 0.412*"부대/Noun" + 0.267*"UAE/Alpha" + 0.243*"○/Foreign" + 0.192*"국군/Noun"',
 '0.326*"결혼/Noun" + 0.315*"예고/Noun" + 0.285*"손해/Noun" + 0.205*"ㆍ/Foreign" + 0.197*"원사/Noun"']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LDA&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# optional&lt;/span&gt;
&lt;span class="n"&gt;lda_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ldamodel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LdaModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id2word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lda_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_topics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nwords&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['0.005*the + 0.003*to + 0.003*pct + 0.002*of + 0.002*said',
 '0.005*cts + 0.005*Record + 0.005*div + 0.004*Pay + 0.004*Qtly',
 '0.010*vs + 0.006*mln + 0.006*000 + 0.005*loss + 0.004*cts']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# optional&lt;/span&gt;
&lt;span class="n"&gt;lda_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ldamodel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LdaModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id2word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lda_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_topics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nwords&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['0.001*학위/Noun + 0.001*파견/Noun + 0.001*손해/Noun + 0.001*간호/Noun + 0.001*소말리아/Noun',
 '0.002*파견/Noun + 0.002*부대/Noun + 0.001*UAE/Alpha + 0.001*손해/Noun + 0.001*○/Foreign',
 '0.003*육아휴직/Noun + 0.002*만/Noun + 0.002*×/Foreign + 0.002*대체/Noun + 0.002*고용/Noun']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;HDP&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# optional&lt;/span&gt;
&lt;span class="n"&gt;hdp_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hdpmodel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HdpModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id2word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hdp_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_topics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;topn&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nwords&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['topic 0: 0.005*the + 0.003*to + 0.002*in + 0.002*a + 0.002*of',
 'topic 1: 0.008*vs + 0.005*000 + 0.004*loss + 0.004*mln + 0.004*cts',
 'topic 2: 0.001*the + 0.001*vs + 0.001*in + 0.001*to + 0.001*mln']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# optional&lt;/span&gt;
&lt;span class="n"&gt;hdp_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hdpmodel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HdpModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id2word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hdp_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_topics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;topn&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nwords&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['topic 0: 0.004*소집/Noun + 0.004*도/Josa + 0.004*’/Foreign + 0.004*｢/Foreign + 0.004*9892/Number',
 'topic 1: 0.004*이애주/Noun + 0.004*年/Foreign + 0.004*意思/Foreign + 0.004*마찰/Noun + 0.004*고 려/Noun',
 'topic 2: 0.005*명시/Noun + 0.004*영업정지/Noun + 0.004*세로/Noun + 0.004*중개업/Noun + 0.004*다양하다/Adjective']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;3. Scoring documents&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;bow&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_model_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;doc2bow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lsi_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lda_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hdp_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[(0, 0.1336800876240628),
 (2, -0.030832981664564624),
 (1, -0.39895210562646022)]&lt;/p&gt;
&lt;p&gt;[(2, 0.84087091284115845),
 (0, 0.13882114432084294),
 (1, 0.020307942837998694)]&lt;/p&gt;
&lt;p&gt;[(0, 0.95369717052959579)]
&lt;/pre&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;bow&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_model_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;doc2bow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lsi_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lda_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hdp_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[(0, 0.072924758682943097),
 (2, -0.0029545572070390153),
 (1, -0.13195370933374836)]&lt;/p&gt;
&lt;p&gt;[(0, 0.62957273636869904),
 (2, 0.3270007771486681),
 (1, 0.043426486482632851)]&lt;/p&gt;
&lt;p&gt;[(0, 0.90574410236561731),
 (1, 0.010409702375525492)]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;bow&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_model_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;doc2bow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lsi_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lda_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hdp_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[(0, 0.97829017893328929),
 (1, -0.016909513239922121),
 (2, -0.020121561014425089)]&lt;/p&gt;
&lt;p&gt;[(2, 0.93880436704581616),
 (0, 0.030626827732744354),
 (1, 0.030568805221439507)]&lt;/p&gt;
&lt;p&gt;[(0, 0.94848723192042672),
 (1, 0.014364056233061516),
 (2, 0.010285449586192942)]
&lt;/pre&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;bow&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_model_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;doc2bow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lsi_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lda_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hdp_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[(0, 0.97829017893328929),
 (1, -0.016909513239922121),
 (2, -0.020121561014425089)]&lt;/p&gt;
&lt;p&gt;[(2, 0.93881674048370278),
 (0, 0.0306176131467021),
 (1, 0.030565646369595065)]&lt;/p&gt;
&lt;p&gt;[(0, 0.94848723192042672),
 (1, 0.014364056233061516),
 (2, 0.010285449586192942)]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- Add document/query similarities http://radimrehurek.com/gensim/tut3.html#similarity-interface --&gt;

&lt;blockquote&gt;
&lt;p&gt;Confident with topic modeling? Try a bigger dataset: &lt;a href="http://radimrehurek.com/gensim/wiki.html"&gt;Experiments on the English Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Word embedding&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Objective: Learn feature vectors from documents&lt;ul&gt;
&lt;li&gt;Text is normally represented with one-hot encoding + hand crafted features&lt;/li&gt;
&lt;li&gt;Ex: [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 ]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Word embedding&lt;/strong&gt;: A set of feature unsupervised learning techniques where words are mapped to n-dimensional vectors of real numbers (the continuous space)&lt;ul&gt;
&lt;li&gt;Use local context to get a more syntactic or semantic representation&lt;/li&gt;
&lt;li&gt;Ex: v("cat") = [0.2, -0.4, ..., 0.7], v("mat") = [-0.0, -0.2, ..., -0.1]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Approaches&lt;ul&gt;
&lt;li&gt;Neural networks (Bengio et al., 2001, Mikolov et al., 2013)&lt;/li&gt;
&lt;li&gt;Dimensionality reduction (Lebret et al., 2013)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;word2vec (Mikolov et al., 2013)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A neural network based embedding method for learning distributed vector representations of words&lt;ul&gt;
&lt;li&gt;No hidden layers!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;"an optimized single-machine  can train 100B+ words in one day"&lt;/li&gt;
&lt;li&gt;CBOW &amp;amp; Skip-gram: Two ways of creating the "task" for the neural network&lt;br&gt;
    &lt;img src="images/cbow-skip.png" width="600px"&gt;&lt;/li&gt;
&lt;li&gt;Characteristics&lt;ul&gt;
&lt;li&gt;Places similar words next to each other in a vector space&lt;/li&gt;
&lt;li&gt;Places similar relations in parallel (preserve linguistic regularities)&lt;ul&gt;
&lt;li&gt;ex: France: Paris = Germany: Berlin != Italy: Madrid&lt;br&gt;
    &lt;img src="images/countries.png" width="400px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Linguistic regularities&lt;ul&gt;
&lt;li&gt;v(KING) – v(MAN) + v(WOMAN) = v(QUEEN)&lt;/li&gt;
&lt;li&gt;v(KINGS) – v(KING) + v(QUEEN) = v(QUEENS)&lt;/li&gt;
&lt;li&gt;v(MADRID) – v(SPAIN) + v(FRANCE) = v(PARIS)&lt;/li&gt;
&lt;li&gt;&lt;img src="images/regularities.png" width="400px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Applications&lt;ul&gt;
&lt;li&gt;Machine translation (Socher et al., 2013)&lt;br&gt;
    &lt;img src="images/embedding-mt.png" width="400px"&gt;&lt;/li&gt;
&lt;li&gt;Jointly embedding images and text (Frome et al., 2013, &lt;a href="http://googleresearch.blogspot.co.uk/2014/11/a-picture-is-worth-thousand-coherent.html"&gt;link&lt;/a&gt;)&lt;br&gt;
    &lt;img src="images/google-text.png" width="600px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Some good references to begin with in case you are interested:&lt;ul&gt;
&lt;li&gt;http://radimrehurek.com/2014/02/word2vec-tutorial/&lt;/li&gt;
&lt;li&gt;http://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let's go for it.&lt;/p&gt;
&lt;h3&gt;word2vec toy problem&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Load documents&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;reuters&lt;/span&gt;
&lt;span class="n"&gt;docs_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;reuters&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;reuters&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;
&lt;span class="n"&gt;docs_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tokenize&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;docs_en&lt;/span&gt; &lt;span class="c"&gt;# because we loaded tokenized documents in step 1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.tag&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;pos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;texts_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;docs_ko&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Train&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gensim.models&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;word2vec&lt;/span&gt;
&lt;span class="n"&gt;wv_model_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;word2vec&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Word2Vec&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;wv_model_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;init_sims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;wv_model_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;en_word2vec.model&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gensim.models&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;word2vec&lt;/span&gt;
&lt;span class="n"&gt;wv_model_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;word2vec&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Word2Vec&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;wv_model_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;init_sims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;wv_model_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ko_word2vec.model&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Test&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;wv_model_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;president&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;wv_model_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;secretary&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;wv_model_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;country&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[('chairman', 0.8655247688293457),
 ('vice', 0.8160154819488525),
 ('executive', 0.8094440698623657),
 ('officer', 0.7894954085350037),
 ('Kjell', 0.7766541838645935),
 ('former', 0.7680522203445435),
 ('chief', 0.7660256028175354),
 ('Robert', 0.7623487114906311),
 ('director', 0.7434573173522949),
 ('Roger', 0.7231118679046631)]&lt;/p&gt;
&lt;p&gt;[('assistant', 0.8573123812675476),
 ('Carlos', 0.796258807182312),
 ('Daniel', 0.7900130748748779),
 ('undersecretary', 0.7888025045394897),
 ('representative', 0.7878221273422241),
 ('Deputy', 0.7847912311553955),
 ('NAWG', 0.7829214930534363),
 ('Republican', 0.7773356437683105),
 ('Greek', 0.7752739191055298),
 ('Papandreou', 0.7684933543205261)]&lt;/p&gt;
&lt;p&gt;[('kingdom', 0.8003361225128174),
 ('biggest', 0.765742301940918),
 ('island', 0.7639101147651672),
 ('founding', 0.7143765687942505),
 ('nation', 0.7080289125442505),
 ('fortunes', 0.7054018974304199),
 ('strength', 0.6875098943710327),
 ('challenging', 0.6863174438476562),
 ('actions', 0.6835225820541382),
 ('departure', 0.6834459900856018)]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;wv_model_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;정부&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;wv_model_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;초등학교&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[('경비/Noun', 0.9357226490974426),
 ('선박/Noun', 0.9204540252685547),
 ('연장/Noun', 0.9183653593063354),
 ('임무/Noun', 0.9179578423500061),
 ('우리/Noun', 0.9015840291976929),
 ('목적/Noun', 0.8871368169784546),
 ('기타/Noun', 0.875058650970459),
 ('화/Suffix', 0.8669425249099731),
 ('해역/Noun', 0.8575668334960938),
 ('한국/Noun', 0.8549510836601257)]&lt;/p&gt;
&lt;p&gt;[('취학/Noun', 0.9686248898506165),
 ('중인/Noun', 0.9336546659469604),
 ('하더/Verb', 0.8985729217529297),
 ('정의화/Noun', 0.8843945860862732),
 ('김정훈/Noun', 0.8682949542999268),
 ('지방/Noun', 0.8677719831466675),
 ('조정함/Verb', 0.8617256879806519),
 ('44/Number', 0.8445801734924316),
 ('세/Noun', 0.8318654298782349),
 ('第/Foreign', 0.8222816586494446)]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;word2vec in the real world&lt;/h3&gt;
&lt;p&gt;Not enough? Let's see a real life example.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data source: Naver News &amp;amp; Naver blog&lt;br&gt;
    &lt;img src="images/experiment.png" width="500px"&gt;&lt;/li&gt;
&lt;li&gt;Questions&lt;br&gt;
    &lt;img src="images/questions.png" width="500px"&gt;&lt;/li&gt;
&lt;li&gt;Matching pairs: 그/Noun:남자/Noun = 그녀/Noun:?&lt;br&gt;
    &lt;img src="images/pairs.png" width="500px"&gt;&lt;/li&gt;
&lt;li&gt;Visualization&lt;br&gt;
    &lt;img src="images/tsne1.png" width="600px"&gt;&lt;br&gt;
    &lt;img src="images/tsne2.png" width="600px"&gt;&lt;br&gt;
    &lt;img src="images/tsne3.png" width="600px"&gt;&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!--

## Text classification
### Sentiment analysis
- https://github.com/nltk/nltk/wiki/Sentiment-Analysis

## Machine translation
- http://www.statmt.org/

## Deep learning
- https://github.com/nltk/nltk/wiki/Installing-Third-Party-Software#senna-for-various-nlp-tasks
    - http://ml.nec-labs.com/senna/
--&gt;</summary><category term="text"></category><category term="lectures"></category></entry><entry><title>Scraping from the Web</title><link href="http://lucypark.kr/courses/2015-ba/crawling.html" rel="alternate"></link><updated>2015-03-20T15:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-20:courses/2015-ba/crawling.html</id><summary type="html">&lt;p&gt;Choose a target of your choice:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Target 1: &lt;a href="http://land.naver.com/article/articleList.nhn?rletTypeCd=A01&amp;amp;tradeTypeCd=&amp;amp;hscpTypeCd=&amp;amp;cortarNo=1162010200&amp;amp;mapLevel=10"&gt;Naver 부동산&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Target 2: &lt;a href="http://www.imdb.com/search/title?count=100&amp;amp;start=101"&gt;IMDB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Target 3: &lt;a href="http://www.ted.com/talks"&gt;TED.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Method 1: ctrl + c / ctrl + v&lt;/h2&gt;
&lt;p&gt;&lt;img src="images/excel.png"&gt;&lt;/p&gt;
&lt;h2&gt;Method 2: Google spreadsheet&lt;/h2&gt;
&lt;p&gt;&lt;img src="images/google-spreadsheet.png"&gt;&lt;/p&gt;
&lt;h2&gt;Method 3: import.io (or some other scraping service)&lt;/h2&gt;
&lt;p&gt;&lt;img src="images/importio.png"&gt;&lt;/p&gt;
&lt;h2&gt;Method 4: Being the programmer&lt;/h2&gt;
&lt;p&gt;Let's try programming a crawler ourselves.&lt;/p&gt;
&lt;h3&gt;1. Identify Web page URL&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;First find a Web page where you can find item lists&lt;/li&gt;
&lt;li&gt;Let's understand the URL (cf. &lt;a href="http://meyerweb.com/eric/tools/dencoder/"&gt;Online URL decoder/encoder&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;It is best to find a page where the URL is has an iterable parameter (ex: page numbers, item IDs)&lt;ul&gt;
&lt;li&gt;TED.com talks: http://www.ted.com/talks?page=1&lt;ul&gt;
&lt;li&gt;&lt;code&gt;page&lt;/code&gt; is iterable from 1 to 54&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Amazon.com TVs: &lt;code&gt;http://www.amazon.com/s/?rh=n:172282,n:!493964,n:1266092011,n:172659&amp;amp;page=1&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;page&lt;/code&gt; is iterable from 1 to 143&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Set the variables &lt;code&gt;npages&lt;/code&gt;, &lt;code&gt;url_base&lt;/code&gt;, and also a &lt;code&gt;file_base&lt;/code&gt; to name download files. Normally, you want to set npages to a smaller number (ex: 3), rather than the actuall value (i.e., 54) to test the code before actually executing it.&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;npages&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;54&lt;/span&gt;
&lt;span class="n"&gt;url_base&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;http://www.ted.com/talks?page=&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;file_base&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;ted_talks_&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;.html&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2. Download Web pages&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;First define a function named &lt;code&gt;save_text&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;save_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then using the list URL found on step 1, download list pages. We will use the package &lt;code&gt;requests&lt;/code&gt; for this task&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;page_num&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;npages&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;page_num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url_base&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;page_num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;save_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;file_base&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;page_num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check whether the pages have downloaded succesfully&lt;br&gt;
    &lt;img src="images/download_ted.png"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;3. Parse downloaded Web pages&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Before we go any further, let's recall how an html document looks like. Take a look at one of the downloaded html docs as well.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="cp"&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;html&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;head&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;meta&lt;/span&gt; &lt;span class="na"&gt;charset=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;link&lt;/span&gt; &lt;span class="na"&gt;rel=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;stylesheet&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;href=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;...&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;script &lt;/span&gt;&lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;text/javascript&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;src=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;...&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/head&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;body&amp;gt;&lt;/span&gt;
    &lt;span class="c"&gt;&amp;lt;!-- This is a comment --&amp;gt;&lt;/span&gt;
    ... and this is where the visible contents go ...
&lt;span class="nt"&gt;&amp;lt;/body&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/html&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now, let's set the &lt;code&gt;page_num&lt;/code&gt; to 1 for detailed investigation, rather than creating a &lt;code&gt;for&lt;/code&gt; loop for all pages&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;page_num&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For parsing, we'll be using &lt;a href="http://lxml.de/lxmlhtml.html"&gt;&lt;code&gt;lxml.html&lt;/code&gt;&lt;/a&gt;. Many people also use &lt;a href="https://docs.python.org/3/library/re.html"&gt;regex&lt;/a&gt;. There are various many other options (ex: bs4), so feel free to Google them up.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;lxml&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;html&lt;/span&gt;
&lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_base&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;page_num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With &lt;code&gt;root&lt;/code&gt;, we can easily parse a given text using &lt;a href="http://lxml.de/xpathxslt.html#xpath"&gt;xpath&lt;/a&gt;s, just by identifying the &lt;em&gt;tag&lt;/em&gt;, &lt;em&gt;class&lt;/em&gt;, or &lt;em&gt;id&lt;/em&gt; of an html element. Why don't we try extracting all the text from the &lt;code&gt;&amp;lt;body&amp;gt;&lt;/code&gt; tag? Try this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;//body//text()&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cool, huh? Now, let's think of what we want to extract from our downloaded html, and picture what we want as a result. From our html page, we probably want to extract the title, speaker, view count, date, and url of all TED talks, resulting in a spreadsheet format as follows:
    &lt;div class="row"&gt;
    &lt;div class="col-md-3"&gt;
    &lt;img src="images/ted.png"&gt;
    &lt;/div&gt;
    &lt;div class="col-md-9"&gt;
    &lt;table class="table"&gt;&lt;tr&gt;&lt;th&gt;    title&lt;/th&gt;&lt;th&gt;speaker&lt;/th&gt;&lt;th&gt;views&lt;/th&gt;&lt;th&gt;date&lt;/th&gt;&lt;th&gt;url&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;    The price of shame&lt;/td&gt;&lt;td&gt;Monica Lewinsky&lt;/td&gt;&lt;td&gt;83K&lt;/td&gt;&lt;td&gt;Mar 2015&lt;/td&gt;&lt;td&gt;http://...&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;    What if 3D printing was 100x faster?&lt;/td&gt;&lt;td&gt;Joseph DeSimone&lt;/td&gt;&lt;td&gt;212K&lt;/td&gt;&lt;td&gt;Mar 2015&lt;/td&gt;&lt;td&gt;http://...&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;    Can we create new senses for humans?&lt;/td&gt;&lt;td&gt;David Eagleman&lt;/td&gt;&lt;td&gt;215K&lt;/td&gt;&lt;td&gt;Mar 2015&lt;/td&gt;&lt;td&gt;http://...&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;    The good news about PMS&lt;/td&gt;&lt;td&gt;Robyn Stein DeLuca&lt;/td&gt;&lt;td&gt;248K&lt;/td&gt;&lt;td&gt;Mar 2015&lt;/td&gt;&lt;td&gt;http://...&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;    ...&lt;/td&gt;&lt;td&gt;...&lt;/td&gt;&lt;td&gt;...&lt;/td&gt;&lt;td&gt;...&lt;/td&gt;&lt;td&gt;... &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
    &lt;/div&gt;
    &lt;/div&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;So, in order to find what &lt;em&gt;tag&lt;/em&gt;, &lt;em&gt;class&lt;/em&gt;, or &lt;em&gt;id&lt;/em&gt; we need to exact such elements, let's go back to &lt;a href="http://www.ted.com/talks?page=1"&gt;www.ted.com/talks?page=1&lt;/a&gt;, right click, and "Inspect Element"s.&lt;br&gt;
    &lt;img src="images/parse-1.png" width="400px"&gt;
    &lt;img src="images/parse-2.png" width="400px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;By navigating with the DOM, we can see that the &lt;code&gt;div&lt;/code&gt; tag with &lt;code&gt;id=browse-results&lt;/code&gt; contains all the talk items in &lt;code&gt;div&lt;/code&gt; tags with &lt;code&gt;class=col&lt;/code&gt;, each containing a talk item. (When identifying and html element, using &lt;em&gt;id&lt;/em&gt; is better than using a &lt;em&gt;class&lt;/em&gt;, because normally &lt;em&gt;id&lt;/em&gt;s are unique within a html page.)&lt;br&gt;
    &lt;img src="images/parse-3.png" width="400px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now, let's use xpath to get the talk items.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;items&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;//div[@id=&amp;quot;browse-results&amp;quot;]//div[@class=&amp;quot;col&amp;quot;]&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;   &lt;span class="c"&gt;# returns 36, the number of talk items in the page&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dig into one of the &lt;code&gt;&amp;lt;div class="col"&amp;gt;&lt;/code&gt;s, to further investigate the identifiers of talk information.&lt;br&gt;
    &lt;img src="images/parse-4.png" width="400px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Choose one item and extract relevant data.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;item&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;.//h4[@class=&amp;quot;h12 talk-link__speaker&amp;quot;]/text()&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;.//h4[@class=&amp;quot;h9 m5&amp;quot;]/a/text()&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;.//h4[@class=&amp;quot;h9 m5&amp;quot;]/a/@href&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;.//span[@class=&amp;quot;meta__val&amp;quot;]/text()&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;All the items are contained in a list, and it would be better if we could strip the new lines(&lt;code&gt;\n&lt;/code&gt;) from the strings. Additionally, rather than handling each info separately, let's put the extracted info into one dictionary, and make that a function named &lt;code&gt;parse_item()&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse_item&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s"&gt;&amp;#39;speaker&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;.//h4[@class=&amp;quot;h12 talk-link__speaker&amp;quot;]/text()&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="s"&gt;&amp;#39;title&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;.//h4[@class=&amp;quot;h9 m5&amp;quot;]/a/text()&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="s"&gt;&amp;#39;href&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;.//h4[@class=&amp;quot;h9 m5&amp;quot;]/a/@href&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="s"&gt;&amp;#39;views&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;.//span[@class=&amp;quot;meta__val&amp;quot;]/text()&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="s"&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;.//span[@class=&amp;quot;meta__val&amp;quot;]/text()&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Perfect. Now let's iterate through the items on page 1.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parse_item&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;    &lt;span class="c"&gt;# returns 36&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Great. Now we're ready to iterate through all 54 web pages.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;page_num&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;npages&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

&lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_base&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;page_num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;items&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;//div[@id=&amp;quot;browse-results&amp;quot;]//div[@class=&amp;quot;col&amp;quot;]&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parse_item&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;    &lt;span class="c"&gt;# returns 1943 or a similar number&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;4. Save the parsed data to file&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;We currently have our data in a dictionary format.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Normally, it's enough to save this data directly into a json file.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data.json&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dump&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;&lt;a href="https://chrome.google.com/webstore/detail/jsonview/chklaanhfefbnpoihckbnefhakgolnmc?hl=en"&gt;JSONView&lt;/a&gt; is a nice way to pretty print your json.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;However, sometimes it's better to convert this data into a spreadsheet. If so, try this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;csv&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;writer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;csv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DictWriter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fieldnames&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;writer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;writeheader&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;writer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;writerows&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;5. What's next?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;You can see a refactored, cleaner code of the crawler above &lt;a href="https://gist.github.com/e9t/43f986a915c4059d75af"&gt;here&lt;/a&gt;. Try to understand the syntax yourself.&lt;/li&gt;
&lt;li&gt;Furthermore, you can traverse into the individual talk urls you have just acquired from the list pages.&lt;/li&gt;
&lt;li&gt;Concurrent crawling may come of use. Consult &lt;a href="http://www.slideshare.net/cornchz/pyconkr-2014-30"&gt;this presentation material&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Try crawling some other website of interest.&lt;/li&gt;
&lt;li&gt;If you already have enough data to crunch, go ahead and crunch 'em!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;Below are some Web crawler examples. Most are for Python 2, so be careful.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/e9t/95df9b68ff829a557cfb"&gt;TED.com crawler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/e9t/9680106"&gt;Naver OnStage crawler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://github.com/teampopong/crawlers"&gt;Team POPONG crawlers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/e9t/551f9647f58800273025"&gt;Korean National Assembly bill crawler&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="lectures"></category><category term="crawling"></category></entry><entry><title>Logistic regression</title><link href="http://lucypark.kr/courses/2015-dm/logistic-regression.html" rel="alternate"></link><updated>2015-03-20T09:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-20:courses/2015-dm/logistic-regression.html</id><summary type="html">&lt;h2&gt;오늘의 목표&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;MLR의 블랙박스 열어보기&lt;/li&gt;
&lt;li&gt;로지스틱 회귀모형 개념 익히고 실제로 구현하기&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Multiple linear regression (revisited)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;지난 시간에 우리는 MLR(multiple linear regression)에 대해 배우고 파이썬으로 실제 데이터에 대해 모델을 구축해보았다&lt;/li&gt;
&lt;li&gt;MLR은 실제로 기술 모델링, 설명 모델링 모두를 위해 인기있는 방법론이니 잘 알아두면 좋다.&lt;/li&gt;
&lt;li&gt;그런데 우리 컴퓨터는 MLR을 어떻게 학습했을까? (i.e., 파라미터 $b_j$들을 어떻게 추정했을까?)&lt;/li&gt;
&lt;li&gt;이번 시간에는 MLR의 &lt;a href="http://en.wikipedia.org/wiki/Function_(mathematics)"&gt;블랙박스(black box)&lt;/a&gt; 안에 무엇이 있는지를 보자.&lt;br&gt;
    &lt;a href="http://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/Function_machine2.svg/440px-Function_machine2.svg.png"&gt;&lt;img src="images/function.png" width="200px"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Multiple linear regression? Fit a linear relationship between a quantitative dependent variable $y$ and a set of independent variables $x_1, x_2, ..., x_m$&lt;/p&gt;
&lt;p&gt;$$y = b_0 + b_1x_1 + b_2x_2 + ... + b_mx_m + \epsilon$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$y$: output variable / dependent variable&lt;/li&gt;
&lt;li&gt;$x_j$: $j$th input variable / independent variable&lt;/li&gt;
&lt;li&gt;$b_j$: parameters / coefficients&lt;/li&gt;
&lt;li&gt;$m$: Number of input variables/features&lt;/li&gt;
&lt;li&gt;$\epsilon$: Observation noise&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ex: 33명 성인 여성의 나이와 수축혈압(SBP, systolic blood pressure)&lt;br&gt;
&lt;div class="row"&gt;
    &lt;div class="col-md-8"&gt;
    &lt;table class="table"&gt;&lt;tr&gt;&lt;th&gt;Age&lt;/th&gt;&lt;th&gt;SBP&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;22&lt;/td&gt;&lt;td&gt;131&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;23&lt;/td&gt;&lt;td&gt;128&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;24&lt;/td&gt;&lt;td&gt;116&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;27&lt;/td&gt;&lt;td&gt;106&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan="2" class="data-link"&gt;&lt;a href="data/sbp.csv"&gt;data link&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
    &lt;/div&gt;
    &lt;div class="col-md-4"&gt;
    &lt;img src="images/sbp.png" width="300px"&gt;
    &lt;/div&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;OLS(ordinary least squares) for parameter estimation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;MLR의 파라미터 $b_j$들을 추정하기 위해서는 OLS를 사용한다&lt;ul&gt;
&lt;li&gt;정답과의 오차를 최소화한다는 의미&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Formulation (단순화하기 위해 $b_0, b_1$만 고려해보자)&lt;ul&gt;
&lt;li&gt;Hypothesis: $h(x) = b_0 + b_1x_1$&lt;/li&gt;
&lt;li&gt;Parameters: $b_0, b_1$&lt;/li&gt;
&lt;li&gt;Cost function: $J(b_0, b_1) = \frac{1}{2n}\sum_{i=1}^{n}(h(x_1^{(i)}) - y^{(i)})^2$&lt;ul&gt;
&lt;li&gt;The equation above is called the MSE(mean squared error, 오차의 제곱의 평균)&lt;/li&gt;
&lt;li&gt;MSE 말고도 평균 오차(mean error), MAE, MAPE, RMSE 등을 사용할 수도 있다&lt;ul&gt;
&lt;li&gt;Mean error: $\frac{1}{n}\sum_{i=1}^{n} (h(x_1^{(i)}) - y^{(i)})$&lt;/li&gt;
&lt;li&gt;Mean absolute error (MAE): $\frac{1}{n}\sum_{i=1}^{n} |h(x_1^{(i)}) - y^{(i)}|$&lt;/li&gt;
&lt;li&gt;Mean absolute percentage error (MAPE): $100 \times \frac{1}{n}\sum_{i=1}^{n} |\frac{h(x_1^{(i)}) - y^{(i)}}{y^{(i)}}|$&lt;/li&gt;
&lt;li&gt;Root mean squared error (RMSE): $\sqrt{\frac{1}{2n}\sum_{i=1}^{n}(h(x_1^{(i)}) - y^{(i)})^2}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;이 값은 작을수록 좋음. 즉, 좋은 MSE가 되게 하는 모델이 좋은 모델&lt;/li&gt;
&lt;li&gt;바꿔말하면 좋은 모델을 만들기 위해서는 작은 MSE가 되게 하면 됨&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Goal: $arg \min J(b_0, b_1, ..., b_m)$&lt;ul&gt;
&lt;li&gt;즉, 비용 $J$를 최소화하는 $b_j (j=0, 1, ..., m)$를 찾자&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Solution&lt;ul&gt;
&lt;li&gt;Numerical solution: &lt;a href="http://en.wikipedia.org/wiki/Gradient_descent"&gt;Gradient descent&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Local minimum을 찾기 위한 방법론&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Analytical solution: Normal equation&lt;ul&gt;
&lt;li&gt;Let $y = X\beta$, then
    $$\beta = (X^TX)^{-1}X^Ty$$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- Add bias-variance decomposition with MSE --&gt;

&lt;h2&gt;Logistic regression&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ex: 33명 성인 여성의 나이와 심장동맥병(CD, coronary heart disease) 발병 여부&lt;ul&gt;
&lt;li&gt;&lt;code&gt;CD==1&lt;/code&gt;: positive class (normally the minority class, 예측 대상, ex: 불량, 발병, 스팸 등)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CD==0&lt;/code&gt;: negative class (normally the majority class)&lt;br&gt;
&lt;div class="row"&gt;
    &lt;div class="col-md-8"&gt;
    &lt;table class="table"&gt;&lt;tr&gt;&lt;th&gt;Age&lt;/th&gt;&lt;th&gt;CD&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;22&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;23&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;24&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;27&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan="2" class="data-link"&gt;&lt;a href="data/cd.csv"&gt;data link&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
    &lt;/div&gt;
    &lt;div class="col-md-4"&gt;
    &lt;img src="images/cd.png" width="300px"&gt;
    &lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;위와 같이 일반적인 linear regression 알고리즘을 fitting한 후 $h(x) = ax+b$에 대해 다음과 같은 모델을 추가할 수 있다&lt;ul&gt;
&lt;li&gt;if $h(x) \geq 0.5$, then $\hat{y}=1$&lt;/li&gt;
&lt;li&gt;if $h(x) \lt 0.5$, then $\hat{y}=0$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;하지만 이 방법은 두 가지 측면에서 적절하지 않다.&lt;ol&gt;
&lt;li&gt;&lt;a href="http://en.wikipedia.org/wiki/Outlier"&gt;Outlier&lt;/a&gt;에 robust하지 못하다. 가령 나이가 1세이고 CD==0인 단 한 개의 점이 training set에 추가된다면 모델은 어떻게 바뀔까?&lt;/li&gt;
&lt;li&gt;실제로 $y$값은 0, 1의 두 가지 값밖에 가지지 못함에도 불구하고, $-\infty &amp;lt; h(x) &amp;lt; \infty$ 여서 $h(x)$가 0과 1 사이의 값 뿐 아니라 1보다 크거나 0보다 작은 값도 가질 수 있게 된다. (이 때, 분류 오차도 엄청 커질 수 있다)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Logistic Regression? Fit a linear relationship between a &lt;em&gt;categorical&lt;/em&gt; dependent variable $y$ and a set of independent variables $x_1,x_2,...,x_m$&lt;ul&gt;
&lt;li&gt;주의: 이름에 등장하는 "regression"이라는 표현과는 달리 logisitic regression은 분류 문제를 풀기 위한 알고리즘!&lt;/li&gt;
&lt;li&gt;logistic regression = logit regression == maximum-entropy classification (MaxEnt) == log-linear classifier&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;목표: $0 \leq h(x) \leq 1$가 되는 $h(x)$를 만들어보자.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$h(x) = g(b_0 + b_1x_1 + ... + b_mx_m)$: Multiple linear regression에 함수 $g(x)$를 씌운 꼴&lt;/li&gt;
&lt;li&gt;where $g(z) = \frac{1}{1+e^{-z}}$ ("logistic function" or "&lt;a href="http://en.wikipedia.org/wiki/Sigmoid_function"&gt;sigmoid function&lt;/a&gt;")&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/logistic.png" width="300px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;MLE(maximum likelihood estimation) for parameter estimation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;MLE를 알기 위해서는 먼저 likelihood의 개념을 아는 것이 중요하다.&lt;/li&gt;
&lt;li&gt;likelihood의 개념을 알기 위해서는 &lt;a href="https://sites.google.com/site/lucyparklab/4-discussions/bayesian"&gt;Bayesian 통계&lt;/a&gt;를 아는 것이 중요하다.&lt;ul&gt;
&lt;li&gt;$p(x \vert y)$: 사후확률(posterior)&lt;/li&gt;
&lt;li&gt;$p(y \vert x)$: 우도(likelihood)&lt;/li&gt;
&lt;li&gt;$p(x)$: 사전확률(prior)&lt;/li&gt;
&lt;li&gt;$p(y)$: 증거(evidence)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$p(x|y) = \frac{p(y|x)p(x)}{p(y)}$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;이 likelihood $p(y|x)$에 log를 씌우면 log likelihood가 되고 logistic regression에서는 log likelihood를 $w$에 대해 편미분하여 최대화하는 방식으로 파라미터를 구한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$L(w) = \sum_{i=1}^{n} \log{p(y|x)} = \sum \log{g(x, w)^{y}} + (1-g(x, w))^{1-y}$$&lt;/p&gt;
&lt;p&gt;where $g(x, w) = \frac{1}{1+\exp{-wx}}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;마지막으로 gradient decent를 사용하며 update rule은 $w \leftarrow w + \nu \sum(y-g(x,w))x$이다.&lt;/li&gt;
&lt;li&gt;식 유도 과정은 &lt;a href="http://web.engr.oregonstate.edu/~xfern/classes/cs534/notes/logistic-regression-note.pdf"&gt;이 문서&lt;/a&gt; 참고&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;[Programming] Logistic regression with scikit-learn&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="../tips/terminal.html"&gt;먼저 시작하기 전에 터미널 프로그래밍을 위한 몇 가지 tip&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;1. Data acquisition&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;오늘도 지난 시간처럼 데이터 파일을 직접 구해서 로딩하기보다는 편의를 위해 scikit-learn 패키지를 이용해보자.&lt;ul&gt;
&lt;li&gt;단, 이번에는 원래 scikit-learn 패키지에 포함되어 있는 데이터가 아니라 scikit-learn의 &lt;a href="http://scikit-learn.org/0.12/modules/generated/sklearn.datasets.fetch_mldata.html"&gt;&lt;code&gt;datasets.fetch_mldata()&lt;/code&gt;&lt;/a&gt; 메소드를 이용해서 &lt;a href="http://mldata.org"&gt;mldata.org&lt;/a&gt;에 있는 데이터셋을 받아올 것이다.&lt;/li&gt;
&lt;li&gt;그 밖에도 scikit-learn을 통해 접근하거나 다운로드 받을 수 있는 데이터셋에 관해서는 &lt;a href="http://scikit-learn.org/stable/datasets/"&gt;이 링크&lt;/a&gt;를 참고하자.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;이번에 우리가 사용할 데이터셋은 머신러닝계에서 아주 유명한 &lt;a href="http://yann.lecun.com/exdb/mnist/"&gt;MNIST 데이터&lt;/a&gt;이다.&lt;ul&gt;
&lt;li&gt;이 데이터셋은 너비 28픽셀, 높이 28픽셀로 된 숫자 필기 이미지 70,000장에 대한 데이터이다.&lt;/li&gt;
&lt;li&gt;오늘 풀어볼 문제는, "임의의 숫자 필기 이미지를 입력받았을 때 컴퓨터가 어떤 숫자에 대한 이미지인지 알게 할 수 있는가?" 즉, 필기 인식이다.&lt;/li&gt;
&lt;li&gt;사실은 사람들도 꾸준한 "학습(learning)"을 통해 생성된 "분류기"를 이용해 숫자를 분류한다.&lt;br&gt;
&lt;img src='images/mnist.gif'&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이제 데이터를 다운로드 받아보자. &lt;a href="http://scikit-learn.org/stable/datasets/#downloading-datasets-from-the-mldata-org-repository"&gt;&lt;code&gt;datasets.fetch_mldata()&lt;/code&gt;&lt;/a&gt; 메소드에
우리가 받고 싶은 데이터의 이름 'MNIST original'를 명시한 후,
데이터를 저장할 곳 &lt;code&gt;data_home&lt;/code&gt;을 현재 디렉토리(&lt;code&gt;.&lt;/code&gt;)로 정해주면 데이터가 다운로드 된 후 바로 변수 &lt;code&gt;d&lt;/code&gt;로 로드(load)된다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;
&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fetch_mldata&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;MNIST original&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data_home&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;&lt;code&gt;data_home&lt;/code&gt;은 얼마든지 다른 디렉토리로 지정해줘도 된다.&lt;/li&gt;
&lt;li&gt;한번 데이터를 다운받고 나서 같은 명령어를 재실행하면 다운로드 없이 바로 데이터가 로드된다.&lt;/li&gt;
&lt;li&gt;이번에도 변수 &lt;code&gt;d&lt;/code&gt;는 dictionary 형태로 되어 있으며, &lt;a href="multiple-linear-regression.html#programming-slr-mlr-with-scikit-learn"&gt;지난 시간에 살펴보았던 당뇨병(diabetes) 데이터셋&lt;/a&gt;과 마찬가지로 dictionary를 구성하는 key, value 중 'data', 'target'라는 key를 비롯하여 'COL_NAMES', 'DESCR' 등의 key도 있다.
(이 key들이 어떤 value를 담고 있는지 궁금하다면 출력해보자.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;여기서는 곧바로 당뇨병 데이터와 마찬가지로 'data' key의 value를 &lt;code&gt;X&lt;/code&gt;에, 'target' key의 value를 &lt;code&gt;y&lt;/code&gt;라는 변수에 저장하고,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;     &lt;span class="c"&gt;# python shell에서 실행하는 경우 `print()`는 필요없음&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;target&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;X&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;의 차원(dimension)을 확인해보자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c"&gt;# check data type of variable X, y&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c"&gt;# returns (70000, 784) (70000,)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;출력된 결과를 보니 &lt;code&gt;X&lt;/code&gt;에는 70,000개의 record(row)와 784개의 attribute(column, variable)가 있고, &lt;code&gt;y&lt;/code&gt;는 70,000개의 record로 구성된 1차원 데이터라고 한다.&lt;/li&gt;
&lt;li&gt;또, 넘어가기 전에 &lt;strong&gt;X의 record수와 y의 record 수가 일치&lt;/strong&gt;하고 &lt;strong&gt;y는 1차원&lt;/strong&gt;임을 반드시 확인하고 넘어가자.  위의 두 가지 사항이 맞지 않는다면 꽤 골치 아파질 것이다.
(왜 그럴까? 각자 생각해보자.)&lt;/li&gt;
&lt;li&gt;한편, 여기서 사용하는 &lt;code&gt;shape&lt;/code&gt;는 numpy의 &lt;code&gt;ndarray&lt;/code&gt;나  pandas의 &lt;code&gt;DataFrame&lt;/code&gt; 등 특정 데이터 타입을 사용할 때만 적용할 수 있다는 점을 알아두면 좋다.
(즉, 파이썬의 &lt;code&gt;list&lt;/code&gt; 데이터 타입을 사용할 때는 &lt;code&gt;shape&lt;/code&gt;를 사용할 수 없는데, 무슨 말인지 모르겠으면 일단 넘어가자. 다음에 이런 일이 발생하게 된다면 어차피 에러가 뜰테니까.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2. Data exploration&lt;/h3&gt;
&lt;p&gt;처음 데이터를 받고 나면 무엇부터 할 수 있을까?
바로 데이터 학습? 아니다.
다음은 실제 데이터를 다룰 떄 살펴보는 사항들이다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;데이터가 크기가 얼마나 되는가? (용량, 행/열 차원 수)&lt;/li&gt;
&lt;li&gt;$y$ 값으로 설정할만한 실수형 혹은 범주형 변수가 있는가?&lt;/li&gt;
&lt;li&gt;Missing data가 있는가?&lt;/li&gt;
&lt;li&gt;변수의 종류는 무엇인가? 실수형? 범주형?&lt;ul&gt;
&lt;li&gt;실수형은 정규화(normalization)해주는 것이 일반적&lt;/li&gt;
&lt;li&gt;범주형은 1-of-c 코딩 등의 방식으로 변환해주는 것이 일반적&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;데이터는 어떻게 분할할까?&lt;ul&gt;
&lt;li&gt;Training:Test=60:40이 일반적이기는 하지만 다른 방법은 없을까?&lt;/li&gt;
&lt;li&gt;&lt;a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)"&gt;10-fold cross validation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;우리도 본격적으로 logistic regression 알고리즘으로 분류 모델을 만들기 전에 우리가 가진 데이터를 이리저리 살펴보자.
Data exploration은 현재 가지고 있는 데이터를 이리저리 굴려가며 모양새를 확인하는 것이다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;X, y는 각각 어떤 값들로 이루어졌는지 확인해보기 위해 X, y 각각의 첫번째 값을 출력해보자. (배열의 첫번째 index는 1이 아니라 0이라는 사실이 기억나는가?)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;X는 특히 0과 256 미만의 숫자들로 구성이 되어 있는데 이것은 어떤 의미를 가질까? (256이라는 숫자가 힌트!)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;쉽게 이해하기 위해 &lt;code&gt;matplotlib&lt;/code&gt; 패키지를 이용해 첫 번째 record를 한 번 그려보자. (원래 matplotlib은 3rd party 패키지여서 따로 설치해야하지만, 다행히도 anaconda가 matplotlib을 미리 설치해줬다.)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;
&lt;span class="n"&gt;X0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;           &lt;span class="c"&gt;# reshape 1*784 array to 28*28 array&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;image&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;binary&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;      &lt;span class="c"&gt;# set runtime configurations (rc) for color maps&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                     &lt;span class="c"&gt;# plot matrix&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;X0.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;               &lt;span class="c"&gt;# save plot to image file&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;                          &lt;span class="c"&gt;# show plot on screen&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;무슨 모양 같은가? 그렇다. 숫자 '0'이다.&lt;br&gt;&lt;img src="images/X0.png" width="300px"&gt;&lt;/li&gt;
&lt;li&gt;그럼 &lt;code&gt;y[0]&lt;/code&gt;의 값을 출력해보면? 마찬가지로 '0'이다. &lt;code&gt;y[0]&lt;/code&gt;는 &lt;code&gt;X[0]&lt;/code&gt;의 "정답"이다. &lt;/li&gt;
&lt;li&gt;여유가 된다면 X, y의 첫번째 record가 아니라 42번째, 10000번째, 마지막 record 등도 그려보자.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이번에는 y가 어떤 값들을 가질 수 있는지 확인해보기 위해 다음을 입력해보자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;   &lt;span class="c"&gt;# returns {0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.python.org/3/tutorial/datastructures.html#sets"&gt;&lt;code&gt;set()&lt;/code&gt;&lt;/a&gt;은 파이썬에서 제공하는 기본 함수로, 배열을 입력받으면 unique한 값들을 반환한다.&lt;ul&gt;
&lt;li&gt;예를들어, [1,2,3,2,2,1,1,1,3,1,1]이라는 배열을 입력받았을 때 [1,2,3]을 반환한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;우리가 하려는 것이 뭔지 대충 감이 잡히는가?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;우리는 &lt;code&gt;X&lt;/code&gt;에 손글씨로 숫자를 쓴 필기 이미지와, &lt;code&gt;y&lt;/code&gt;에 그 이미지의 label(정답)을 가지고 있으며 정답셋은 0-9까지의 숫자로 구성되어 있다.&lt;/li&gt;
&lt;li&gt;지난 시간에 다룬 당뇨병 데이터는 $y$가 실수형 벡터였던 것과 달리 이번 시간에 다루는 MNIST 데이터는 $y$가 범주형(categorical) 벡터이다. $y$가 실수형일 때는 regression problem이지만, $y$가 범주형일 때는 classification problem이다.&lt;/li&gt;
&lt;li&gt;보다시피 필기체 인식은, 가장 대표적인 분류 문제 중 하나이다.&lt;br&gt;
&lt;img src='images/diotek.jpg' width="300px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;3. Data partitioning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;이번에는 데이터를 partitioning 해보자.&lt;ul&gt;
&lt;li&gt;다시 한 번 얘기하지만, data partitioning은 &lt;strong&gt;overfitting 방지, 일반화 성능 향상&lt;/strong&gt;을 위해 하는 것이다.&lt;/li&gt;
&lt;li&gt;Data partitioning의 의미를 잊었다면 &lt;a href="multiple-linear-regression.html#data-partitioning"&gt;이 곳&lt;/a&gt;에 가서 복습하고 오자.
 데이터로 컴퓨터를 학습시킬 때 가장 중요한 개념 중 하나이니 반드시 익혀둬야 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;당뇨병 데이터셋에서는 X, y를 단순한 list split을 통해 440개 record 중에서 400개를 training set, 40개를 test set으로 설정했다.
이번에는 record가 70,000개인데, 어떻게 나누는 것이 좋을까?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;cross_validation&lt;/span&gt;
&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cross_validation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1234&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;다시 list split을 사용해도 되지만, 이번에는 scikit-learn에서 제공하는 &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html"&gt;&lt;code&gt;train_test_split()&lt;/code&gt;&lt;/a&gt;을 써보자.&lt;/li&gt;
&lt;li&gt;이 메소드는 데이터를 비율에 맞게 랜덤 샘플링(random sampling)해준다는 점에서 단순히 list split을 하는 것보다 바람직하다. 왜일까? &lt;code&gt;y&lt;/code&gt;의 값들이 오름차순으로 정렬되어 있기 때문이다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;test_size&lt;/code&gt; 파라미터는 test set의 비율이다. 0.4로 했으니 training set은 0.6이 될 것이고, 따라서 test set에는 70,000의 40%인 28,000개의 record가 random으로 selection돼서 들어간다. 이 값을 명시해주지 않으면 scikit-learn v0.15.2를 기준으로 test set이 0.25, training set이 0.75가 된다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;random_state&lt;/code&gt;는 랜덤 샘플링할 때 사용하는 seed이다.
이 seed를 같은 숫자로 설정해주면 같은 결과를 얻게 되고, 설정해주지 않으면 실행할 때마다 다른 결과를 얻게 된다.
실험 재현(reproduction)의 측면에서 random number를 generation하는 seed를 지정해주는 것은 아주 중요하다.
여기서 사용한 1234가 아니라 51321, 0 등 어떤 숫자를 사용해도 되는데,
중요한 것은 실험 조작 등을 방지하고, 누구라도 같은 코드를 돌렸을 때 동일한 실험 결과를
낳을 수 있게 하기 위해 가급적이면 명시하는 것이 좋다.&lt;/li&gt;
&lt;li&gt;또, 여기서 사용한 서브패키지 &lt;code&gt;cross_validation&lt;/code&gt;은 사실 단순히 데이터를 두 개의 파티션으로 나누는 일 외에도 중요한 일을 하는데, 아직은 몰라도 되지만 곧 학기 중에 반드시 다루게 될 중요한 개념이니 이름을 익혀두도록 하자.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;4. Training&lt;/h3&gt;
&lt;p&gt;자, 이제 드디어 로지스틱 회귀분석 모델을 학습해보자!
고맙고 신기하게도 scikit-learn 패키지를 이용하면 모델 학습은 단 세 줄만에 끝난다.
(물론 내부에는 누군가가 이미 고생해서 짜놓은 어마어마한 "black box"가 존재한다는 것을 잊지 말자.)
MLR을 학습할 때와 마찬가지로 LogisticRegression 클래스를 import한 후, instance를 생성하고, training set으로 모델을 학습하면 된다&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;
&lt;span class="n"&gt;lr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1234&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;      &lt;span class="c"&gt;# LR instance 생성&lt;/span&gt;
&lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                        &lt;span class="c"&gt;# LR 학습&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;그런데... 결과가 뜨지 않는다.
컴퓨터가 먹통됐나? 아니다. 실제로 컴퓨터는 엄청 열심히 돌고 있다.&lt;/li&gt;
&lt;li&gt;당뇨병 데이터로 MLR을 돌릴 때는 뭔가 돌긴 돌았나 싶을 정도로 빨리 끝났지만,
이번에는 경우가 다르다.&lt;/li&gt;
&lt;li&gt;데이터 개수도 440개에서 70,000개로 늘어난데다가 무엇보다 차원의 수가 10개에서 784개로 늘어났다.&lt;ul&gt;
&lt;li&gt;데이터 크기가 10배가 증가했다고 해서 학습/처리 시간이 10배만큼 늘어나는 것이 아니라, 때로는 100배, 1000배씩 증가할 때도 있다.&lt;/li&gt;
&lt;li&gt;특히 차원의 개수가 늘어날 때 우리는 &lt;a href="http://en.wikipedia.org/wiki/Curse_of_dimensionality"&gt;차원의 저주(curse of dimensionality)&lt;/a&gt;를 겪는다고 말한다.&lt;/li&gt;
&lt;li&gt;학습은 아니지만 계산 속도가 기하급수적으로 증가하는 간단한 실험: &lt;code&gt;sum(range(10**7))&lt;/code&gt;, &lt;code&gt;sum(range(10**8))&lt;/code&gt;, &lt;code&gt;sum(range(10**9)&lt;/code&gt;의 계산 속도를 비교해보자.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;쿼드 코어 노트북 기준으로 이 로지스틱 회귀분석 모델을 학습하는데는 약 45분이 걸렸다. (..)&lt;/li&gt;
&lt;li&gt;따라서 이 데이터 전체를 돌리는 것은 &lt;a href="assignments.html#assignment-1-classification"&gt;숙제&lt;/a&gt;다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;실제로 데이터로 좋은 모델은 학습 &lt;strong&gt;시간&lt;/strong&gt;이 짧고 &lt;strong&gt;성능(performance)&lt;/strong&gt;이 좋다.&lt;/p&gt;
&lt;p&gt;어떻게 하면 빠르게 학습시킬 수 있는가? 어떻게 하면 더 좋은 성능을 낼 수 있는가?
이런 질문들은 데이터마이너들에게 아주 익숙한 질문이다.&lt;/p&gt;
&lt;p&gt;그런데 여기서 끝내기엔 좀 아쉽지 않은가?
시간을 단축하기 위해 문제를 단순화 시키고, 하는 김에 csv에서 데이터 로딩하는 법을 익혀보자.&lt;/p&gt;
&lt;h3&gt;5. 2범주 MNIST: 0과 1 구분하기&lt;/h3&gt;
&lt;p&gt;0, 1은 프로그래밍할 때 굉장히 중요한 숫자들이다.
이들만 골라서 2범주 분류 문제를 한 번 풀어보자.
편의를 위해 &lt;a href="https://gist.github.com/e9t/5d4c2b48d8eca8c662ef#file-mnist_binarize-py"&gt;이 변환 파일&lt;/a&gt;을 이용해 10 class, 70000 row의 MNIST dataset을
2 class, 14780 row의 데이터셋으로 변환했다.&lt;/p&gt;
&lt;p&gt;먼저 데이터셋을 다운로드 받은 후, csv 파일을 열어 데이터 모양을 확인해보자.
(csv 파일은 엑셀로 열 수 있는 spreadsheet 형태의 데이터이며 comma-separated-values의 약자이다.)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;X: &lt;a href="data/mnist-x-bin.csv"&gt;lucypark.kr/courses/2015-dm/data/mnist-x-bin.csv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;y: &lt;a href="data/mnist-y-bin.csv"&gt;lucypark.kr/courses/2015-dm/data/mnist-y-bin.csv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;다음으로 아래 코드를 이용해 csv 데이터를 로딩해보자.&lt;/p&gt;
&lt;p&gt;여기서는 numpy의 &lt;a href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html"&gt;&lt;code&gt;genfromtxt()&lt;/code&gt;&lt;/a&gt;를 써서 csv 파일을 로딩해보자.
파일에서 데이터 로딩하는 것도 그리 어렵지 않다!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;genfromtxt&lt;/span&gt;
&lt;span class="n"&gt;X_bin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;genfromtxt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;mnist-x-bin.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;delimiter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y_bin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;genfromtxt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;mnist-y-bin.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;delimiter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;참고: pandas 패키지의 &lt;code&gt;read_csv()&lt;/code&gt;를 이용하면 더 간판하고 빠르게 csv 데이터를 읽을 수 있다.
pandas는 파이썬에서 DataFrame 등을 이용하여 구조적 데이터를 편리하게 분석할 수 있게 해주는 인기있는 도구이다. 관심있다면 검색해보자.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;자, 이제 여러번 반복했듯 data partitioning, 그리고 model fitting(==training)을 해서 &lt;code&gt;lr2&lt;/code&gt;이라는 이름으로 저장하자.&lt;br /&gt;
(이 부분은 설명을 생략)&lt;/p&gt;
&lt;p&gt;모델을 학습한 다음에는 무엇을 해야할까?
성능을 측정하기 위해 시험을 봐야지! (Testing phase)
Training 데이터와 test 데이터 모두의 정확도를 도출해보자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lr2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_bin_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_bin_train&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lr2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_bin_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_bin_test&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;사실 분류 문제는 정확도 말고도 precision, recall, f-measure 등의 지표가 있다.
아래는 이들 지표에 대한 목록이다. (참고: &lt;a href="http://en.wikipedia.org/wiki/Precision_and_recall"&gt;Precision and recall&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;&lt;img src="images/cmt.png" width="400px"&gt;
&lt;img src="images/cm.png"&gt;&lt;/p&gt;
&lt;p&gt;이 값들은 &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html"&gt;precision_recall_fscore_support()&lt;/a&gt;을 이용해서 구할 수 있다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;precision_recall_fscore_support&lt;/span&gt;
&lt;span class="n"&gt;y_bin_pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lr2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_bin_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;precision_recall_fscore_support&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_bin_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_bin_pred&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;average&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;macro&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;성능 지표의 값들은 얼마가 나오는가?
괜찮은가?&lt;/p&gt;
&lt;h3&gt;6. 1범주 MNIST: 1-against-all&lt;/h3&gt;
&lt;p&gt;사실 우리가 애초에 풀려던 문제는 좀 어려운 문제였을 수 있다.
무려 10가지 숫자(digit) 중에서 맞는 숫자를 골라보라니!
(실제로 &lt;a href="http://www.livescience.com/38310-ai-has-four-year-old-iq.html"&gt;2013년 기준 현대 AI의 수준은 4살짜리 꼬마의 지능과 유사하다&lt;/a&gt;고 한다)&lt;/p&gt;
&lt;p&gt;이번에는 처음의 70000행의 MNIST 데이터셋을 그대로 사용하되
문제를 좀 단순화시켜서, 이미지에 등장한 숫자가 1인지 아닌지만 판단하는 모델 &lt;code&gt;lr1&lt;/code&gt;을 만들어보자.
즉, 이 모델은 0, 2, 3, 4, ..., 9는 0(또는 False)을 반환하고, 1만 1(또는 True)을 반환하면 된다.
이렇게.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;
&lt;span class="n"&gt;lr1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1234&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;lr1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;이제 accuracy, precision, recall, f-measure을 재보자.
성능이 어떤가? 학습 시간은?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;참고:&lt;br&gt;
1. &lt;a href="http://colah.github.io/posts/2014-10-Visualizing-MNIST/"&gt;Visualizing MNIST: An Exploration of Dimensionality Reduction&lt;/a&gt;&lt;br&gt;
2. &lt;a href="http://deeplearning.net/tutorial/logreg.html"&gt;Classifying MNIST digits using Logistic Regression&lt;/a&gt;&lt;br&gt;
3. &lt;a href="https://www.kaggle.com/c/digit-recognizer"&gt;Kaggle Digit Recognizer contest&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</summary></entry><entry><title>터미널에서 프로그래밍하기</title><link href="http://lucypark.kr/courses/tips/terminal.html" rel="alternate"></link><updated>2015-03-18T15:55:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-18:courses/tips/terminal.html</id><summary type="html">&lt;p&gt;이제 프로그래밍에 조금은 익숙해졌죠?
익숙해지지 않았다면? 지금이라도 열심히 복습하세요. 연습만이 살 길입니다.&lt;/p&gt;
&lt;p&gt;다음은 터미널에서 프로그래밍할 때, 조금 더 생산성을 높이기 위한 몇 가지 꿀팁입니다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;탭(tab) 키를 잘 활용하자!&lt;ul&gt;
&lt;li&gt;쉘에서 명령어의 일부만 입력한 후 탭 키를 누르면 명령어 자동완성&lt;/li&gt;
&lt;li&gt;Python 쉘 또는 IPython 쉘에서 특정 모듈 뒤에 쩜(&lt;code&gt;.&lt;/code&gt;)을 입력한 후 탭 키를 누르면 관련 메소드(method)들이 화면에 출력
&lt;script type="text/javascript" src="https://asciinema.org/a/17805.js" id="asciicast-17805" async&gt;&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;화살표키도 자주 사용됨&lt;ul&gt;
&lt;li&gt;쉘에서 화살표 키를 위 아래 위위 아래로 누르면 예전에 입력했던 명령어들을 볼 수 있다
&lt;script type="text/javascript" src="https://asciinema.org/a/17804.js" id="asciicast-17804" async&gt;&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;해커의 생명은 단축키&lt;ul&gt;
&lt;li&gt;줄의 맨 앞으로 가는 단축키? ctrl+a&lt;/li&gt;
&lt;li&gt;맨 뒤로 가는 단축키? ctrl+e&lt;/li&gt;
&lt;li&gt;쉘에서 나가는 단축키? 보통 ctrl+d 또는 ctrl+c
&lt;script type="text/javascript" src="https://asciinema.org/a/17807.js" id="asciicast-17807" async&gt;&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary></entry><entry><title>Multiple linear regression</title><link href="http://lucypark.kr/courses/2015-dm/multiple-linear-regression.html" rel="alternate"></link><updated>2015-03-16T18:37:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-13:courses/2015-dm/multiple-linear-regression.html</id><summary type="html">&lt;h2&gt;오늘의 목표&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;데이터마이닝 알고리즘의 분류&lt;/li&gt;
&lt;li&gt;Data partitioning 개념 익히기&lt;/li&gt;
&lt;li&gt;그 외 데이터마이닝에서 빈번히 다루는 용어들 익히기&lt;/li&gt;
&lt;li&gt;단변수, 다변수 선형회귀분석(linear regression)의 개념 익히고 파이썬으로 돌려보기&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Data mining process&lt;/h2&gt;
&lt;p&gt;&lt;img src="images/process.png" width="500px"&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Problem definition&lt;/li&gt;
&lt;li&gt;Data acquisition and selection&lt;/li&gt;
&lt;li&gt;Data exploration&lt;/li&gt;
&lt;li&gt;Data preprocessing&lt;/li&gt;
&lt;li&gt;Train and evaluate data mining model&lt;/li&gt;
&lt;li&gt;Interpret results&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;목적에 따른 분류: Predictive methods vs Descriptive methods&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Predictive modeling&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;Predict the &lt;em&gt;future&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Identify strong links between variables of data&lt;/li&gt;
&lt;li&gt;To predict the unknown consequence (dependent variable) based on the information provided (independent variable)&lt;ul&gt;
&lt;li&gt;과거를 통해 현재를 알고 미래를 내다보자&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Descriptive modeling&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;Look back to the &lt;em&gt;past&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;To extract compact and easily understood information from large, sometimes gigantic databases&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/methods.png" width="600px"&gt;&lt;/p&gt;
&lt;h3&gt;학습데이터에 따른 분류: Supervised learning vs Unsupervised learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;교사학습(Supervised learning)&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;Goal: predict a single "target" or "outcome" variable $y$&lt;ul&gt;
&lt;li&gt;입출력(input $X$-output$y$)의 쌍으로 구성된 training data로부터 입력을 출력을 사상하는 함수를 학습하는 과정&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Method: &lt;em&gt;Learn&lt;/em&gt; on training data, &lt;em&gt;score&lt;/em&gt; on test data&lt;ul&gt;
&lt;li&gt;즉, 입력벡터를 $X$, 그에 대응하는 출력벡터(i.e., label)를 $y$라고 할 때, training data는 $D={(x, y)}$로 주어지게 되며, 모델은 이 training data에 기반하여 관측하지 않은 새로운 데이터 $x'$가 들어왔을 때 그에 해당되는 label, $y'$을 추론하는 방법을 배우게 된다&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ex: 분류(classification)와 회귀분석(regression)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;비교사학습(Unsupervised learning)&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;Goal: Explore intrinsic characteristics of data $X$&lt;/li&gt;
&lt;li&gt;Method: Estimate underlying distributions and/or segment data into meaningful groups or detect patterns&lt;ul&gt;
&lt;li&gt;There is no target (outcome) variable to predict or classify&lt;/li&gt;
&lt;li&gt;출력값 없이 오직 입력값만 주어지며, 이러한 입력값들의 공통적인 특성을 파악하여 학습하는 과정&lt;/li&gt;
&lt;li&gt;Training data는 $D={(x)}$로 주어지게 된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ex: 군집화(clustering), 밀도추정(density estimation), 차원축소(dimension reduction)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;cf. semi-supervised learning&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Data partitioning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;데이터를 training data와 test data로 나누는 것&lt;ul&gt;
&lt;li&gt;Training data: 모델 학습용&lt;/li&gt;
&lt;li&gt;Test data: 모델 성능 측정용&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;왜? Overfitting 방지, 일반화 성능 향상&lt;/li&gt;
&lt;li&gt;보통은 60:40 정도로 데이터를 분할하지만, 보유하고 있는 데이터 규모에 따라 이 비율은 달라지기도 함&lt;/li&gt;
&lt;li&gt;컴퓨터가 모델을 학습하고 평가 받는 것은, 교실에서 학생과 선생님 사이에서 발생하는 일과 매우 유사하다!&lt;ul&gt;
&lt;li&gt;Training phase: 교사는 문제($X_{train}$)와 정답($y_{train}$)이 모두 포함된 training data를 이용해 컴퓨터를 훈련(training)시키고, 컴퓨터는 모델을 학습한다(learning).&lt;/li&gt;
&lt;li&gt;Testing phase: 컴퓨터가 training data로 모델을 학습한 후에는 교사가 컴퓨터에게 정답($y_{test}$) 없이 문제($X_{test}$)만 포함된 시험(test data)을 전달한다. 이 때, 컴퓨터가 제출한 답안지($\hat{y}$)와 실제 정답($y_{test}$)간의 차이를 비교해서 오답/오류(error)가 얼마나 발생했는지 확인함으로써 모델의 성능/성적을 평가한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;때로는 training data, validation data, test data 등 세 개의 그룹으로 데이터를 나누기도 함 (참고: &lt;a href="http://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set"&gt;What is the difference between test set and validation set?&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/partition.png" width="700px"&gt;&lt;/p&gt;
&lt;h2&gt;Simple linear regression (SLR)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Regression&lt;ul&gt;
&lt;li&gt;대표적인 교사학습(supervised learning) 방법론&lt;ul&gt;
&lt;li&gt;"right answers" given&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Predict continuous valued output&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Formulation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$x$: 독립변수(independent variable)&lt;/li&gt;
&lt;li&gt;$y$: 종속변수(dependent variable)&lt;/li&gt;
&lt;li&gt;$a, b$: 파라미터(parameters) or 계수(coefficients)&lt;/li&gt;
&lt;li&gt;$\epsilon$: Observation noise&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$y = ax + b + \epsilon$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ex: Housing price prediction&lt;br&gt;
    &lt;img src="images/house.png" width="400px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Multiple linear regression (MLR)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Formulation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$x_j$: 독립변수들(independent variables)&lt;/li&gt;
&lt;li&gt;$y$: 종속변수(dependent variable)&lt;/li&gt;
&lt;li&gt;$b_j$: 파라미터(parameters) or 계수(coefficients)&lt;/li&gt;
&lt;li&gt;$\epsilon$: Observation noise&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$y = b_0 + b_1x_1 + b_2x_2 + ... + b_mx_m + \epsilon$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;[Programming] SLR, MLR with scikit-learn&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;데이터 import 하기&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;먼저 파이썬에서 MLR을 시행하기 위해서 &lt;a href="http://scikit-learn.org/"&gt;scikit-learn&lt;/a&gt; 패키지를 사용해보자.&lt;/li&gt;
&lt;li&gt;보통은 데이터를 어디선가 다운로드 받고, 정제한 후 읽어들어야겠지만, scikit-learn 패키지에 이미 몇 가지 데이터셋이 준비되어 있으니 그 중 한 가지인 diabetes(당뇨병) 데이터셋을 써보자.&lt;/li&gt;
&lt;li&gt;파이썬에서 패키지를 사용하기 위해서는 &lt;code&gt;import some_package&lt;/code&gt;을 입력하면 되고, 하나의 큰 패키지에서 일부만을 사용할 때는 &lt;code&gt;from some_package import a_subpackage&lt;/code&gt;를 입력하면 된다.
우리는 먼저 scikit-learn의 일부인 &lt;code&gt;dataset&lt;/code&gt; subpackage 사용할 것이니 &lt;code&gt;from sklearn import datasets&lt;/code&gt;를 하고, 데이터를 로딩해보자.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;어렵지 않다. 말 그대로 다른 패키지에서 특정 기능, 혹은 모든 기능을 수입(import)해오겠다는 것이다.&lt;br&gt;(참고: &lt;code&gt;import&lt;/code&gt;에 대해 더 자세히 알기 위해서는 &lt;a href="https://docs.python.org/3/tutorial/modules.html"&gt;모듈에 대한 파이썬 공식 문서&lt;/a&gt;를 보자.)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;
&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_diabetes&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;우리가 다른 곳에서 (ex: &lt;a href="http://archive.ics.uci.edu/ml/"&gt;UCI Datasets&lt;/a&gt;) 데이터를 다운로드 받았다면 별도의 전처리 과정을 거쳐야했겠지만 친절하게도 scikit-learn은 데이터를 이미 전처리해서 data (X), target (y)로 나누어 놓았다. 이를 각각 &lt;code&gt;X&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;에 넣어보자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;  &lt;span class="c"&gt;# returns [&amp;#39;target&amp;#39;, &amp;#39;data&amp;#39;]&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;target&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;다른 작업을 진행하기 이전에 X, y 데이터에 대한 탐색을 해보자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;      &lt;span class="c"&gt;# returns (442, 10)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Simple linear regression&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;먼저 하나의 변수를 정해 simple linear regression부터 해보자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="n"&gt;X2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newaxis&lt;/span&gt;&lt;span class="p"&gt;][:,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;변수를 선택하고 나면 X2, y를 각각 training set, test set으로 나눈다. 현재 데이터의 개수가 442개이므로 test set을 약 10%인 40개로 해보자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;X2_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X2_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X2&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;X2&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Train&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LinearRegression&lt;/span&gt;
&lt;span class="n"&gt;slr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LinearRegression&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;slr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X2_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# The coefficients&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Coefficients: &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;slr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coef_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# mean square error&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;RSS: &lt;/span&gt;&lt;span class="si"&gt;%.2f&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;slr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X2_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c"&gt;# Explained variance score: 1 is perfect prediction&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Variance score: &lt;/span&gt;&lt;span class="si"&gt;%.2f&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;slr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X2_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Plot&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X2_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X2_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;slr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X2_test&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;blue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;linewidth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xticks&lt;/span&gt;&lt;span class="p"&gt;(())&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;yticks&lt;/span&gt;&lt;span class="p"&gt;(())&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Multiple linear regression&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Data partitioning&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Train&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LinearRegression&lt;/span&gt;
&lt;span class="n"&gt;mlr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LinearRegression&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;mlr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# The coefficients&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Coefficients: &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mlr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coef_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# mean square error&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;RSS: &lt;/span&gt;&lt;span class="si"&gt;%.2f&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;mlr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c"&gt;# Explained variance score: 1 is perfect prediction&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Variance score: &lt;/span&gt;&lt;span class="si"&gt;%.2f&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;mlr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;Example source: &lt;a href="http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html"&gt;Linear regression example&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;[Tip] How to write a data mining proposal&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Choosing a good project topic&lt;ol&gt;
&lt;li&gt;이 문제를 푸는 것이 의미가 있는가 (있다면 어떤 의미가 있는가?)&lt;/li&gt;
&lt;li&gt;데이터를 구할 수 있는가 (어디서 구할 수 있는가? 정제는 되어 있는가?)&lt;/li&gt;
&lt;li&gt;어떤 접근법/방법론을 사용할 것인가? (내가 주어진 시간 안에 할 수 있는가? 원하는 것을 전부 할 수 없다면, 내가 할 수 있는 범위는 어디까지인가?)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary></entry><entry><title>파이썬 프로그래밍을 위한 Sublime Text</title><link href="http://lucypark.kr/courses/tips/sublime-text.html" rel="alternate"></link><updated>2015-03-09T13:26:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-09:courses/tips/sublime-text.html</id><summary type="html">&lt;h2&gt;Installation&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Sublime Text 설치&lt;br&gt;
&lt;a href="http://sublimetext.com"&gt;&lt;img alt="sublime" src="images/sublime.png" /&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://packagecontrol.io/installation#st2"&gt;Sublime Text 패키지 매니저&lt;/a&gt; 설치&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;내가 설치한 Sublime Text의 버젼을 잘 확인하자! 2인가 3인가?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Suggested packages&lt;/h2&gt;
&lt;h3&gt;IMESupport: 한글 입력이 한 박자 늦게 되는 문제 해결&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://meaningone.tistory.com/116"&gt;&lt;strong&gt;IMESupport&lt;/strong&gt; 패키지 설치&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Origami: Divide window to several panes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;방법 1.&lt;br&gt;
&lt;img src="images/pane.png" width="500px"&gt;&lt;/li&gt;
&lt;li&gt;방법 2. Install the &lt;strong&gt;Origami&lt;/strong&gt; package (훨씬 다양하게 pane을 나눠 쓸 수 있음)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;SublimeREPL: Python REPL in Sublime&lt;/h3&gt;
&lt;p&gt;&lt;img src="images/repl.png" width="500px"&gt;&lt;/p&gt;</summary></entry><entry><title>Introduction to Python (on Windows)</title><link href="http://lucypark.kr/courses/tips/introduction-to-python.html" rel="alternate"></link><updated>2015-03-08T18:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-08:courses/tips/introduction-to-python.html</id><summary type="html">&lt;h2&gt;오늘의 목표&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;나도 할 수 있다, 프로그래밍!&lt;ul&gt;
&lt;li&gt;왜?&lt;/li&gt;
&lt;li&gt;뭐든지 잘할 수 있어야 재밌고 재밌어야 잘할 수 있고 잘 해야 재밌음.&lt;/li&gt;
&lt;li&gt;일단 나도 할 수 있다는 자신감을 느껴보고 더불어 신기함과 재미도 느껴보자!&lt;/li&gt;
&lt;li&gt;&lt;s&gt;간지도 좀 남&lt;/s&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="programmer" src="https://s-media-cache-ak0.pinimg.com/236x/7b/b7/06/7bb706cc6f2ac6e62c58b299acf3f362.jpg" /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;이 튜토리얼은 프로그래밍 초보자를 대상으로 하는 것이기는 하지만, for문, if문, 변수 등 프로그래밍의 기본적인 개념은 숙지하고 있다고 가정하고 진행됩니다. 만일 이게 무슨 말인지 모르겠다면 &lt;a href="http://doc.pyschools.com/html/index.html"&gt;이 링크&lt;/a&gt;에서 간단히 공부해보세요 :)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;들어가기 전에&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;운영체제(OS)란?&lt;ul&gt;
&lt;li&gt;&lt;a href="http://ko.wikipedia.org/wiki/%EC%9A%B4%EC%98%81_%EC%B2%B4%EC%A0%9C"&gt;"시스템 하드웨어와 소프트웨어를 실행하기 위한 시스템 소프트웨어"&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;ex: 윈도우 7, Mac OS 10.10, Ubuntu 14.04, iOS 6, Android 5.0, ...&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;프로그래밍을 하기 전에는 내가 어떤 OS의 어떤 버젼을 사용하고 있는지 꼭 알아두자!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;여기서는 윈도우 7을 사용하고 있다는 가정 하에 튜토리얼을 진행합니다.&lt;/strong&gt;&lt;br&gt;
&lt;img src="http://www.tutorialspoint.com/images/os-mini-logo.png"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;쉘(shell)이란?&lt;ul&gt;
&lt;li&gt;&lt;a href="http://ko.wikipedia.org/wiki/%EC%85%B8"&gt;"운영체제 상에서 다양한 운영체제 기능과 서비스를 구현하는 인터페이스를 제공하는 프로그램"&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;운영체제의 핵심 부분을 구성하는 "커널(kernel)"을 감싸고 있다는 뜻에서 "쉘"이라는 이름이 붙었죠&lt;br&gt;
&lt;a href="http://www.quora.com/What-is-the-origin-of-the-name-shell"&gt;&lt;img src="images/kernel.gif" width="250px"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;GUI? CLI?&lt;ul&gt;
&lt;li&gt;GUI는 graphic user interface의 약자로, 그래픽으로 컴퓨터를 조작할 수 있게 해준다. &lt;a href="http://en.wikipedia.org/wiki/Windows_shell"&gt;윈도우 쉘&lt;/a&gt;이 대표적인 graphic shell이다.&lt;br&gt;
&lt;img src="http://upload.wikimedia.org/wikipedia/en/b/bd/Windows_7.png" width="500px"&gt;&lt;/li&gt;
&lt;li&gt;CLI는 command line interface의 약자로, 텍스트로 컴퓨터를 조작할 수 있게 해준다. 윈도우에서는 &lt;a href="http://en.wikipedia.org/wiki/Cmd.exe"&gt;명령 프롬프트&lt;/a&gt;가 대표적인 text shell이다.&lt;br&gt;
&lt;img src="http://upload.wikimedia.org/wikipedia/commons/1/10/Dir_command_in_Windows_Command_Prompt.png" width="500px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;왜 파이썬인가?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://blog.trinket.io/why-python/"&gt;파이썬은, 처음 배우는 프로그래밍 언어로써 좋다&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Python is now the most popular introductory language at Top US Universities (July, 2014)&lt;br&gt;
&lt;a href="http://cacm.acm.org/blogs/blog-cacm/176450-python-is-now-the-most-popular-introductory-teaching-language-at-top-us-universities/fulltext"&gt;&lt;img src="images/python.png" width="400px"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.stat.washington.edu/~hoytak/blog/whypython.html"&gt;파이썬은, 연구용 언어로써 좋다&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Python is a major programming language for data mining (Aug, 2014)&lt;br&gt;
&lt;a href="http://www.kdnuggets.com/2014/08/four-main-languages-analytics-data-mining-data-science.html"&gt;&lt;img src="images/kdnuggets.jpg" width="350px"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;What's so great about Python?&lt;/h3&gt;
&lt;p&gt;이번 시간에 계속 살펴보겠지만, 파이썬의 문법은 아주 간결하고 읽기 편합니다.
게다가 &lt;a href="https://docs.python.org/"&gt;문서화&lt;/a&gt;가 아주 상세하게 잘 되어 있어서 배우기도 쉽고요.&lt;/p&gt;
&lt;p&gt;하지만 파이썬이 모든 경우에 가장 좋은 언어라고 할 수는 없습니다.
특히, 파이썬이 현존하는 모든 태스크를 위해 가장 적합하게 설계된 언어는 아닙니다.
&lt;!-- 프로그래밍 언어는 그 자체로 기술(technology, 技術)이라기보다는 아이디어를 표현하는 기술법(description, 記述)이며 각 태스크에 적합한 언어는 따로 있습니다.  (적어도 2015년 현재에는 그런듯합니다) --&gt;&lt;/p&gt;
&lt;p&gt;비유를 한 번 들어볼까요?
나무를 베고, 못을 박고, 나사를 돌릴 때 여러분은 아래에 있는 도구 중 어떤 것을 선택하겠습니까?
&lt;img src="http://upload.wikimedia.org/wikipedia/commons/d/df/Saw%2C_hammer%2C_screwdriver%2C_wrench%2C_pliers.png"&gt;&lt;/p&gt;
&lt;p&gt;보통은 나무를 벨 때 톱을, 못을 박을 때는 망치를, 나사를 돌릴 때는 드라이버를 사용하겠죠.
프로그래밍 언어도 도구여서, 목적에 따라 다른 도구를 사용하는 것이 좋을 때가 있습니다.
가령, 웹에 시각화를 올리기 위해서는 자바스크립트가, 구조적 데이터를 다룰 때는 R이 더 편할 수도 있는거죠.&lt;/p&gt;
&lt;p&gt;한편 파이썬은 특정 목적에 적합한 언어라기보다는 범용으로 사용할 수 있는 언어(general purpose language)입니다.&lt;br&gt;
일종의 Swiss army knife와 같은거죠.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Wenger_EvoGrip_S17.JPG/440px-Wenger_EvoGrip_S17.JPG"&gt;&lt;/p&gt;
&lt;p&gt;실제로 파이썬의 다양한 3rd-party 패키지들을 사용하면 웹에 시각화를 올린다든지 구조적인 데이터를 다루는 일 등을 할 수 있습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;시각화: matplotlib, mpld3&lt;/li&gt;
&lt;li&gt;웹프로그래밍: requests, django, flask&lt;/li&gt;
&lt;li&gt;구조적 데이터 분석: numpy, scipy, scikit-learn&lt;/li&gt;
&lt;li&gt;비구조적 데이터 분석 (또는 자연어 처리): nltk, konlpy&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;하지만 Swiss army knife가 때로는 망치만큼의 강건함이나 만족스러움을 주지 못하듯, 파이썬도 마찬가지 일 수 있습니다.&lt;br&gt;
그럴 때는 망치를 구하시면 됩니다! (i.e., JavaScript, R 등 새로운 스킬/도구/언어를 또 습득하시면 됩니다! 하지만 그건 이 수업 말고 다른 기회에...)&lt;/p&gt;
&lt;p&gt;게다가 파이썬에는 활발한 개발 커뮤니티가 있습니다.
&lt;a href="https://www.python.org/dev/peps/pep-0001/"&gt;PEP&lt;/a&gt;, 즉 Python enhancement proposal이라고 누구나 파이썬 언어 자체에 대한 제안을 할 수도 있고
아래와 같이 유저(user) 커뮤니티들도 활발하게 돌아가고 있습니다.
개발을 하다가 질문이 있을 때는 아래 커뮤니티들을 적극 활용해보세요!&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.facebook.com/groups/pythonkorea/"&gt;파이썬 코리아 페이스북 그룹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.facebook.com/groups/codingeverybody/"&gt;생활코딩 페이스북 그룹&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.facebook.com/pyjog"&gt;파이조그(PyJog)&lt;/a&gt;: 이 커뮤니티는 오프라인 커뮤니티입니다. 고수님들을 직접 만날 기회이니 프로그래밍을 더 잘해보고 싶은 분은 한 번쯤 참석해보시기 바랍니다.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;요약하자면, 파이썬은 아래와 같은 장점들이 있습니다:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;쉽다&lt;/li&gt;
&lt;li&gt;간결하고 읽기 쉽다 (readability)&lt;/li&gt;
&lt;li&gt;문서화가 잘 되어 있다 (documentation)&lt;/li&gt;
&lt;li&gt;라이브러리/패키지가 풍부하다&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.python.org/community/"&gt;개발 커뮤니티&lt;/a&gt;가 활발하다&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Then is Python the best programming language for data mining?&lt;/h3&gt;
&lt;!-- No, and [there probably will never be such a thing](http://paulgraham.com/hundred.html) --&gt;

&lt;p&gt;데이터마이너는 가장 핵심이 되는 데이터 분석 뿐 아니라, 앞 단의 데이터 수집이나 데이터 정제부터, 데이터 시각화까지
넓은 영역의 태스크들을 수행하게 됩니다.&lt;/p&gt;
&lt;p&gt;데이터마이닝을 배우는 이 강좌에서 파이썬을 주 언어로 택한 이유는
파이썬이 데이터마이닝을 위해 가장 좋은 언어이거나, 데이터마이닝의 특정 태스크를 수행하는데 가장 좋기 때문은 아닙니다.
다만, 좋은 Swiss army knife를 마련해서 도구는 빨리 습득하고,
여러분이 데이터마이닝 알고리즘들 자체에 조금 더 focus할 수 있게 하기 위함입니다.&lt;/p&gt;
&lt;p&gt;게다가 덤으로, 좋은 프로그래밍 언어를 습득함으로써 프로그래밍 자체에 대한 이해를 높이고 흥미를 느낄 수 있으면 좋겠죠!&lt;/p&gt;
&lt;p&gt;자, 그럼 시작해볼까요 :)&lt;/p&gt;
&lt;h2&gt;Installing Python&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;윈도우에서 자바 프로그래밍 환경을 마련하는 일반적인 절차는?&lt;ul&gt;
&lt;li&gt;1단계: &lt;a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html"&gt;자바 개발 키트 (JDK)&lt;/a&gt; 설치 (2015년 3월 현재, JDK 8u40 배포중)&lt;/li&gt;
&lt;li&gt;2단계: 환경변수 설정 (ex: &lt;code&gt;JAVA_HOME&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;3단계: 자바 IDE 설치 (ex: &lt;a href="https://eclipse.org/"&gt;이클립스&lt;/a&gt;, &lt;a href="https://www.jetbrains.com/idea/"&gt;IntelliJ IDEA&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;윈도우에서 R 프로그래밍 환경을 마련하는 일반적인 절차는?&lt;ul&gt;
&lt;li&gt;1단계: &lt;a href="http://cran.r-project.org/"&gt;R 배포판&lt;/a&gt; 설치 (2015년 3월 현재, R 3.1.2 배포중)&lt;/li&gt;
&lt;li&gt;2단계: R IDE 설치 (ex: &lt;a href="http://rstudio.com"&gt;RStudio&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;윈도우에서 파이썬 프로그래밍 환경을 마련하는 일반적인 절차는?&lt;ul&gt;
&lt;li&gt;1단계: &lt;a href="http://python.org/download"&gt;파이썬 배포판&lt;/a&gt; 설치&lt;/li&gt;
&lt;li&gt;2단계: 파이썬 IDE 설치&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;자, 그럼 시작해봅시다!&lt;/p&gt;
&lt;h3&gt;1단계: 파이썬 배포판 설치&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Download &lt;a href="http://continuum.io/downloads#34"&gt;Continuum's Anaconda&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;잠깐, &lt;a href="http://python.org/download"&gt;python.com&lt;/a&gt;이 아니라 딴데서 설치파일을 다운받으라고?&lt;ul&gt;
&lt;li&gt;python.com/download: 파이썬 정식 배포판&lt;/li&gt;
&lt;li&gt;continuum.io/downloads#34: 파이썬 사제 배포판&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;파이썬 정식 배포판이 아니라 일반 회사의 사제 배포판을 사용하는 이유는?&lt;ul&gt;
&lt;li&gt;Windows에서는 파이썬의 몇몇 패키지 설치가 어렵다는 풍문이 있다&lt;/li&gt;
&lt;li&gt;이를 극복하기 위해 &lt;a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/"&gt;윈도우만을 위해 사전에 컴파일 된 패키지를 따로 제공하는 사람도 있다&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;우리는 패키지 설치의 번거로움에서 벗어나기 위해 사전에 &lt;a href="http://docs.continuum.io/anaconda/pkg-docs.html"&gt;195개의 패키지&lt;/a&gt;가 한꺼번에 깔리는 배포판을 선택
&lt;img src="images/anaconda.png" width="600px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;윈도우 32비트? 64비트?&lt;ul&gt;
&lt;li&gt;아나콘다가 알아서 인식해서 잡아주지 않을 수도 있으니, 확실하지 않다면 &lt;a href="images/bit.png"&gt;내 컴퓨터의 속성 메뉴에서 나의 시스템 종류를 확인하자&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://wiki.python.org/moin/Python2orPython3"&gt;Python 2.x? 3.x?&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;아직까지 학계에서는 Python 2도 많이 사용&lt;/li&gt;
&lt;li&gt;하지만 우리는 더 최신 버젼인 Python 3 선택&lt;ol&gt;
&lt;li&gt;파이썬 3가 유니코드 서포트를 해서 한국어를 사용하는 사람들에게 편리&lt;/li&gt;
&lt;li&gt;&lt;a href="http://python3wos.appspot.com/"&gt;이제 많은 패키지들이 파이썬 3도 지원&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;파이썬 3 is &lt;a href="http://pythonkr.github.io/pyconkr-2014/pdf/pyconkr-2014-25_geofront.pdf"&gt;the way to go&lt;/a&gt;
&lt;!-- - 그리고 자꾸 패키지, 패키지하는데 패키지가 뭔가요? --&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Install Anaconda&lt;ul&gt;
&lt;li&gt;고맙게도 파이썬 경로에 대한 환경변수 설정은 따로 할 필요없이 아나콘다가 알아서 해줌&lt;br&gt;
&lt;img src="images/anaconda2.png" width="400px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run Python!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;다음과 같이 터미널을 열자:&lt;ol&gt;
&lt;li&gt;&lt;code&gt;window&lt;/code&gt; + &lt;code&gt;r&lt;/code&gt; 단축키를 이용해 실행창(Run)을 열고&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cmd&lt;/code&gt;라고 입력한다.&lt;br&gt;
&lt;img src="images/cmd.png" width="400px"&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;터미널에 &lt;code&gt;ipython&lt;/code&gt;을 입력해서 "파이썬 쉘"을 열어보자.&lt;br&gt;
    터미널로 작업할 때는 열심히 "독서"하는 습관을 들이는 것이 좋다.
    우리가 &lt;code&gt;ipython&lt;/code&gt;을 입력하니 무엇이 출력되었는가?
    파이썬 버젼 3.4.1, 64비트 아나콘다 2.1.0이 구동되었다는 것을 알 수 있고, 그 밖의 소소한 명령어에 대한 소개도 있다.&lt;br&gt;
    &lt;img src="images/ipython.png" width="500px"&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;파이썬 쉘이 열리면:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Hello world!&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Hello&lt;/span&gt; &lt;span class="n"&gt;world&lt;/span&gt;&lt;span class="err"&gt;!&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="mf"&gt;0.3333333333333333&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt;

&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt; &lt;span class="nb"&gt;exit&lt;/span&gt;    &lt;span class="c"&gt;# exit을 입력하는 대신 단축키 ctrl+d를 사용할 수도 있다&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now you're a Python programmer! (적어도 계산기로는 쓸 수 있다)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;1.5단계: 파이썬 스크립트 실행&lt;/h3&gt;
&lt;p&gt;위와 같이 파이썬을 쉘(shell)에서 실행하는 것은 순간적인 실행을 위해서는 아주 편리하지만,
긴 프로그램을 짜고자 할 때, 또는 프로그램을 저장하고자 할 때는 적합하지 않다.
이럴 때는 스크립트(script) 파일을 이용해서 파이썬을 실행할 수도 있다.&lt;/p&gt;
&lt;p&gt;스크립트 파일 실행을 위해 PyCharm, Eclipse 등의 IDE를 활용할 수도 있지만,
일단은 IDE없이 한 번 가보자.&lt;/p&gt;
&lt;p&gt;먼저 프로그래밍의 기본! 파이썬 스크립트를 만들어 Hello world를 출력해볼까?
이미 우리는 ipython을 통해 파이썬 쉘에서 Hello world를 출력해봤지만 
다음의 몇 가지 절차를 거치면 파일을 이용해 파이썬 스크립트를 실행할 수 있다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;아래와 같이 윈도우에서 메모장을 열자.&lt;ol&gt;
&lt;li&gt;&lt;code&gt;window&lt;/code&gt; + &lt;code&gt;r&lt;/code&gt; 단축키를 이용해 실행창(Run)을 열고&lt;/li&gt;
&lt;li&gt;&lt;code&gt;notepad&lt;/code&gt;라고 입력한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;다음의 헬로월드 출력문을 파일에 입력한 후&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Hello world!&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;파일을 바탕화면에 &lt;code&gt;test.py&lt;/code&gt;라는 이름으로 저장하자. 다만 한 가지 유의할 점은, &lt;strong&gt;다음 그림과 같이 Encoding을 UTF-8로 변경해서 저장해줘야 한다.&lt;/strong&gt; (그렇지 않으면 스크립트를 실행할 때 인코딩 에러가 발생할 것이다.)&lt;br&gt;
&lt;img src="images/notepad.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;그 다음에, 다시 터미널을 띄워서 (앞에서 어떻게 했는지 기억하는가?)&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;아래와 같이 입력하면 파이썬 파일이 실행된다.&lt;br&gt;
첫번째 줄은 윈도우 탐색기에서 "바탕화면"으로 이동하라는 버튼을 누른 것과 같고, 두번째 줄은 윈도우 탐색기에서 &lt;code&gt;test.py&lt;/code&gt; 파일을 클릭하여 실행한 것과 같다. 멋지지 않은가? 이제 우리도 마우스를 클릭하는 GUI(graphic user interface)가 아니라 키보드로 명령어를 입력하는 CLI(command line interface)에서 프로그래밍을 할 수 있게 된 것이다!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&amp;gt; &lt;span class="nb"&gt;cd &lt;/span&gt;Desktop        &lt;span class="c"&gt;# Desktop이라는 디렉토리로 변경하라(change directory)&lt;/span&gt;
&amp;gt; python test.py    &lt;span class="c"&gt;# python이라는 프로그램으로 test.py라는 파일을 실행하라&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;이제부터 파이썬에서 빈번하게 사용할 기능을 7가지 예시를 통해 배워볼 것이다.&lt;br&gt;
방금 생성한 &lt;code&gt;test.py&lt;/code&gt;에서 Hello world! 출력문 대신 아래의 다양한 예시를 입력해보자.
이미 Desktop 폴더로 이동한 상태이니 &lt;strong&gt;앞으로는 터미널에 &lt;code&gt;python test.py&lt;/code&gt;만 입력해서 코드를 실행하면 된다.&lt;/strong&gt;
각 예시는 이해를 돕기 위해 자바 1.7의 코드와 병렬적으로 배치해두었다.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;예시 1: "Hello world"&lt;/h4&gt;
&lt;p&gt;앞에서 우리는 파이썬 쉘과 스크립트로 Hello world!를 출력하는데 성공했다.
우리의 파이썬 코드와 자바 코드에는 어떤 차이점이 있을까?
다음은 자바와 파이썬으로 각각 Hello world!를 출력하는 코드이다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Java 1.7&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;MyClass&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Hello world!&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Python 3&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Hello world!&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;자바와 파이썬 코드에 어떤 차이점이 있는가? 자바 코드와는 달리 파이썬 코드에서는:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;public class MyClass { ... }&lt;/code&gt; 등과 같이 클래스를 선언하지 않아도 된다.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;public static void main (String[] args) { ... }&lt;/code&gt; 등과 같이 메인함수를 선언하지 않아도 된다.&lt;/li&gt;
&lt;li&gt;라인 끝에 세미콜론(&lt;code&gt;;&lt;/code&gt;)을 붙이지 않아도 된다.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;그리하여 파이썬으로는 무려 한 줄 만으로 Hello world!를 출력할 수 있다!
아주 간결하지 않은가?&lt;/p&gt;
&lt;h4&gt;예시 2: 변수 선언&lt;/h4&gt;
&lt;p&gt;다음으로 변수를 선언해보자.
&lt;code&gt;print&lt;/code&gt;문을 이용해 출력하는 것이 없다면 변수를 선언하는 것만으로는 터미널 창에 아무 것도 뜨지 않겠지만,
변수 선언만으로도 중요한 차이점을 많이 발견할 수 있으니 코드는 한 번 자세히 들여다보자.
다음은 자바와 파이썬으로 각각 변수를 선언하는 코드이다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Java 1.7 (static typed)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;myString&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;this is a string&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="n"&gt;myString&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;3&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;//  ok&lt;/span&gt;
&lt;span class="n"&gt;myString&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sc"&gt;&amp;#39;3&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;//  Type mismatch: cannot convert from char to String&lt;/span&gt;
&lt;span class="n"&gt;myString&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;   &lt;span class="c1"&gt;//  Type mismatch: cannot convert from int to String&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Python 3 (dynamic typed)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;my_string&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;this is a string&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;my_string&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;3&amp;quot;&lt;/span&gt; &lt;span class="c"&gt;# ok&lt;/span&gt;
&lt;span class="n"&gt;my_string&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;3&amp;#39;&lt;/span&gt; &lt;span class="c"&gt;# ok&lt;/span&gt;
&lt;span class="n"&gt;my_string&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="c"&gt;# ok&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이미 위에서 언급된 차이점들 외에도 크게 네 가지 차이점을 발견할 수 있다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;자바는 &lt;a href="http://en.wikipedia.org/wiki/Type_system#Static_type-checking"&gt;정적 타이핑(static typing)&lt;/a&gt;언어라 변수의 데이터 타입(type), 즉 String인지 int인지 등을 미리 지정해줘야하고, 한 번 지정하고 나면 변수의 타입은 바뀔 수 없다. 반면 파이썬은 &lt;a href="http://en.wikipedia.org/wiki/Type_system#DYNAMIC"&gt;동적 타이핑(dynamic typing)&lt;/a&gt; 언어라 변수의 데이터 타입(type) 선언할 필요도 없을 뿐더러 처음 선언이 된 이후에도 다른 타입으로 바뀔 수 있다.&lt;/li&gt;
&lt;li&gt;자바에서는 작은 따옴표(&lt;code&gt;char&lt;/code&gt;)와 큰 따옴표(&lt;code&gt;String&lt;/code&gt;)의 사용이 구분되지만 파이썬에서는 작은 따옴표나 큰 따옴표로 묶인 문자열은 전부 &lt;code&gt;str&lt;/code&gt; 타입으로 간주된다.&lt;/li&gt;
&lt;li&gt;자바 코드에서는 변수를 선언할 때 &lt;code&gt;myString&lt;/code&gt;과 같이 &lt;a href="http://en.wikipedia.org/wiki/CamelCase"&gt;camelCase&lt;/a&gt;를 사용하는데 반해 파이썬 코드에서는 &lt;code&gt;my_string&lt;/code&gt;과 같이 &lt;a href="http://en.wikipedia.org/wiki/Naming_convention_(programming)#Python_and_Ruby"&gt;under_score&lt;/a&gt;를 사용한다. 파이썬의 스타일링에 관해서는 &lt;a href="https://www.python.org/dev/peps/pep-0008/"&gt;PEP-8&lt;/a&gt;에 잘 나와 있다. 만일 파이썬 프로그래밍을 꾸준히 할 마음이 있다면 한 번쯤 훑어보자. 이 문서를 지금 당장 다 읽지 않더라도, 중요한 지침을 담고 있으니 반드시 이름은 기억해두는 것이 좋다.&lt;/li&gt;
&lt;li&gt;주석을 다는 방법이 다르다. 자바에서는 &lt;code&gt;//&lt;/code&gt; 썼다면, 파이썬에서는 &lt;code&gt;#&lt;/code&gt;를 쓴다. 긴 주석의 경우에도 자바는 &lt;code&gt;/* some very long comment */&lt;/code&gt;라면, 파이썬은 &lt;code&gt;""" some very long comment """&lt;/code&gt;와 같다. (긴 주석 내에서는 줄바꿈을 할 수 있다.)&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;예시 3: 파일 쓰기 (writing)&lt;/h4&gt;
&lt;p&gt;아래는 &lt;code&gt;some_file.txt&lt;/code&gt;에 "Hello world full of data!"라는 문자열을 입력하는 코드이다.
자바에서 파일 입출력(I/O)은 생각만큼 간단하지 않지만, 파이썬에서는 무척 간단하다.
코드를 이렇게 읽어보자: &lt;code&gt;"some_file.txt"&lt;/code&gt;를 &lt;code&gt;"w"&lt;/code&gt;(write) 모드로 &lt;code&gt;open&lt;/code&gt;하고 그것을 &lt;code&gt;f&lt;/code&gt;라고 부르자.
그리고 &lt;code&gt;f&lt;/code&gt;에는 &lt;code&gt;"Hello world full of data!"&lt;/code&gt;라는 문자열을 &lt;code&gt;write&lt;/code&gt;하자!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Java 1.7&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.io.*&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;WriteFile&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="kd"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;IOException&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;Writer&lt;/span&gt; &lt;span class="n"&gt;writer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;writer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;BufferedWriter&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;OutputStreamWriter&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;
                  &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;FileOutputStream&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;some_file.txt&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
            &lt;span class="n"&gt;writer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;write&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Hello world full of data!&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt; &lt;span class="k"&gt;catch&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;IOException&lt;/span&gt; &lt;span class="n"&gt;ex&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;An exception occurred during writing file.&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt; &lt;span class="k"&gt;finally&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="n"&gt;writer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;close&lt;/span&gt;&lt;span class="o"&gt;();}&lt;/span&gt; &lt;span class="k"&gt;catch&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Exception&lt;/span&gt; &lt;span class="n"&gt;ex&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{}&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Python 3&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;some_file.txt&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;w&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Hello world full of data!&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;예시 4: 파일 읽기 (reading)&lt;/h4&gt;
&lt;p&gt;이미 바탕화면에는 &lt;code&gt;some_file.txt&lt;/code&gt;라는 파일이 생겼을 것이다. 한 번 확인해보자.
만일 &lt;code&gt;test.py&lt;/code&gt; 파일을 바탕화면이 아니라 다른 폴더 안에 저장했다면, &lt;code&gt;some_file.txt&lt;/code&gt;는 그 폴더 안에 있을 것이다.&lt;/p&gt;
&lt;p&gt;이번에는 그 파일의 내용을 읽어보자.
아마도 "Hello world full of data!"가 출력되겠지?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Java 1.7&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.io.BufferedReader&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.io.FileReader&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.io.IOException&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ReadFile&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="kd"&gt;throws&lt;/span&gt; &lt;span class="n"&gt;IOException&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;BufferedReader&lt;/span&gt; &lt;span class="n"&gt;br&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;BufferedReader&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;FileReader&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;some_file.txt&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;StringBuilder&lt;/span&gt; &lt;span class="n"&gt;sb&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;StringBuilder&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
            &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;br&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;readLine&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;

            &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
                &lt;span class="n"&gt;sb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;append&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
                &lt;span class="n"&gt;sb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;append&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;lineSeparator&lt;/span&gt;&lt;span class="o"&gt;());&lt;/span&gt;
                &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;br&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;readLine&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
            &lt;span class="o"&gt;}&lt;/span&gt;
            &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;everything&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;toString&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
            &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;everything&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt; &lt;span class="k"&gt;finally&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;br&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;close&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Python 3&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;some_file.txt&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;r&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;예시 5: HashMap 또는 Dictionary&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Key&lt;/strong&gt;와 &lt;strong&gt;value&lt;/strong&gt;로 이루어진 데이터 타입을 자바에서는 HashMap, 파이썬에서는 &lt;a href="https://docs.python.org/3/tutorial/datastructures.html#dictionaries"&gt;dictionary&lt;/a&gt;라고 부른다.
Dictionary는 1) key가 unique하다는 점과 2) item에 순서가 없다는 점이 독특하다. Dict에 대한 상급 활용법이 궁금한 사람은 &lt;a href="https://speakerdeck.com/jongman/2014-pycon-kr-widaehan-dict-ihaehago-sayonghagi"&gt;이 곳&lt;/a&gt;을 살펴보자.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Java 1.7&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.*&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;HashTest&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="c1"&gt;// create hashmap&lt;/span&gt;
        &lt;span class="n"&gt;HashMap&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;studentIds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;HashMap&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;();&lt;/span&gt;
        &lt;span class="n"&gt;studentIds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;put&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;홍길동&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;13083301&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;studentIds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;put&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;김미자&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;11030104&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;studentIds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;put&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;박은정&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;11121994&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

        &lt;span class="c1"&gt;// iterate over hashmap&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Map&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;Entry&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;studentIds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;entrySet&lt;/span&gt;&lt;span class="o"&gt;())&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Key: &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getKey&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;, Value: &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getValue&lt;/span&gt;&lt;span class="o"&gt;());&lt;/span&gt;
        &lt;span class="o"&gt;}&lt;/span&gt;

        &lt;span class="c1"&gt;// get keys&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;studentIds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;keySet&lt;/span&gt;&lt;span class="o"&gt;());&lt;/span&gt;

        &lt;span class="c1"&gt;// get value for key&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;studentIds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;get&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;박은정&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Python 3&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# -*- coding: utf-8 -*-&lt;/span&gt;

&lt;span class="c"&gt;# create dictionary&lt;/span&gt;
&lt;span class="n"&gt;student_ids&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;홍길동&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;13083301&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="s"&gt;&amp;quot;김미자&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;11030104&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="s"&gt;&amp;quot;박은정&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;11121994&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c"&gt;# iterate over hashmap&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;student_ids&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Key: &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;, Value: &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# get keys&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;student_ids&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;

&lt;span class="c"&gt;# get value for key&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;student_ids&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;박은정&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;앞서 살펴본 예시와는 달리 아래 파이썬 코드의 상단에 &lt;code&gt;# -*- coding: utf-8 -*-&lt;/code&gt;이라는 특이한 줄이 생긴 것을 볼 수 있다.
이 줄은 &lt;a href="https://www.python.org/dev/peps/pep-0263/"&gt;PEP 263&lt;/a&gt;에 의해 제안된 것으로,
프로그램 상으로는 역할을 하지 않지만 코드에 영문 알파벳 등 기본적인 ASCII 문자 외에 다른 문자(ex: 한글)가 코드에 있는 경우 반드시 필요한 줄이다.
우리는 앞서 파일을 OS간 호환성을 위해 UTF-8으로 인코딩하여 저장했으므로, 파일이 UTF-8로 되어 있다고 선언한다.
만일 앞에서 파일을 UTF-8으로 저장하지 않았다면, 윈도우의 시스템 인코딩인 cp949로 선언해야 인코딩 에러를 피할 수 있을 것이다.
(만일 cp949로 선언해도 인코딩 에러가 발생한다면, 터미널에서 &lt;code&gt;chcp&lt;/code&gt;를 입력하여 내가 어떤 코드 페이지를 사용하고 있는지 확인하자.)
앞으로 고생을 덜기 위해 (그리고 다양한 프로그래밍 환경에서 작업하는 사람들과 원활하게 협업하기 위해) 다음의 두 가지는 습관화하는 것이 좋다:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;파이썬 스크립트를 저장할 때 UTF-8 인코딩을 지정하고&lt;/li&gt;
&lt;li&gt;파이썬 스크립트 최상단에 &lt;code&gt;# -*- coding: utf-8 -*-&lt;/code&gt;과 같은 방식으로 인코딩을 명시하자.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;예시 6: Array 또는 List&lt;/h4&gt;
&lt;p&gt;순서가 존재하는 데이터 타입인 배열(array)은 어떻게 선언할까?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Java 1.7&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;java.util.ArrayList&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ArrayTest&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="c1"&gt;// create arraylist&lt;/span&gt;
        &lt;span class="n"&gt;ArrayList&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;myList&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;ArrayList&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;();&lt;/span&gt;
        &lt;span class="n"&gt;myList&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;add&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;a&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;myList&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;add&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;b&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;myList&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;add&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;c&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;myList&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;add&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;d&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;myList&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;add&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;e&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;myList&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

        &lt;span class="c1"&gt;// get item in arraylist&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;myList&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;get&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;

        &lt;span class="c1"&gt;// split arraylist&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;myList&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;subList&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="o"&gt;));&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Python 3&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# create list&lt;/span&gt;
&lt;span class="n"&gt;my_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;b&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;c&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;d&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;e&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;my_list&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# get item in list&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;my_list&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;   &lt;span class="c"&gt;# returns &amp;#39;d&amp;#39;&lt;/span&gt;

&lt;span class="c"&gt;# split list&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;my_list&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="c"&gt;# returns [&amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;, &amp;#39;d&amp;#39;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;많은 프로그래밍 언어는 배열에 속하는 item의 번호, 즉 &lt;a href="https://plus.google.com/115212051037621986145/posts/YTUxbXYZyfi"&gt;index를 매길 때 1이 아니라 0부터 시작한다&lt;/a&gt;.
그러니까 위의 &lt;code&gt;my_list&lt;/code&gt;에서 item 'a'의 index는 0, item 'b'의 index는 1, item 'e'의 index는 4이다.
이 때 &lt;code&gt;my_list[3]&lt;/code&gt;이라고 입력하면 index 값이 3인 item을 가져오라는 뜻이며, 따라서 'd'를 출력한다.
한편 list를 분할할 때는 &lt;code&gt;my_list[1:4]&lt;/code&gt;라고 입력하는데, 이는 index가 1인 item부터 index가 4인 item _직전_까지 가져오라는 의미이다.
list 분할은 데이터 분석에서 데이터를 두 개 이상의 set으로 partitioning할 때 활용할 수 있다.
가령 위의 &lt;code&gt;my_list&lt;/code&gt;를 ['a', 'b', 'c']와 ['d', 'e']로 나누는 것은 아래와 같이 다양한 방식으로 할 수 있다. (세 경우 모두 같은 결과를 낳는다)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;p1, p2 = my_list[0:3], my_list[3:5]&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;p1, p2 = my_list[:3], my_list[3:]&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;p1, p2 = my_list[:-2], my_list[-2:]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;위에서 볼 수 있듯 &lt;code&gt;my_list[:4]&lt;/code&gt;라고 입력하면 처음부터 index가 4인 item _직전_까지 반환하고
&lt;code&gt;my_list[1:]&lt;/code&gt;을 입력하면 index가 1인 item부터 마지막 item까지 반환한다.
음수 index를 명시하면 마지막에서부터 index를 세게 되는데,
(위 예시의 경우 배열의 길이인 &lt;code&gt;len(my_list)&lt;/code&gt;에서 2를 뺀 값)
이것도 아주 편리하게 이용되는 기능이다.&lt;/p&gt;
&lt;h4&gt;예시 7: 클래스(class)와 상속(inheritance)&lt;/h4&gt;
&lt;p&gt;예시 1에서도 설명했지만, 파이썬에서는 클래스를 반드시 선언해주지는 않아도 된다.
하지만, 클래스가 유용한 경우는 종종 있고, 파이썬에서도 클래스를 만들 수 있다.
아래 코드를 참고하자.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Java 1.7&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Animal&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kd"&gt;protected&lt;/span&gt; &lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="nf"&gt;Animal&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;this&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;saySomething&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;I am a &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;.&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Dog&lt;/span&gt; &lt;span class="kd"&gt;extends&lt;/span&gt; &lt;span class="n"&gt;Animal&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="nf"&gt;Dog&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="kd"&gt;super&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;saySomething&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;System&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;println&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;I am a &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;. Bark, bark!&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ClassTest&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="kd"&gt;public&lt;/span&gt; &lt;span class="kd"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="o"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;Dog&lt;/span&gt; &lt;span class="n"&gt;dog&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;Dog&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Chiwawa&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;dog&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;saySomething&lt;/span&gt;&lt;span class="o"&gt;();&lt;/span&gt;
    &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Python 3&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Animal&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;say_something&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;I am a &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Dog&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Animal&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;say_something&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;I am a &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;. Bark, bark!&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;dog&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Dog&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Chiwawa&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;dog&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;say_something&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2단계: 파이썬 IDE 설치&lt;/h3&gt;
&lt;p&gt;지금까지 IDE 없이 파이썬 스크립트를 작성하고 실행해보았다.
어떤가? 나쁘지 않은가?
사실 별도의 IDE 없이 좀 더 괜찮은 에디터를 사용해서 파이썬 프로그래밍을 하는 프로그래머도 많이 있다. 가령:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="sublime-text.html"&gt;Sublime Text&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Vim&lt;/li&gt;
&lt;li&gt;&lt;a href="http://tutorialzine.com/2012/07/battle-of-the-tools-which-is-the-best-code-editor/"&gt;...and more&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;등만 잘 활용해도 충분하다.
하지만 IDE의 풍부한 기능을 사용하고 싶다면 다음의 몇 가지 대안을 검토해볼 수도 있다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;PyCharm&lt;/li&gt;
&lt;li&gt;Eclipse&lt;/li&gt;
&lt;li&gt;Visual Studio &lt;/li&gt;
&lt;li&gt;&lt;a href="http://pedrokroger.net/choosing-best-python-ide/"&gt;...and more&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;또는,
터미널로 돌아가서, &lt;code&gt;ipython&lt;/code&gt;을 입력하는 대신 &lt;code&gt;ipython notebook&lt;/code&gt;이라고 입력해보자.
신세계가 열릴 것이다!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://ipython.org/notebook.html"&gt;IPython notebook official docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nbviewer.ipython.org/"&gt;IPython notebook을 사용한 예시들&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!--
## 좀 더 실질적인걸 해볼까요?

- 문법은 대강 알겠는데, 어디다가 쓸 수 있을까요?
- 앞에서 사용한 문법을 응용해서 내 컴퓨터에 파일 생성하고 이름 바꾸고 지우기!

        :::python
        # Create ten files
        for i in range(10):
            with open("some file %s.txt" % i, "w") as f:
                f.write("Hello world full of data!\nThis is the %sth file." % i)
--&gt;

&lt;h2&gt;What's next?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;이제 설치도 끝났고 파이썬이 대강 어떻게 돌아갔는지 살펴보았다&lt;/li&gt;
&lt;li&gt;그렇다면 다음 단계는 뭘까?&lt;/li&gt;
&lt;li&gt;앞으로 우리는 몇 시간에 걸쳐 각종 데이터마이닝 알고리즘에 대해 공부하고, 각각을 파이썬 코드를 이용해 직접 돌려볼 것이다&lt;/li&gt;
&lt;li&gt;하지만 파이썬을 책으로 좀 더 깊게 들여다보고 싶다면? 아래 링크들을 참고해보자&lt;ul&gt;
&lt;li&gt;초급: &lt;a href="http://learnpythonthehardway.org/book/"&gt;Learn Python the hard way&lt;/a&gt; (&lt;a href="http://www.yes24.com/24/goods/15240210"&gt;번역본&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;중/고급: &lt;a href="https://julien.danjou.info/books/the-hacker-guide-to-python"&gt;The hacker's guide to Python&lt;/a&gt; (&lt;a href="http://www.yes24.com/24/goods/15418826"&gt;번역본&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;데이터 분석 (적어도 초급은 떼고 시작하면 좋음): &lt;a href="http://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1449319793"&gt;Python for data analysis&lt;/a&gt; (&lt;a href="http://www.hanbit.co.kr/book/look.html?isbn=978-89-6848-047-8"&gt;번역본&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;난 책 같은거 필요없다! 온라인으로 배울 방법이 궁금하다면?&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.codecademy.com/tracks/python"&gt;Code Academy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kaggle.com/wiki/GettingStartedWithPythonForDataScience"&gt;Getting started with Python for data science&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;난 바로 실전으로 들어간다. 파이썬을 활용한 연습문제를 풀어보고 싶다면?&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.pythonchallenge.com"&gt;Python Challenge&lt;/a&gt;: 파이썬보다는 퀴즈&lt;/li&gt;
&lt;li&gt;&lt;a href="https://projecteuler.net/"&gt;Project Euler&lt;/a&gt;: 파이썬보다는 알고리즘&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;가장 중요한 것: 여러분이 이 과정을 &lt;strong&gt;즐기는&lt;/strong&gt; 것이 가장 중요합니다.&lt;ul&gt;
&lt;li&gt;프로젝트도, 여러분이 스스로 흥미와 재미를 느낄 법한 주제를 골라보는 것이 중요해요.&lt;/li&gt;
&lt;li&gt;과연 그게 뭘까요? 내가 가진, 혹은 앞으로 이 수업을 통해 가질 기술로, 나는 나의 삶을, 우리 학교를, 서울시를, 대한민국을, 세계에 어떤 영향을 줄 수 있을까요?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;제안: 프로젝트 팀을 짜고나면 프로젝트 뿐 아니라 파이썬 스터디도 같이 진행해보면 어때요?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Appendix&lt;/h2&gt;
&lt;h3&gt;초짜 프로그래머가 프로그래밍 잘하는 법&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;에러 메세지를 잘 &lt;em&gt;읽자&lt;/em&gt; (read, not see). 흔히들 시험 볼 때 문제 속에 답이 있다고 하는데, 프로그래밍할 때는 에러 메세지 속에 이유가 있다. 진짜다.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://lmgtfy.com/?q=python3 docs"&gt;구글링!&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;주의: 구글링을 한다고 무조건 좋은 레퍼런스가 찾아지는 것은 아니다&lt;/li&gt;
&lt;li&gt;보통은 공식 문서 (official documents) / API가 가장 좋은 레퍼런스 (ex: &lt;a href="http://docs.python.org"&gt;docs.python.org&lt;/a&gt; &amp;lt;- 웹문서의 도메인을 잘 보라.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Learn how to program, rather than just accomplishing the task&lt;ul&gt;
&lt;li&gt;프로그래밍을 배우는 것과 복/붙하는 것은 다르다 (참고: &lt;a href="http://norvig.com/21-days.html"&gt;Teach yourself programming in ten years&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;일단 프로그램이 작동하게 하는데 성공했다면, 왜 작동했는지를 이해하자.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Follow coding conventions. 많은 똑똑한 사람들이 선택한 방법에는 이유가 있다.&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.python.org/dev/peps/pep-0008"&gt;PEP-8&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;변수/파일에는 직관적인 이름을 붙여주자.&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote class="twitter-tweet" lang="en"&gt;&lt;p&gt;There are two hard things in computer science: cache invalidation, naming things, and off-by-one errors.&lt;/p&gt;&amp;mdash; Jeff Atwood (@codinghorror) &lt;a href="https://twitter.com/codinghorror/status/506010907021828096"&gt;August 31, 2014&lt;/a&gt;&lt;/blockquote&gt;

&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;

&lt;h3&gt;윈도우 프로그래머를 위한 팁&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;윈도우에서 자주 속썩이는 것들&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;인코딩이 골치. UTF8 쓰는게 OS간 호환성에 가장 좋지만, 윈도우는 cp949이 기본. 한글 사용자라면 &lt;a href="http://www.joelonsoftware.com/articles/Unicode.html"&gt;유니코드가 뭔지 알아보자&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;한편, 파이썬 스크립트를 실행했을 때 아래의 에러가 생길 수 있다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;UnicodeEncodeError: &lt;span class="s1"&gt;&amp;#39;cp949&amp;#39;&lt;/span&gt; codec can&lt;span class="s1"&gt;&amp;#39;t encode character &amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\u&lt;/span&gt;20a9&lt;span class="err"&gt;&amp;#39;&lt;/span&gt; in position 90: illegal multibyte sequence&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이는 윈도우에서 기본 인코딩을 cp949를 사용하고 있지만, 우리가 utf8을 사용해서 발생하는 문제다. 한번 확인해볼까?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;locale&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;locale&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getpreferredencoding&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;     &lt;span class="c"&gt;# 아마 cp949, 바꿔주지 않아도 되나 매번 인코딩 명시해야&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encoding&lt;/span&gt;                  &lt;span class="c"&gt;# 아마 cp949, 이건 PYTHONIOENCODING 환경변수를 utf8로 설정하면 바뀜&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getdefaultencoding&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;             &lt;span class="c"&gt;# 아마 utf8, 굿&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;이 때 애를 먹지 않기 위해서는 두 가지 대응 방법이 있는데&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1) 일괄적으로 utf-8을 사용하지 않고 cp949를 쓰거나&lt;/li&gt;
&lt;li&gt;2) 다소 번거롭더라도 utf-8을 사용하도록 설정을 변경하는 것이다&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;위에서 2)를 따를 경우, 지금 당장 할 수 있는 것은 딱 한 가지이다. 윈도우의 환경변수 설정에 들어가서 &lt;code&gt;PYTHONIOENCODING&lt;/code&gt;의 값을 &lt;code&gt;utf-8&lt;/code&gt;로 설정하는 것. 그 후에 쉘을 다시 닫았다가 연 후 아래를 입력해보자. 아마 값이 달라졌을 것이다.&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encoding&lt;/span&gt;                  &lt;span class="c"&gt;# 아마 utf-8&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://blog.codinghorror.com/the-great-newline-schism/"&gt;Newlines가 골치&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;역슬래시가 골치&lt;ul&gt;
&lt;li&gt;왜 내 키보드에는 역슬래시가 없을까? (폰트 문제)&lt;/li&gt;
&lt;li&gt;폴더 구분자를 쓸 때 왜 역슬래시를 두 번 표기해야할까?&lt;/li&gt;
&lt;li&gt;폴더 구분자를 쓸 때 왜 역슬래시 대신 슬래시를 쓸까?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;사용자(user)의 홈디렉토리(home directory)에 대한 개념을 익히자&lt;ul&gt;
&lt;li&gt;보통 사용자가 "lucypark"라면 윈도우에서 홈디렉토리는 &lt;code&gt;C:\Users\lucypark&lt;/code&gt;. 맥이나 리눅스에서는 &lt;code&gt;~/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;다른 OS를 한번쯤 써보면 금세 익힐 수 있게 된다!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;탐색기(Explorer) 설정 변경&lt;br&gt;
&lt;img src="images/windows.png" width="700px"&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;"파일 확장명 숨기기" 선택 해제를 하고 나면 다음과 같이 된다.
파일이 확장자(extension)가 있는지, 없는지, 있다면 어떤 확장자인지 아는 것은 중요하다.
확장자는 우리가, 그리고 컴퓨터가, 파일이 어떤 프로그램으로 실행할 수 있는지 알 수 있는 힌트이기 때문이다.&lt;/p&gt;
&lt;p&gt;&lt;img src="images/windows2.png" width="700px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;그 밖의 유용한 참고자료&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://blogs.perceptionsystem.com/images/JavaVsPython.png"&gt;Java vs Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;최성철, &lt;a href="http://www.slideshare.net/blissray/w-37771905"&gt;산업공학과를 위한 프로그래밍 입문 (w/파이썬) Part 1: 파이썬 기초&lt;/a&gt;, 2014.&lt;/li&gt;
&lt;li&gt;최성철, &lt;a href="http://www.slideshare.net/blissray/w-part-2"&gt;산업공학과를 위한 프로그래밍 입문 (w/파이썬) Part 2: 파이썬 활용&lt;/a&gt;, 2014.&lt;/li&gt;
&lt;li&gt;김태훈, &lt;a href="http://carpedm20.github.io/140min-python"&gt;140분의 Python: 소개부터 문법 실습까지&lt;/a&gt;, 2015.&lt;/li&gt;
&lt;/ul&gt;</summary></entry><entry><title>Course Introduction</title><link href="http://lucypark.kr/courses/2015-ba/course-logistics.html" rel="alternate"></link><updated>2015-03-06T15:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-06:courses/2015-ba/course-logistics.html</id><summary type="html">&lt;h2&gt;About the instructor&lt;/h2&gt;
&lt;p&gt;&lt;img src="http://lucypark.kr/courses/images/me.jpg" width="150px" class="pull-right"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Eunjeong (Lucy) Park&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dm.snu.ac.kr/~epark"&gt;PhDc for data mining&lt;/a&gt; at Seoul National University&lt;/li&gt;
&lt;li&gt;You can call me &lt;a href="http://www.phdcomics.com/comics/archive.php?comicid=1153"&gt;"Ms. Park"&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Normally to professors, using "Dr." is a better idea&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;a.k.a., &lt;a href="http://lucypark.kr"&gt;lucypark&lt;/a&gt;, &lt;a href="http://twitter.com/echojuliett"&gt;echojuliett&lt;/a&gt;, &lt;a href="http://github.com/e9t"&gt;e9t&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Course logistics&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Course objective: &lt;strong&gt;Pragmatic data mining on real data&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Work for the course&lt;ul&gt;
&lt;li&gt;Class meets every Friday 15:00-18:00&lt;/li&gt;
&lt;li&gt;Most classes will be consisted of two parts&lt;ol&gt;
&lt;li&gt;Lectures and/or tutorials&lt;/li&gt;
&lt;li&gt;Short presentations by each project team/individual&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Course website: &lt;a href="http://lucypark.kr/courses/2015-ba"&gt;http://lucypark.kr/courses/2015-ba&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Lecture notes&lt;/li&gt;
&lt;li&gt;Schedule/Announcements&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Schedule: &lt;a href="http://lucypark.kr/courses/2015-ba/#schedule"&gt;http://lucypark.kr/courses/2015-ba/#schedule&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Office hours&lt;ul&gt;
&lt;li&gt;Right before every class&lt;/li&gt;
&lt;li&gt;You are welcome to ask any kind of questions&lt;/li&gt;
&lt;li&gt;You are also encouraged to &lt;a href="mailto:2015-ba@dm.snu.ac.kr"&gt;book ahead&lt;/a&gt;, or your meeting may have to be deferred to another time&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Grading&lt;ul&gt;
&lt;li&gt;Assignments (20%): Two graded assignments related to your project, and two reading assignments during the semester&lt;/li&gt;
&lt;li&gt;Mid-term exam (20%): In-class exam covering the first half of the semester&lt;/li&gt;
&lt;li&gt;Finals (60%): Finals consist of an in-class exam and a project presentation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Term Project&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;You will be conducting a term project throughout the semester&lt;/li&gt;
&lt;li&gt;Term projects will be done as individual work&lt;/li&gt;
&lt;li&gt;There will be two designated assigments according to the project, and one graded presentation at the end of the semester&lt;/li&gt;
&lt;li&gt;Extra credit will be given to those who submit and/or rank in public tournaments (ex: &lt;a href="http://kaggle.com"&gt;Kaggle&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Reading assignments&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Charles Wheelan, &lt;a href="http://www.amazon.com/gp/product/039334777X"&gt;Naked Statistics: Stripping the Dread from the Data&lt;/a&gt; (There's also a &lt;a href="http://www.yes24.com/24/goods/11257680"&gt;Korean version&lt;/a&gt;, so pick a version that suits you)&lt;/li&gt;
&lt;li&gt;You will be picking two chapters&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Advice on your projects&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;The best topics are the &lt;em&gt;topics you are actually interested in&lt;/em&gt;&lt;ul&gt;
&lt;li&gt;You should be able to "&lt;a href="http://en.wikipedia.org/wiki/Eating_your_own_dog_food"&gt;dogfood&lt;/a&gt;" your own analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Don't be afraid to shift the project's direction&lt;ul&gt;
&lt;li&gt;However, shifting too much will give you less time for real work -- balance!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Feel free to use project results in your graduation project or paper&lt;ul&gt;
&lt;li&gt;Grab two rabbits at once!&lt;/li&gt;
&lt;li&gt;These projects have potential to become something in your portfolio&lt;/li&gt;
&lt;li&gt;May be a plus when you get a job, or apply for grad school&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Presenting project progress&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Update your progress (Max. 10 minutes)&lt;ol&gt;
&lt;li&gt;Prepare printouts (for the whole class) or slides or whatever format that best conveys your work&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Please share your materials at the forum before class&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Be brief yet clear&lt;ul&gt;
&lt;li&gt;Note: &lt;a href="http://echojuliett.tumblr.com/post/32108001510/clarity-brevity"&gt;Clarity wins brevity&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Take notes&lt;ul&gt;
&lt;li&gt;Keep precise research progress and feedback notes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;A good presentation contains the following:&lt;ol&gt;
&lt;li&gt;What questions you had&lt;/li&gt;
&lt;li&gt;What approach you chose to alleviate such questions&lt;/li&gt;
&lt;li&gt;What results you achieved&lt;/li&gt;
&lt;li&gt;What questions you further got and what you plan to do next&lt;/li&gt;
&lt;li&gt;(Optional) Tricks and tips you want to share with the class&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Asking questions&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Never hesitate in asking questions&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Private questions: &lt;a href="mailto:2015-ba@dm.snu.ac.kr"&gt;2015-ba@dm.snu.ac.kr&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Personal questions and/or requests&lt;/li&gt;
&lt;li&gt;Assignment submissions that regard privacy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Public questions: &lt;a href="mailto:2015-ba@googlegroups.com"&gt;2015-ba@googlegroups.com&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;This is the class forum&lt;/li&gt;
&lt;li&gt;Everything else you want to ask goes here&lt;/li&gt;
&lt;li&gt;Using any language of your choice (ex: English, Korean, Java, ...)&lt;/li&gt;
&lt;li&gt;Asking good questions at the class forum&lt;ul&gt;
&lt;li&gt;Provide as much details as you can&lt;/li&gt;
&lt;li&gt;However, be "brief" and "clear"&lt;/li&gt;
&lt;li&gt;In case of programming questions, explicitly list versions of software being used (including packages and OSs)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Academic integrity&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/Academic_integrity"&gt;Academic integrity is the moral code or ethical policy of academia&lt;/a&gt;.
There may be times you are tempted to be dishonest, cheat, or plagarize other work,
but in this course (and undoubtfully in all other classes),
we encourage you to approach your work with honesty and integrity.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is disallowed&lt;ul&gt;
&lt;li&gt;Don't ask another student to do the work for you&lt;/li&gt;
&lt;li&gt;Don't fabricate experimental results&lt;/li&gt;
&lt;li&gt;Don't cheat on exams, and don't let anothers copy your answers&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;What is allowed&lt;ul&gt;
&lt;li&gt;Do trust your ability&lt;/li&gt;
&lt;li&gt;Do give credit to others' work (Mind your citations!)&lt;/li&gt;
&lt;li&gt;Do brag about your acheivements&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!--
### Plagarism

- It is *critically important* that you give proper credit to people/sources when you use their words or ideas.

&gt; Some sources on plagarism
&gt; - [Student Handbook on Referencing](http://www.jhsph.edu/academics/degree-programs/master-of-public-health/current-students/JHSPH-ReferencingHandbook.pdf), Johns Hopkins U, 2010.

### Honor code for BA 2015

*My answers to homework, quizzes and exams will be my own work (except for assignments that explicitly permit collaboration). I will not make solutions to homework, quizzes or exams available to anyone else. This includes both solutions written by me, as well as any official solutions provided by the course staff. I will not engage in any other activities that will dishonestly improve my results or dishonestly improve/hurt the results of others.*

## Tips

1. Writing a good CV
    - http://tex.stackexchange.com/questions/80/latex-template-for-resume-curriculum-vitae
1. Writing a good self-introduction
    - Use positive words.
    - Divide an conquer!
        - Step 1. Focus only on the contents! (Using a basic text editor or plain paper might be a good idea)
        - Step 2. Do the formatting. Formatting matters. (ex: fonts, layouts, tenses, etc.)
1. Performing data analysis
    - https://twitter.com/echojuliett/status/491256372726480896
    m Traditional battles in CS and DM https://twitter.com/echojuliett/status/491564823096737794
1. How to find good resources (cf. What is "good"?)
    - If it's a book, author &amp; publisher
    - If it's an academic paper, author &amp; publisher &amp; year of publish
    - If it's a Web document, author &amp; date of publish, popularity among your friends
1. Using great tools: The key to research is search, using great tools.
    - Stackoverflow
    - Google Scholar
    - Markdown, pandoc
    - Coursera, Quora, Kaggle
    - Facebook Groups
--&gt;</summary><category term="lectures"></category><category term="intro"></category></entry><entry><title>Assignments</title><link href="http://lucypark.kr/courses/2015-dm/assignments.html" rel="alternate"></link><updated>2015-03-06T09:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-06:courses/2015-dm/assignments.html</id><summary type="html">&lt;p&gt;For assignment guidelines, visit the class &lt;a href="http://eclass.seoultech.ac.kr"&gt;e-class&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Assignment 0: 자기소개서 쓰기&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;마감일: 2015-03-11 23:59&lt;/li&gt;
&lt;li&gt;제출처: e-class&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A4 용지 1페이지 이내로 자기소개서를 작성해봅시다.
형식은 자유이지만 아래의 내용은 꼭 포함시켜주시기 바랍니다.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;이름, 전화번호, 메일주소, 사진&lt;/li&gt;
&lt;li&gt;성격, 취미, 특기, 동아리 활동 등&lt;/li&gt;
&lt;li&gt;프로그래밍 경력 (사용 가능한 언어, 상중하 수준, 언어를 이용해 진행한 일)&lt;/li&gt;
&lt;li&gt;데이터마이닝 수업을 듣게 된 이유, 수업을 통해 얻고 싶은 것&lt;/li&gt;
&lt;li&gt;졸업 후 계획, 가고 싶은 학교 또는 회사 &lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Project proposal&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;마감일: 2015-03-18 23:59&lt;/li&gt;
&lt;li&gt;제출처: e-class&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;팀프로젝트에서 진행할 데이터마이닝 아이디어 한 가지를 제안해주세요.
제안서는 A4 용지 1페이지 이내로 작성하고 PDF로 변환하여 올려주시기 바랍니다.&lt;/p&gt;
&lt;p&gt;프로젝트에 대한 자세한 사항은 &lt;a href="http://www.lucypark.kr/courses/2015-dm/course-introduction.html#term-project-40"&gt;이 링크&lt;/a&gt;를 참고해주세요.&lt;/p&gt;
&lt;h2&gt;Assignment 1: Classification&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;마감일: 2015-04-02 23:59&lt;/li&gt;
&lt;li&gt;제출처: e-class&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Assignment 1은 수업 시간에 사용한 MNIST 데이터셋을 이용한 학습을 실제로 해보는 것입니다.
아래의 다섯 가지 문항에 대한 답을 문서로 작성하고 PDF로 변환한 후 올려주시기 바랍니다.&lt;/p&gt;
&lt;p&gt;&lt;a href="logistic-regression.html"&gt;수업 시간에 배운 logistic regression&lt;/a&gt; 알고리즘을 학습해보자.
단, 이번에는 1) Binary가 아니라 전체 10개의 범주(class)에 대해 분류해보고, 2) 성능과 학습 시간을 모두 측정해보는 것이 목표이다.&lt;/p&gt;
&lt;p&gt;먼저 scikit-learn을 통해 MNIST dataset을 loading하고, partitioning해보자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cross_validation&lt;/span&gt;
&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fetch_mldata&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;MNIST original&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data_home&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;target&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cross_validation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1234&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;참고&lt;/strong&gt;: &lt;code&gt;d = datasets.fetch_mldata('MNIST original', data_home='.')&lt;/code&gt;에서 &lt;code&gt;HTTP Error 500: Internal Server Error&lt;/code&gt;를 내면서 죽는다면 mldata.org 사이트의 접속량 폭주 때문일 수 있다. 이 때 해결법은 두 가지가 있다.&lt;br&gt;
1. 접속이 원활해질 때까지 기다렸다가 잠시 후에 다시 시도해보거나&lt;br&gt;
2. &lt;a href="https://gist.github.com/e9t/736b5410c0937091166b"&gt;이 파이썬 파일&lt;/a&gt;을 현재 디렉토리에서 실행해보자.&lt;br&gt;
현재 디렉토리에 &lt;code&gt;mldata&lt;/code&gt;라는 폴더가 생기고, 그 안에 &lt;code&gt;mnist-original.mat&lt;/code&gt;이라는 이름으로 약 54MB 크기의 파일이 저장되었다면 성공이다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;학습시간을 측정하기 위해 다음과 같이 &lt;a href="https://docs.python.org/3/library/time.html"&gt;time&lt;/a&gt; 모듈을 사용해보자.
다만, 코드가 무슨 말인지는 꼭 이해하고 가자!
이해가 안 된다면 이 참에 구글링도 하고 scikit-learn 공식 문서도 뒤져보자.
우리의 목표는 이 숙제를 완성하는 것이 아니라 실제로 데이터를 가지고 놀 수 있는 능력을 키우는 것이다.&lt;/p&gt;
&lt;p&gt;시간이 오래걸릴 것이니 밥을 먹고 와도 좋다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;
&lt;span class="n"&gt;lr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1234&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;1: 로지스틱 회귀분석으로 MNIST 데이터를 학습하는데 시간이 얼마나 걸렸는지 기록하자.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;학습이 다 됐는가? Training하느라 우리 컴퓨터가 수고 많았다.
매번 그 과정을 거치면 우리 컴퓨터가 너무 힘드니까 모델을 저장해보자.
이 때 모델의 이름은 길더라도 의미있게 짓는 것이 좋다.
(여기서는 random_state라는 파라미터를 입력했으니 그것을 변수명에 넣어보겠다.)
여기서 파일 확장자로 사용한 &lt;code&gt;pkl&lt;/code&gt;은 &lt;a href="https://docs.python.org/3/library/pickle.html"&gt;pickle&lt;/a&gt; 파일이라는 것을 나타낸다.
pickle은 파이썬에서 오브젝트(object)를 binary로 저장하는 방식 중 하나이다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.externals&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;joblib&lt;/span&gt;
&lt;span class="n"&gt;joblib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dump&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;lr_randomstate_1234.pkl&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;위 코드를 입력하면 내 컴퓨터에 한 개(혹은 그 이상)의 파일이 생성되는 것을 확인할 수 있다.
(참고자료: &lt;a href="http://scikit-learn.org/stable/modules/model_persistence.html"&gt;Model persistence&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;이렇게 모델을 파일로 저장하고나면 다음부터는 컴퓨터를 재부팅하고도 다시 많은 시간을 투자해서 모델을 학습하지 않고 아래와 같이 모델을 파일로부터 로딩할 수 있다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;lr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;joblib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;lr_randomstate_1234.pkl&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;2: 생성된 학습 모델 파일명과 파일의 크기가 몇 KB인지 기록하자.
파일이 여러 개 생성되었다면 각 파일의 이름과 크기를 모두 기록하자.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;우리가 LogisticRegression 클래스의 instance를 생성할 때 사용한 파라미터는 아래의 명령어로 찾을 수 있다.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_params&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;3: 어떤 값들이 출력되는가? 각 파라미터는 어떤 의미를 가지는지 설명해보자. 잘 모르겠다면 &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"&gt;이 문서&lt;/a&gt;를 확인해보자.&lt;/p&gt;
&lt;p&gt;4: 이 파라미터들을 사용했을 때 test set에 대한 정확도(accuracy), 정밀도(precision), 재현율(recall), F-score는 각각 얼마인지 계산해보자.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;5: 분류 알고리즘은 logistic regression 뿐 아니라 k-NN, Decision trees, SVM, Neural Networks 등 다양하게 있다. Logistic regression을 제외하고 다른 분류 알고리즘을 적어도 하나 택해서 Logistic regression으로 MNIST dataset에 대한 학습 시간과 정확도를 비교해보자.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;로지스틱 회귀분석 모형의 학습 시간이 엄청 길었을 것이다.
그런데 왜 그랬을까?
&lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"&gt;공식 문서&lt;/a&gt;에도 나와있듯 multi-class, 즉 다범주 문제에 대해서 scikit-learn의 구현체가 multinomial logistic regression을 구현하지 않았기 때문이다.
즉, 우리가 수업 시간에 다룬 &lt;a href="http://localhost:8000/2015-dm/logistic-regression.html#6-1범주-mnist-1-against-all"&gt;1-against-all&lt;/a&gt; 모델을 모든 범주, 그러니까 총 10개의 범주에 대해서 다 시행한 것이다.
따라서 원래 모델 하나를 학습하는 시간보다 약 10배의 시간이 걸렸을 것이다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Extra credit: 학습 속도를 높이면서 성능은 유지하거나, 학습 속도를 유지하면서 성능을 높일 수 있는가? 어떻게 하면 되는가? 이 때 어떤 파라미터를 썼는가?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Assignment 2: Dimensionality reduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;마감일: 2015-05-07 23:59&lt;/li&gt;
&lt;li&gt;제출처: e-class&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Assignment 2은 Assignment 1에서 다룬 MNIST 데이터셋을 이용하여 PCA를 이용한 차원축소를 하는 것입니다.
아래의 세 가지 문항에 대한 답을 문서로 작성하고 PDF로 변환한 후 올려주시기 바랍니다.&lt;/p&gt;
&lt;p&gt;이번에는 Assignment 1에서처럼 &lt;code&gt;sklearn.datasets.fetch_mldata()&lt;/code&gt;를 사용하지 말고,
&lt;code&gt;sklearn.datasets.load_digits()&lt;/code&gt;를 사용해서 약식의 MNIST 데이터를 loading해보자.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_digits&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;      &lt;span class="c"&gt;# sklearn의 datasets에 완비된 mnist 데이터 로딩&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;target&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;   &lt;span class="c"&gt;# X, y 변수를 생성하여 각각 독립변수와 종속변수를 넣음&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;1: 변수 X는 몇 개의 record(row)와 몇 개의 attribute(column)로 구성되어 있는가? 첫 다섯 개의 record가 각각 어떤 X값을 가지는지 기록해보자.&lt;/p&gt;
&lt;p&gt;2: 파이썬의 scikit-learn 패키지에서 PCA를 할 수 있는 함수를 찾아 X를 2개의 차원으로 전사하여 Z라는 변수에 저장하자. Z는 몇 개의 record(row)와 몇 개의 attribute(column)로 구성되어 있는가? 또, 첫 다섯 개의 record는 각각 어떤 X값을 가지게 되었는가?&lt;/p&gt;
&lt;p&gt;3: 1, 2번을 수행한 코드를 붙여넣고, 첫째줄부터 마지막줄까지, 작성한 코드의 각 줄이 어떤 동작을 하는지 설명해보자.&lt;/p&gt;
&lt;p&gt;Extra credit: PCA를 이용하여 MNIST 데이터를 두 개의 차원으로 전사한 결과값 Z를 2차원 평면의 그래프로 그려보자. 파이썬을 이용해도 좋고, 전사한 데이터를 파일로 저장하여 다른 언어를 이용해 시각화해도 좋다.
참고로, PCA를 이용하여 &lt;a href="http://en.wikipedia.org/wiki/Iris_flower_data_set"&gt;iris 데이터셋&lt;/a&gt;을 3차원으로 전사시켜 시각화한 예시는 &lt;a href="http://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_iris.html"&gt;이 링크&lt;/a&gt;에서 볼 수 있다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!--
&gt; 5: 분류문제의 성능을 측정할 때는 위의 정확도(accuracy) 뿐 아니라 precision, recall, f-measure 등도 사용된다. 1) 각각은 어떤 의미를 가지며 어떻게 계산하는가? 2) 실제로 값도 구해보고, 3) 도출된 네 가지 지표 accuracy, precision, recall, f-measure을 통해 우리 모델이 잘 학습되었는지 판단해보자.
1. 아래의 코드로 logistic regression의 coefficient들을 그림으로 그려보자.
어떤 모양을 가지는가? 이것이 뜻하는 바는 무엇일까?

        :::python
        plt.matshow(lr.coef_.reshape(28, 28))
        plt.colorbar()
        plt.savefig('lr_coef.png')

## Assignment 3: 분류기 비교

- 마감일: 2015-04-02 23:59
- 제출처: e-class

지금까지 우리는 logistic regression, decision trees, k-NN, ANN, SVM 등의 분류 알고리즘에 대해 배웠거나 배울 것이다.
이들의 특성은 어떻게 다른가?
각각의 알고리즘은 어떤 데이터셋과 상황에 적합하다고 볼 수 있는가?
[iris](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html) 데이터셋을 이용해 각 분류기의 성능을 비교해보자.
    - 참고: [Scikit-learn classifier comparison](http://scikit-learn.org/stable/auto_examples/plot_classifier_comparison.html)
--&gt;</summary><category term="assignments"></category></entry><entry><title>Course Introduction</title><link href="http://lucypark.kr/courses/2015-dm/course-introduction.html" rel="alternate"></link><updated>2015-03-06T09:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-06:courses/2015-dm/course-introduction.html</id><summary type="html">&lt;h2&gt;About the instructor&lt;/h2&gt;
&lt;p&gt;&lt;img src="http://lucypark.kr/courses/images/me.jpg" width="150px" class="pull-right"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Eunjeong (Lucy) Park&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dm.snu.ac.kr/~epark"&gt;PhDc for data mining&lt;/a&gt; at Seoul National University&lt;/li&gt;
&lt;li&gt;a.k.a., &lt;a href="http://lucypark.kr"&gt;lucypark&lt;/a&gt;, &lt;a href="http://twitter.com/echojuliett"&gt;echojuliett&lt;/a&gt;, &lt;a href="http://github.com/e9t"&gt;e9t&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Course logistics&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Course objective: &lt;strong&gt;Understanding data mining algorithms&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Course website&lt;ul&gt;
&lt;li&gt;Schedule/Lecture notes: &lt;a href="http://lucypark.kr/courses/2015-dm"&gt;http://lucypark.kr/courses/2015-dm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Everything else: &lt;a href="http://eclass.seoultech.ac.kr/"&gt;e-class&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Office hours&lt;ul&gt;
&lt;li&gt;Right after every class&lt;/li&gt;
&lt;li&gt;You are welcome to ask any kind of questions&lt;/li&gt;
&lt;li&gt;You are also encouraged to &lt;a href="mailto:2015-dm@dm.snu.ac.kr"&gt;book ahead&lt;/a&gt;, or your meeting may have to be deferred to another time&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Grading&lt;ul&gt;
&lt;li&gt;Assignments (30%): Three graded assignments for you to submit online&lt;/li&gt;
&lt;li&gt;Final exam (30%): In-class exam covering the whole semester&lt;/li&gt;
&lt;li&gt;Term project (40%): Group work solving a real world problem&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Assignments (30%)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Three graded take-home assignments for you to submit online&lt;/li&gt;
&lt;li&gt;Instead of taking a mid-term exam, we will have assignments for reviewing purposes&lt;/li&gt;
&lt;li&gt;Assignments consist of a quiz and a programming task&lt;ul&gt;
&lt;li&gt;Frankly, the quiz is not for assessment but for you to review and/or preview class materials&lt;/li&gt;
&lt;li&gt;Programming tasks will cover what you have studied during class. You will have done most of the work in class already. What you're going to do at home is to wrap up your work and document it.&lt;/li&gt;
&lt;li&gt;Will be open early, and can be submitted at any time&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Note the submission date&lt;/em&gt;&lt;ul&gt;
&lt;li&gt;The assignments will still be open even after the due date but you won't get any credit for solving it&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Final exam (30%)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;In-class exam covering the whole semester&lt;/li&gt;
&lt;li&gt;Consists of an easy 80%, a relatively hard 20%&lt;ul&gt;
&lt;li&gt;If you have fully understood the contents of the assignments, the easy 80% wouldn't be a problem&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Term Project (40%)&lt;/h3&gt;
&lt;h4&gt;Proposal (10/40)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Individual work&lt;/li&gt;
&lt;li&gt;Submit 1 data mining project idea within 1 page (Due: 2015-03-18 23:59)&lt;ul&gt;
&lt;li&gt;Delay penalty: 100% off after due (No delays allowed)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Suggested contents&lt;ol&gt;
&lt;li&gt;Background: What question do you have? Why is this problem important?&lt;/li&gt;
&lt;li&gt;Formulation: Convert your problem into a data mining problem. What are the inputs and outputs? What algorithms are you going to use? (ex: Classification, clustering, regression, text mining, etc.)&lt;/li&gt;
&lt;li&gt;Data acquisition: How are you going to obtain the data?&lt;/li&gt;
&lt;li&gt;Expected results&lt;/li&gt;
&lt;li&gt;Expected (business) implications&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Evaluation will be based on following criteria&lt;ol&gt;
&lt;li&gt;아이디어가 가지는 의미 (5점)&lt;/li&gt;
&lt;li&gt;아이디어의 구체화 정도 (5점)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Fix the team with a team leader at e-class (Due: 2015-03-18 23:59)&lt;/li&gt;
&lt;li&gt;Choose a topic (Due: 2015-03-29 23:59)&lt;ul&gt;
&lt;li&gt;Among your teammates' proposals, select one topic and conduct a project as a group&lt;/li&gt;
&lt;li&gt;You can also choose topics among &lt;a href="http://kaggle.com"&gt;Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Progress presentation (15/40)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Submit presentation slides (Due: 2015-05-07 23:59)&lt;ul&gt;
&lt;li&gt;It is recommended that you have done approx. 70-80% of your whole project by this date&lt;/li&gt;
&lt;li&gt;Submit presentation slides to the e-class&lt;/li&gt;
&lt;li&gt;No page limits&lt;/li&gt;
&lt;li&gt;Delay penalty: 50% off (next day) 100% off (after presentation)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Suggested contents: Your proposal + the following&lt;ol&gt;
&lt;li&gt;(Optional) If you have changed the subject, what was the reason?&lt;/li&gt;
&lt;li&gt;Data Exploration&lt;/li&gt;
&lt;li&gt;What approach you chose to alleviate such questions&lt;/li&gt;
&lt;li&gt;What results you achieved&lt;/li&gt;
&lt;li&gt;What questions you further got and what you plan to do next&lt;/li&gt;
&lt;li&gt;Tricks and tips you want to share with the class&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Presentation day (2015-05-08)&lt;ul&gt;
&lt;li&gt;You will present your project progress in front of the class (Max. 10 min)&lt;/li&gt;
&lt;li&gt;Peer assessment&lt;ul&gt;
&lt;li&gt;You will also be grading your peers' work on presentation day&lt;/li&gt;
&lt;li&gt;You will be given three votes&lt;/li&gt;
&lt;li&gt;You can give one vote to three teams, or give all votes to one team&lt;/li&gt;
&lt;li&gt;You will also be reviewing contributions of your own teammates&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Be brief yet clear&lt;/li&gt;
&lt;li&gt;Record the feedback&lt;ul&gt;
&lt;li&gt;One can make the slides&lt;/li&gt;
&lt;li&gt;Another can prepare for the presentation&lt;/li&gt;
&lt;li&gt;And another can do the presentation&lt;/li&gt;
&lt;li&gt;Yet another can take feedback notes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Final report (15/40)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Present what your group has done throughout the whole project in more than 10 pages (Due: 2015-06-14 23:59)&lt;ul&gt;
&lt;li&gt;Delay penalty: 50% off (next day) 100% off (after that)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;You will also be grading your teammates, based on their contributions&lt;/li&gt;
&lt;li&gt;Extra credit will be given to those who submit and/or rank in an open tournament (ex: &lt;a href="http://kaggle.com"&gt;Kaggle&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Suggested contents: Your progress report + the following&lt;ul&gt;
&lt;li&gt;Enhanced results&lt;/li&gt;
&lt;li&gt;(Business) implications&lt;/li&gt;
&lt;li&gt;Future work&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;More advice on your projects&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;The best topics are the topics you are actually interested in&lt;ul&gt;
&lt;li&gt;You should be able to "&lt;a href="http://en.wikipedia.org/wiki/Eating_your_own_dog_food"&gt;dogfood&lt;/a&gt;" your own analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Don't be afraid to shift the project's direction&lt;ul&gt;
&lt;li&gt;However, shifting too much will give you less time for real work -- balance!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Feel free to use project results in your graduation project or paper&lt;ul&gt;
&lt;li&gt;Grab two rabbits at once!&lt;/li&gt;
&lt;li&gt;These projects have potential to become something in your portfolio&lt;/li&gt;
&lt;li&gt;May be a plus when you get a job, or apply for grad school&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Asking questions&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Never hesitate in asking questions&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Private questions: &lt;a href="mailto:2015-dm@dm.snu.ac.kr"&gt;2015-dm@dm.snu.ac.kr&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Personal questions and/or requests&lt;/li&gt;
&lt;li&gt;Assignment submissions that regard privacy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Public questions: Everything else you want to ask goes to e-class&lt;ul&gt;
&lt;li&gt;Using any language of your choice (ex: English, Korean, Java, ...)&lt;/li&gt;
&lt;li&gt;Asking good questions&lt;ul&gt;
&lt;li&gt;Provide as much details as you can&lt;/li&gt;
&lt;li&gt;However, be "brief" and "clear"&lt;/li&gt;
&lt;li&gt;In case of programming questions, explicitly list versions of software being used (including packages and OSs)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary><category term="lectures"></category><category term="intro"></category></entry><entry><title>데이터마이닝을 소개합니다</title><link href="http://lucypark.kr/courses/2015-dm/data-mining.html" rel="alternate"></link><updated>2015-03-06T09:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-06:courses/2015-dm/data-mining.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;이번 시간이 끝나고 나면:
데이터마이닝에 대해 정의할 수 있게 됩니다. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;한 마디로 "데이터마이닝"은?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;대용량의 데이터에 담긴 의미있는 규칙을 찾는 일&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;그런데 &lt;a href="http://en.wikipedia.org/wiki/Data_mining"&gt;데이터마이닝(data mining)&lt;/a&gt;은...&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;많은 자료 속에 숨어있는 일정한 패턴(규칙)을 발견하는 일이기에 &lt;a href="http://en.wikipedia.org/wiki/Pattern_recognition"&gt;패턴인식(pattern recognition)&lt;/a&gt;의 영역과 맞닿아 있으며&lt;/li&gt;
&lt;li&gt;컴퓨터를 학습(훈련)시키는 &lt;a href="http://en.wikipedia.org/wiki/Machine_learning"&gt;기계학습(machine learning)&lt;/a&gt;과도 유사합니다&lt;/li&gt;
&lt;li&gt;좀더 발전적인 개념으로는 &lt;a href="http://en.wikipedia.org/wiki/Artificial_intelligence"&gt;인공지능(artificial Intelligence)&lt;/a&gt;도 있어요&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="center"&gt;
&lt;script type="text/javascript" src="//www.google.com/trends/embed.js?hl=en-US&amp;q=data+mining,+pattern+recognition,+machine+learning,+artificial+intelligence&amp;date=1/2014+12m&amp;cmpt=q&amp;tz&amp;tz&amp;content=1&amp;cid=TIMESERIES_GRAPH_0&amp;export=5&amp;w=680&amp;h=330"&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;div class="caption"&gt;2014년 기준 데이터마이닝, 패턴인식, 기계학습, 인공지능에 대한 구글 트렌드. 음? 그렇다면 &lt;a href="http://www.google.com/trends/explore#q=data%20mining%2C%20pattern%20recognition%2C%20machine%20learning%2C%20artificial%20intelligence%2C%20big%20data&amp;cmpt=q&amp;tz="&gt;빅데이터(big data)&lt;/a&gt;는? 데이터사이언스(data science)는?&lt;/div&gt;

&lt;p&gt;이 영역들은 각기 다른 탄생 배경을 가지고, 엄밀하게는 철학과 목적이 상당히 다르기도 하지만, 방법론의 측면에서는 상당히 유사해서 각 영역끼리 서로 배우는 점도 많지요.
사실 공부도 같은 책으로 많이 해요.
(심도있는 공부를 원하시는 분들은 아래 책들도 한 번 찾아보세요!)&lt;/p&gt;
&lt;p&gt;&lt;a href="http://ecx.images-amazon.com/images/I/612j5Uo43eL._AA160_.jpg"&gt;&lt;img src="images/book1.jpg" height="200px"&gt;&lt;/a&gt;
&lt;a href="http://ecx.images-amazon.com/images/I/41LeU3HcBdL._AA160_.jpg"&gt;&lt;img src="images/book2.jpg" height="200px"&gt;&lt;/a&gt;
&lt;a href="http://ecx.images-amazon.com/images/I/419Ml9MDMaL._AA160_.jpg"&gt;&lt;img src="images/book3.jpg" height="200px"&gt;&lt;/a&gt;
&lt;a href="http://ecx.images-amazon.com/images/I/51MucLjt9IL._AA160_.jpg"&gt;&lt;img src="images/book4.jpg" height="200px"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;style&gt;
iframe {
    width: 700px;
    height: 330px;
}
&lt;/style&gt;

&lt;h2&gt;데이터가 우리 삶을 돕는 다섯 가지 방법&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://readme.skplanet.com/?p=8870"&gt;미래 교통정보 예측: SK Planet T map&lt;/a&gt;&lt;br&gt;
    &lt;a href="http://i1.daumcdn.net/thumb/R750x0/?fname=http%3A%2F%2Fcfile26.uf.tistory.com%2Fimage%2F2204B946524405E408A53F"&gt;&lt;img src="images/tmap.png" width="500px"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://watcha.net"&gt;영화 추천: Frograms Watcha&lt;/a&gt;&lt;br&gt;
    &lt;img src="images/watcha.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://google.com"&gt;문서 랭킹: Google&lt;/a&gt;&lt;br&gt;
    &lt;img src="images/google.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://labs.naver.com/tech.html#multimedia_recognition"&gt;음악 인식: Naver 앱 음악 및 와인라벨 인식&lt;/a&gt;&lt;br&gt;
    &lt;img src="images/naver.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.apple.com/ios/siri/"&gt;질의응답 (QA): Apple Siri&lt;/a&gt;&lt;br&gt;
    &lt;img src="images/siri0.jpg" width="30%"&gt;
    &lt;img src="images/siri1.jpg" width="30%"&gt;
    &lt;img src="images/siri2.jpg" width="30%"&gt;&lt;/p&gt;
&lt;p&gt;cf. IBM Watson&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;데이터가 우리 삶을 바꿀 방법&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Jarvis and Samantha&lt;br&gt;
    &lt;img src="images/jarvis.png" width="40%"&gt;
    &lt;img src="images/samantha.png" width="40%"&gt;
    &lt;!--
    &lt;iframe width="560" height="315" src="https://www.youtube.com/embed/ZwOxM0-byvc" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;
    --&gt;&lt;/li&gt;
&lt;li&gt;IOT&lt;br&gt;
    &lt;iframe width="560" height="315" src="https://www.youtube.com/embed/NjYTzvAVozo?list=PLl-15sUN2G4eEY2VOqxMEazASNrlMF5FP" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;데이터마이너가 되면 좋은 점&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;세상의 다양한 면을, 다양한 관점에서 살펴볼 수 있습니다&lt;ul&gt;
&lt;li&gt;마케팅부터 시작해서,&lt;/li&gt;
&lt;li&gt;주가의 흐름을 예측하거나(금융),&lt;/li&gt;
&lt;li&gt;DNA 분석이나 MRI 영상을 분석하기도 하며(의료),&lt;/li&gt;
&lt;li&gt;디지털 카메라에서 얼굴 인식(기계)을 하기도 합니다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;사실상 직업이 매일 바뀌는 것이나 다름없음&lt;/li&gt;
&lt;li&gt;물론 그 외에도 우리가 상상할 수 있는 대부분의 영역에 데이터마이닝이 적용된다는 사실!&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;다음 시간 예고:
데이터마이닝을 할 때 가장 중요한 것은? Asking the right question.&lt;/p&gt;
&lt;/blockquote&gt;</summary><category term="seoultech"></category><category term="lectures"></category></entry><entry><title>How to upload files and get a URL</title><link href="http://lucypark.kr/courses/tips/uploading-files.html" rel="alternate"></link><updated>2015-03-05T21:51:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-05:courses/tips/uploading-files.html</id><summary type="html">&lt;h3&gt;Using Google Drive&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Go to &lt;a href="http://drive.google.com"&gt;Google Drive&lt;/a&gt; and log in.&lt;/li&gt;
&lt;li&gt;Upload your file.&lt;ul&gt;
&lt;li&gt;If you have created your assignment in something other than Google Drive: Upload your assignment to Google Drive by clicking the "New" button and "File upload".&lt;br&gt;
&lt;img src="images/gd0.png" width="200px"&gt;&lt;/li&gt;
&lt;li&gt;If you have created your assignment in Google Drive: Go to the next step.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Change the sharing settings for your file. You can do this by following the steps below.&lt;ol&gt;
&lt;li&gt;Right-click on the file name and clicking "Share...", or open the file and click the "Share" button on the upper right side of the page.&lt;br&gt;
&lt;img src="images/gd1.png" width="300px"&gt;
&lt;img src="images/gd2.png" width="300px"&gt;&lt;/li&gt;
&lt;li&gt;Click "Get sharable link" on the upper-right side of the popup menu.&lt;br&gt;
&lt;img src="images/gd3.png" width="300px"&gt;&lt;/li&gt;
&lt;li&gt;Copy the link for the document.&lt;br&gt;
&lt;img src="images/gd4.png" width="300px"&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Congratulations! Now you can share your file with whomever you want by pasting that URL anywhere.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Using Dropbox&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Go to your Dropbox folder.&lt;/li&gt;
&lt;li&gt;Right-click on a file and click "Share Dropbox Link".&lt;br&gt;
&lt;img src="images/dropbox.png" width="300px"&gt;&lt;/li&gt;
&lt;li&gt;You're done already! Go share the URL somewhere.&lt;/li&gt;
&lt;/ol&gt;</summary></entry><entry><title>Business Analytics (Spring 2015)</title><link href="http://lucypark.kr/courses/2015-ba/index.html" rel="alternate"></link><updated>2015-03-02T00:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-02:courses/2015-ba/index.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;Welcome to Business Analytics class of 2015!
Here you'll find all course materials, guides and schedules.
In case you have questions, feel free to send an email to &lt;a href="mailto:2015-ba@googlegroups.com"&gt;2015-ba@googlegroups.com&lt;/a&gt; (or directly write a new topic at the forum below).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Data mining and analytical skills are at the heart of solving many important problems in our world.
In this course, we aim to derive technology-based solutions to such problems, and develop strategical decision making abilities based on data.&lt;/p&gt;
&lt;p&gt;Specifically, we discuss technologies, applications, practices, and skills for continuous iterative exploration and investigation of business performance with external data collected from diverse sources such as the Web, in order to gain insights and drive business planning.
Topics include statistical and quantitative analysis, explanatory and predictive modeling, as well as text analytics with visualization.
Students are required to present progress on their work during the semester, and are assessed by a set of assignments, quizzes and exams.&lt;/p&gt;
&lt;p&gt;Note that this course is the second part of a two part sequence.
We assume you have already taken
Data Mining (ex: &lt;a href="http://lucypark.kr/courses/2015-dm/index.html"&gt;IISE113503&lt;/a&gt;),
the first part of the sequence, where methods and algorithms for mining data were discussed.
This course is the latter part of the sequence, and will be more advanced and project-focused.&lt;/p&gt;
&lt;h3&gt;Prerequisites&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Familiarity in data mining algorithms&lt;/li&gt;
&lt;li&gt;Good knowledge with at least one programming language (ex: R, Python, Java, etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;What you will learn&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Use algorithms to extract meaningful insight from large datasets&lt;/li&gt;
&lt;li&gt;Understand the usage of data mining in a domain of interest&lt;/li&gt;
&lt;li&gt;Develop analytical and data-based thinking&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Grading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Assignments (20%): You will be given four graded assignments during the semester.&lt;/li&gt;
&lt;li&gt;Mid-term Quiz (20%): A mid-term quiz.&lt;/li&gt;
&lt;li&gt;Final Exam (60%): A final exam and presentation.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Schedule&lt;/h2&gt;
&lt;p&gt;&lt;table id="schedule" class="table table-hover table-bordered"&gt;
&lt;tr&gt;&lt;th&gt;date&lt;/th&gt;&lt;th&gt;lecture&lt;/th&gt;&lt;th&gt;assignment&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/06&lt;/td&gt;&lt;td&gt;Course introduction&lt;ul&gt;&lt;li&gt;&lt;a href="course-logistics.html"&gt;Course logistics&lt;/a&gt;&lt;li&gt;GitHub&lt;li&gt;Having fun with Kaggle&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;&lt;a href='http://goo.gl/forms/fE7ZIeL8VK'&gt;Homework 0&lt;/a&gt; (Due: 3/11)&lt;ul&gt;&lt;li&gt;CV + Self-intro&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/13&lt;/td&gt;&lt;td&gt;Tools for pragmatic data mining&lt;ul&gt;&lt;li&gt;&lt;a href="bash.html"&gt;Bash&lt;/a&gt;&lt;li&gt;&lt;a href="../tips/introduction-to-python.html"&gt;Python&lt;/a&gt;&lt;li&gt;Statistical Summaries and Exploratory Data Analysis&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/20&lt;/td&gt;&lt;td&gt;&lt;a href="crawling.html"&gt;Scraping from the Web&lt;/a&gt;&lt;ul&gt;&lt;li&gt;Proposal presentations&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;Project proposals (300 words+)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/27&lt;/td&gt;&lt;td&gt;&lt;a href="text-mining.html"&gt;Text mining 1: Text exploration&lt;/a&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/03&lt;/td&gt;&lt;td&gt;&lt;a href="text-mining.html#topic-modeling"&gt;Text mining 2: Topic modeling&lt;/a&gt;&lt;ul&gt;&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/10&lt;/td&gt;&lt;td&gt;Regression and Predictive modeling&lt;ul&gt;&lt;li&gt;Recommender systems&lt;li&gt;Share project progress&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/17&lt;/td&gt;&lt;td&gt;Mid-term Quiz&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/24&lt;/td&gt;&lt;td&gt;Clustering and Dimensionality Reduction&lt;ul&gt;&lt;li&gt;Singular value decomposition (SVD)&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/01&lt;/td&gt;&lt;td&gt;&lt;a href="visualization.html"&gt;Visualization and storytelling 1&lt;/a&gt;&lt;ul&gt;&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/08&lt;/td&gt;&lt;td&gt;&lt;a href="visualization2.html"&gt;Visualization and storytelling 2&lt;/a&gt;&lt;ul&gt;&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;Progress report (1K+ words)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/15&lt;/td&gt;&lt;td&gt;Going deep: Deep learning&lt;ul&gt;&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/22&lt;/td&gt;&lt;td&gt;Going big 1: Map/reduce&lt;ul&gt;&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/29&lt;/td&gt;&lt;td&gt;Going big 2: Spark&lt;ul&gt;&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;6/05&lt;/td&gt;&lt;td&gt;Final presentation&lt;/td&gt;&lt;td&gt;Project final report (3K+ words)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;6/12&lt;/td&gt;&lt;td&gt;Final exam&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/p&gt;
&lt;!--
Memos for next time:
- DM을 배우고 왔어도, 개념을 remind 해주는 class가 초반에 두 번 정도 있으면 좋을듯. 즉, 4/10, 4/24 2회를 강의 초반에 배치
--&gt;</summary><category term="data"></category><category term="seoultech"></category><category term="lecturer"></category><category term="syllabus"></category></entry><entry><title>Data Mining (Spring 2015)</title><link href="http://lucypark.kr/courses/2015-dm/index.html" rel="alternate"></link><updated>2015-03-02T00:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-02:courses/2015-dm/index.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;Welcome to Data Mining class of 2015!
Here you'll find all course materials, guides and schedules.
For discussions, please visit the class &lt;a href="http://eclass.seoultech.ac.kr/"&gt;e-class&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;데이터마이닝(data mining)이란 대용량 데이터베이스에 존재하는 데이터에서 관계, 패턴, 규칙 등을 찾아내고 모형화해서 의사결정을 돕는 유용한 정보로 변환하는 일련의 과정이다.
본 강좌에서는 기술 모델링(descriptive modeling)과 예측 모델링(predictive modeling)에 사용되는 탐색적 통계, 기계학습, 범주형 자료분석 기법들을 공부하고 응용사례 연구와 패키지를 이용한 프로젝트를 수행한다.&lt;/p&gt;
&lt;h3&gt;Prerequisites&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;한 가지 이상의 프로그래밍 언어에 대한 친숙함 (ex: R, Python, Java, etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;What you will learn&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;데이터마이닝의 기본 개념, 구축 프로세스 학습 및 비즈니스 활용 사례 인식&lt;/li&gt;
&lt;li&gt;데이터마이닝의 주요 방법론의 이론적 토대 학습 및 응용 분야 학습&lt;/li&gt;
&lt;li&gt;데이터마이닝 분야에서 널리 사용되는 오픈소스 데이터 분석 언어인 &lt;a href="https://python.org/"&gt;파이썬&lt;/a&gt; 사용 방법 학습&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Grading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Assignments (30%)&lt;/li&gt;
&lt;li&gt;Final exam (30%)&lt;/li&gt;
&lt;li&gt;Term Project (40%)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Schedule&lt;/h2&gt;
&lt;p&gt;For assignment guidelines, visit the class &lt;a href="http://eclass.seoultech.ac.kr"&gt;e-class&lt;/a&gt;.&lt;/p&gt;
&lt;table id="schedule" class="table table-bordered"&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;th&gt;date&lt;/th&gt;&lt;th&gt;lecture&lt;/th&gt;&lt;/tr&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/06&lt;/td&gt;&lt;td&gt;&lt;a href="course-introduction.html"&gt;Course introduction&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="data-mining.html"&gt;Data mining&lt;/a&gt;&lt;li&gt;Assignment 0 (Due: 3/11) + Project proposal (Due: 3/18)&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;3/11&lt;/td&gt;&lt;td&gt;Due date: Assignment 0&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/13&lt;/td&gt;&lt;td&gt;&lt;a href="multiple-linear-regression.html"&gt;지도학습 1: Multiple linear regression&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="../tips/introduction-to-python.html"&gt;Introduction to Python&lt;/a&gt;&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;3/18&lt;/td&gt;&lt;td&gt;Due date: Project proposal, Fix project teams&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/20&lt;/td&gt;&lt;td&gt;&lt;a href="logistic-regression.html"&gt;지도학습 2: Logistic regression&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="assignments.html#assignment-1-classification"&gt;Assignment 1 (Due: 4/2)&lt;/a&gt;&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/27&lt;/td&gt;&lt;td&gt;&lt;a href="http://eclass.seoultech.ac.kr/ilos/co/efile_download.acl?FILE_SEQ=84201&amp;CONTENT_SEQ=89718"&gt;지도학습 3: Decision tree + k-NN&lt;/a&gt;&lt;ul&gt;&lt;li&gt;In class project discussions&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;3/29&lt;/td&gt;&lt;td&gt;Due date: Choose team project topic&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;4/02&lt;/td&gt;&lt;td&gt;Due date: Assignment 1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/03&lt;/td&gt;&lt;td&gt;&lt;a href="http://eclass.seoultech.ac.kr/ilos/co/efile_download.acl?FILE_SEQ=88162&amp;CONTENT_SEQ=93265"&gt;텍스트 마이닝 1: 이론&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/10&lt;/td&gt;&lt;td&gt;&lt;a href="text-mining.html"&gt;텍스트 마이닝 2: 실습&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/17&lt;/td&gt;&lt;td&gt;변수 선택과 차원 축소&lt;ul&gt;&lt;li&gt;&lt;a href="assignments.html#assignment-2-dimensionality-reduction"&gt;Assignment 2 (Due: 5/07)&lt;/a&gt;&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/24&lt;/td&gt;&lt;td&gt;비지도학습 1: k-means + hierarchical clustering&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/01&lt;/td&gt;&lt;td&gt;비지도학습 2: Market basket analysis&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;5/07&lt;/td&gt;&lt;td&gt;Due date: Assignment 2&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;5/07&lt;/td&gt;&lt;td&gt;Due date: Team project presentation slides&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/08&lt;/td&gt;&lt;td&gt;Team project presentations&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/15&lt;/td&gt;&lt;td&gt;지도학습 5: Artificial neural networks&lt;ul&gt;&lt;li&gt;Assignment 3 (Due: 6/4)&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/22&lt;/td&gt;&lt;td&gt;&lt;a href="svm.html"&gt;지도학습 6: Support vector machines&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/29&lt;/td&gt;&lt;td&gt;데이터 시각화&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;6/04&lt;/td&gt;&lt;td&gt;Due date: Assignment 3&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;6/05&lt;/td&gt;&lt;td&gt;대용량 데이터마이닝&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;6/12&lt;/td&gt;&lt;td&gt;Final Exam&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;6/14&lt;/td&gt;&lt;td&gt;Due date: Team project final report&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;</summary><category term="data"></category><category term="seoultech"></category><category term="lecturer"></category><category term="syllabus"></category></entry><entry><title>Data Mining (Spring 2015)</title><link href="http://lucypark.kr/courses/2015-dm/index.html" rel="alternate"></link><updated>2015-03-02T00:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-02:courses/2015-dm/index.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;Welcome to Data Mining class of 2015!
Here you'll find all course materials, guides and schedules.
For discussions, please visit the class &lt;a href="http://eclass.seoultech.ac.kr/"&gt;e-class&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;데이터마이닝(data mining)이란 대용량 데이터베이스에 존재하는 데이터에서 관계, 패턴, 규칙 등을 찾아내고 모형화해서 의사결정을 돕는 유용한 정보로 변환하는 일련의 과정이다.
본 강좌에서는 기술 모델링(descriptive modeling)과 예측 모델링(predictive modeling)에 사용되는 탐색적 통계, 기계학습, 범주형 자료분석 기법들을 공부하고 응용사례 연구와 패키지를 이용한 프로젝트를 수행한다.&lt;/p&gt;
&lt;h3&gt;Prerequisites&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;한 가지 이상의 프로그래밍 언어에 대한 친숙함 (ex: R, Python, Java, etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;What you will learn&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;데이터마이닝의 기본 개념, 구축 프로세스 학습 및 비즈니스 활용 사례 인식&lt;/li&gt;
&lt;li&gt;데이터마이닝의 주요 방법론의 이론적 토대 학습 및 응용 분야 학습&lt;/li&gt;
&lt;li&gt;데이터마이닝 분야에서 널리 사용되는 오픈소스 데이터 분석 언어인 &lt;a href="https://python.org/"&gt;파이썬&lt;/a&gt; 사용 방법 학습&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Grading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Assignments (30%)&lt;/li&gt;
&lt;li&gt;Final exam (30%)&lt;/li&gt;
&lt;li&gt;Term Project (40%)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Schedule&lt;/h2&gt;
&lt;p&gt;For assignment guidelines, visit the class &lt;a href="http://eclass.seoultech.ac.kr"&gt;e-class&lt;/a&gt;.&lt;/p&gt;
&lt;table id="schedule" class="table table-bordered"&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;th&gt;date&lt;/th&gt;&lt;th&gt;lecture&lt;/th&gt;&lt;/tr&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/06&lt;/td&gt;&lt;td&gt;&lt;a href="course-introduction.html"&gt;Course introduction&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="data-mining.html"&gt;Data mining&lt;/a&gt;&lt;li&gt;Assignment 0 (Due: 3/11) + Project proposal (Due: 3/18)&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;3/11&lt;/td&gt;&lt;td&gt;Due date: Assignment 0&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/13&lt;/td&gt;&lt;td&gt;&lt;a href="multiple-linear-regression.html"&gt;지도학습 1: Multiple linear regression&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="../tips/introduction-to-python.html"&gt;Introduction to Python&lt;/a&gt;&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;3/18&lt;/td&gt;&lt;td&gt;Due date: Project proposal, Fix project teams&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/20&lt;/td&gt;&lt;td&gt;&lt;a href="logistic-regression.html"&gt;지도학습 2: Logistic regression&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="assignments.html#assignment-1-classification"&gt;Assignment 1 (Due: 4/2)&lt;/a&gt;&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/27&lt;/td&gt;&lt;td&gt;&lt;a href="http://eclass.seoultech.ac.kr/ilos/co/efile_download.acl?FILE_SEQ=84201&amp;CONTENT_SEQ=89718"&gt;지도학습 3: Decision tree + k-NN&lt;/a&gt;&lt;ul&gt;&lt;li&gt;In class project discussions&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;3/29&lt;/td&gt;&lt;td&gt;Due date: Choose team project topic&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;4/02&lt;/td&gt;&lt;td&gt;Due date: Assignment 1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/03&lt;/td&gt;&lt;td&gt;&lt;a href="http://eclass.seoultech.ac.kr/ilos/co/efile_download.acl?FILE_SEQ=88162&amp;CONTENT_SEQ=93265"&gt;텍스트 마이닝 1: 이론&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/10&lt;/td&gt;&lt;td&gt;&lt;a href="text-mining.html"&gt;텍스트 마이닝 2: 실습&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/17&lt;/td&gt;&lt;td&gt;변수 선택과 차원 축소&lt;ul&gt;&lt;li&gt;&lt;a href="assignments.html#assignment-2-dimensionality-reduction"&gt;Assignment 2 (Due: 5/07)&lt;/a&gt;&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/24&lt;/td&gt;&lt;td&gt;비지도학습 1: k-means + hierarchical clustering&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/01&lt;/td&gt;&lt;td&gt;비지도학습 2: Market basket analysis&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;5/07&lt;/td&gt;&lt;td&gt;Due date: Assignment 2&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;5/07&lt;/td&gt;&lt;td&gt;Due date: Team project presentation slides&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/08&lt;/td&gt;&lt;td&gt;Team project presentations&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/15&lt;/td&gt;&lt;td&gt;지도학습 5: Artificial neural networks&lt;ul&gt;&lt;li&gt;Assignment 3 (Due: 6/4)&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/22&lt;/td&gt;&lt;td&gt;&lt;a href="svm.html"&gt;지도학습 6: Support vector machines&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/29&lt;/td&gt;&lt;td&gt;데이터 시각화&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;6/04&lt;/td&gt;&lt;td&gt;Due date: Assignment 3&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;6/05&lt;/td&gt;&lt;td&gt;대용량 데이터마이닝&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;6/12&lt;/td&gt;&lt;td&gt;Final Exam&lt;/td&gt;&lt;/tr&gt;
&lt;tr class="due-date"&gt;&lt;td&gt;6/14&lt;/td&gt;&lt;td&gt;Due date: Team project final report&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;</summary><category term="data"></category><category term="seoultech"></category><category term="lecturer"></category><category term="syllabus"></category></entry><entry><title>Business Analytics (Spring 2015)</title><link href="http://lucypark.kr/courses/2015-ba/index.html" rel="alternate"></link><updated>2015-03-02T00:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:lucypark.kr,2015-03-02:courses/2015-ba/index.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;Welcome to Business Analytics class of 2015!
Here you'll find all course materials, guides and schedules.
In case you have questions, feel free to send an email to &lt;a href="mailto:2015-ba@googlegroups.com"&gt;2015-ba@googlegroups.com&lt;/a&gt; (or directly write a new topic at the forum below).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Data mining and analytical skills are at the heart of solving many important problems in our world.
In this course, we aim to derive technology-based solutions to such problems, and develop strategical decision making abilities based on data.&lt;/p&gt;
&lt;p&gt;Specifically, we discuss technologies, applications, practices, and skills for continuous iterative exploration and investigation of business performance with external data collected from diverse sources such as the Web, in order to gain insights and drive business planning.
Topics include statistical and quantitative analysis, explanatory and predictive modeling, as well as text analytics with visualization.
Students are required to present progress on their work during the semester, and are assessed by a set of assignments, quizzes and exams.&lt;/p&gt;
&lt;p&gt;Note that this course is the second part of a two part sequence.
We assume you have already taken
Data Mining (ex: &lt;a href="http://lucypark.kr/courses/2015-dm/index.html"&gt;IISE113503&lt;/a&gt;),
the first part of the sequence, where methods and algorithms for mining data were discussed.
This course is the latter part of the sequence, and will be more advanced and project-focused.&lt;/p&gt;
&lt;h3&gt;Prerequisites&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Familiarity in data mining algorithms&lt;/li&gt;
&lt;li&gt;Good knowledge with at least one programming language (ex: R, Python, Java, etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;What you will learn&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Use algorithms to extract meaningful insight from large datasets&lt;/li&gt;
&lt;li&gt;Understand the usage of data mining in a domain of interest&lt;/li&gt;
&lt;li&gt;Develop analytical and data-based thinking&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Grading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Assignments (20%): You will be given four graded assignments during the semester.&lt;/li&gt;
&lt;li&gt;Mid-term Quiz (20%): A mid-term quiz.&lt;/li&gt;
&lt;li&gt;Final Exam (60%): A final exam and presentation.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Schedule&lt;/h2&gt;
&lt;p&gt;&lt;table id="schedule" class="table table-hover table-bordered"&gt;
&lt;tr&gt;&lt;th&gt;date&lt;/th&gt;&lt;th&gt;lecture&lt;/th&gt;&lt;th&gt;assignment&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/06&lt;/td&gt;&lt;td&gt;Course introduction&lt;ul&gt;&lt;li&gt;&lt;a href="course-logistics.html"&gt;Course logistics&lt;/a&gt;&lt;li&gt;GitHub&lt;li&gt;Having fun with Kaggle&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;&lt;a href='http://goo.gl/forms/fE7ZIeL8VK'&gt;Homework 0&lt;/a&gt; (Due: 3/11)&lt;ul&gt;&lt;li&gt;CV + Self-intro&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/13&lt;/td&gt;&lt;td&gt;Tools for pragmatic data mining&lt;ul&gt;&lt;li&gt;&lt;a href="bash.html"&gt;Bash&lt;/a&gt;&lt;li&gt;&lt;a href="../tips/introduction-to-python.html"&gt;Python&lt;/a&gt;&lt;li&gt;Statistical Summaries and Exploratory Data Analysis&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/20&lt;/td&gt;&lt;td&gt;&lt;a href="crawling.html"&gt;Scraping from the Web&lt;/a&gt;&lt;ul&gt;&lt;li&gt;Proposal presentations&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;Project proposals (300 words+)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/27&lt;/td&gt;&lt;td&gt;&lt;a href="text-mining.html"&gt;Text mining 1: Text exploration&lt;/a&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/03&lt;/td&gt;&lt;td&gt;&lt;a href="text-mining.html#topic-modeling"&gt;Text mining 2: Topic modeling&lt;/a&gt;&lt;ul&gt;&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/10&lt;/td&gt;&lt;td&gt;Regression and Predictive modeling&lt;ul&gt;&lt;li&gt;Recommender systems&lt;li&gt;Share project progress&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/17&lt;/td&gt;&lt;td&gt;Mid-term Quiz&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/24&lt;/td&gt;&lt;td&gt;Clustering and Dimensionality Reduction&lt;ul&gt;&lt;li&gt;Singular value decomposition (SVD)&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/01&lt;/td&gt;&lt;td&gt;&lt;a href="visualization.html"&gt;Visualization and storytelling 1&lt;/a&gt;&lt;ul&gt;&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/08&lt;/td&gt;&lt;td&gt;&lt;a href="visualization2.html"&gt;Visualization and storytelling 2&lt;/a&gt;&lt;ul&gt;&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;Progress report (1K+ words)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/15&lt;/td&gt;&lt;td&gt;Going deep: Deep learning&lt;ul&gt;&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/22&lt;/td&gt;&lt;td&gt;Going big 1: Map/reduce&lt;ul&gt;&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/29&lt;/td&gt;&lt;td&gt;Going big 2: Spark&lt;ul&gt;&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;6/05&lt;/td&gt;&lt;td&gt;Final presentation&lt;/td&gt;&lt;td&gt;Project final report (3K+ words)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;6/12&lt;/td&gt;&lt;td&gt;Final exam&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/p&gt;
&lt;!--
Memos for next time:
- DM을 배우고 왔어도, 개념을 remind 해주는 class가 초반에 두 번 정도 있으면 좋을듯. 즉, 4/10, 4/24 2회를 강의 초반에 배치
--&gt;</summary><category term="data"></category><category term="seoultech"></category><category term="lecturer"></category><category term="syllabus"></category></entry></feed>