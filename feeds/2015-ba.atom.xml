<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Courses</title><link href="//www.lucypark.kr/courses/" rel="alternate"></link><link href="//www.lucypark.kr/courses/feeds/2015-ba.atom.xml" rel="self"></link><id>//www.lucypark.kr/courses/</id><updated>2015-05-08T00:00:00+09:00</updated><entry><title>Visualization</title><link href="//www.lucypark.kr/courses/2015-ba/visualization2.html" rel="alternate"></link><published>2015-05-08T00:00:00+09:00</published><updated>2015-05-08T00:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:www.lucypark.kr,2015-05-08:courses/2015-ba/visualization2.html</id><summary type="html">&lt;p&gt;&lt;img src="images/scientist.png" width="500px"&gt; (&lt;a href="http://www.marketingdistillery.com/2014/08/30/data-science-skill-set-explained/"&gt;source&lt;/a&gt;)&lt;/p&gt;
&lt;h2&gt;[Review] Data visualization&lt;/h2&gt;
&lt;h3&gt;Data types&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Nominal, ordinal, quantitative&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Visual variables&lt;/h3&gt;
&lt;p&gt;&lt;img src="images/cues.png" width="400px"&gt;
&lt;img src="images/together.png" width="100%"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Comparisons
&lt;img src="images/comparison-1.png" width="100%"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(Source: Nathan Yau, &lt;a href="http://flowingdata.com/data-points/DataPoints-Ch3.pdf"&gt;Data points&lt;/a&gt;)&lt;/p&gt;
&lt;h3&gt;Data visualization patterns&lt;/h3&gt;
&lt;p&gt;&lt;img src="images/patterns-1.png" width="500px"&gt;
&lt;img src="images/patterns-2.png" width="500px"&gt;
&lt;img src="images/patterns-3.png" width="500px"&gt;&lt;/p&gt;
&lt;p&gt;(Source: Joel Laumans, &lt;a href="http://piksels.com/wp-content/uploads/2009/01/visualizingdata.pdf"&gt;An introduction to visualizing data&lt;/a&gt;)&lt;/p&gt;
&lt;h2&gt;Map visualizations (Geomapping)&lt;/h2&gt;
&lt;h3&gt;Projections&lt;/h3&gt;
&lt;p&gt;&lt;img src="images/projections-0.png" width="300px"&gt;&lt;br&gt;
&lt;img src="images/projections-1.png" width="400px"&gt;&lt;br&gt;
&lt;img src="images/projections-2.png" width="400px"&gt;&lt;br&gt;
(Source: &lt;a href="http://www.jasondavies.com/maps/"&gt;Jason Davies&lt;/a&gt;)&lt;/p&gt;
&lt;h3&gt;Visual variables for spatial data&lt;/h3&gt;
&lt;p&gt;&lt;img src="images/spatial-variables.png" width="100%"&gt;&lt;/p&gt;
&lt;h3&gt;Examples&lt;/h3&gt;
&lt;h4&gt;Dot map: A dot for every data point&lt;/h4&gt;
&lt;p&gt;&lt;img src="images/dot-map.png" width="400px"&gt;
&lt;img src="images/sushi.png" width="400px"&gt;(&lt;a href="http://bl.ocks.org/e9t/ba9edd99793a5c91eaab"&gt;source&lt;/a&gt;)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How to lie with a dot map&lt;br&gt;
&lt;img src="http://imgs.xkcd.com/comics/heatmap.png" width="400px"&gt;&lt;br&gt;
(Source: &lt;a href="http://xkcd.com/1138/"&gt;xkcd&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;Choropleth map: Attribute uniformly distributed in region&lt;/h4&gt;
&lt;p&gt;&lt;img src="images/choropleth.png" width="400px"&gt;(&lt;a href="http://bl.ocks.org/mbostock/4060606"&gt;source&lt;/a&gt;)
&lt;img src="images/population.png" width="400px"&gt;(&lt;a href="http://bl.ocks.org/e9t/55699e9fa8c3eb7fe40c"&gt;source&lt;/a&gt;)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How to lie with a choropleth&lt;br&gt;
&lt;img src="images/example-1.png" width="300px"&gt;&lt;br&gt;
(Source: &lt;a href="http://elections.huffingtonpost.com/2012/results"&gt;Huffington Post&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;Cartograms: Size of region scaled to attribute value&lt;/h4&gt;
&lt;p&gt;&lt;img src="images/cartogram.png" width="400px"&gt;&lt;/p&gt;
&lt;p&gt;(Source: Shawn Allen, &lt;a href="http://prag.ma/code/d3-cartogram/#intlmig/2011"&gt;Cartograms with d3 &amp;amp; TopoJSON&lt;/a&gt;)&lt;/p&gt;
&lt;!--
#### Others
&lt;img src="images/example-4.png" width="400px"&gt; ([source](http://www.biz-gis.com/index.php?mid=GIS_Essay&amp;document_srl=60689&amp;sort_index=readed_count&amp;order_type=asc))&lt;br&gt;
&lt;img src="images/example-3.png" width="300px"&gt; ([source](http://powertothepeople.kr/comm/bbs/board.php?bo_table=news&amp;wr_id=374&amp;page=5))&lt;br&gt;
--&gt;

&lt;p&gt;(Source: Maneesh Agrawala, &lt;a href="http://vis.berkeley.edu/courses/cs294-10-fa14/wiki/images/3/3f/Lec294-10-20141006.pdf"&gt;D3 Introduction&lt;/a&gt;, Mike Bostock, &lt;a href="http://bost.ocks.org/mike/d3/workshop/"&gt;D3 workshop&lt;/a&gt;)&lt;/p&gt;
&lt;h2&gt;Visualization tools&lt;/h2&gt;
&lt;h3&gt;D3&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Go to &lt;a href="http://d3js.org/"&gt;d3js.org&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;MapBox&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Go to &lt;a href="https://www.mapbox.com"&gt;MapBox&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/mapbox.png" width="500px"&gt;&lt;/p&gt;</summary><category term="lectures"></category></entry><entry><title>Visualization</title><link href="//www.lucypark.kr/courses/2015-ba/visualization1.html" rel="alternate"></link><published>2015-05-01T00:00:00+09:00</published><updated>2015-05-01T00:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:www.lucypark.kr,2015-05-01:courses/2015-ba/visualization1.html</id><summary type="html">&lt;h2&gt;What is data visualization?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The visual representation of information&lt;/li&gt;
&lt;li&gt;Goals of data visualization&lt;ul&gt;
&lt;li&gt;Effective, clear communication of information&lt;/li&gt;
&lt;li&gt;Stimulate viewer engagement&lt;/li&gt;
&lt;li&gt;Exploratory data analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Advantages of visualization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;With many numbers and large datasets, need an efficient way to understand a vast amount of data&lt;/li&gt;
&lt;li&gt;The human visual system is the highest-bandwidth channel to the human brain&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: Given the income, college degree percentage of each state, try answering the following questions with either a table and a graphic representation. Which method is better in answering the questions?&lt;br&gt;
- Which state has highest income?&lt;br&gt;
- Relationship between income and education?&lt;br&gt;
- Outliers?&lt;br&gt;
&lt;img src="images/table.png" width="250px"&gt;
&lt;img src="images/graph.png" width="400px"&gt;&lt;br&gt;
(Example by &lt;a href="http://en.wikipedia.org/wiki/Marti_Hearst"&gt;Marti Hearst&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Graphs reveal data that statistics may not&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: &lt;a href="http://en.wikipedia.org/wiki/Anscombe's_quartet"&gt;Anscombe's quartet&lt;/a&gt;&lt;br&gt;
&lt;div class="row"&gt;
&lt;div class="col-md-6"&gt;
&lt;table class="table"&gt;&lt;tr&gt;&lt;th&gt;I&lt;/th&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;II&lt;/th&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;III&lt;/th&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;IV&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;x&lt;/td&gt;&lt;td&gt;y&lt;/td&gt;&lt;td&gt;x&lt;/td&gt;&lt;td&gt;y&lt;/td&gt;&lt;td&gt;x&lt;/td&gt;&lt;td&gt;y&lt;/td&gt;&lt;td&gt;x&lt;/td&gt;&lt;td&gt;y&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;10.0&lt;/td&gt;&lt;td&gt;8.04&lt;/td&gt;&lt;td&gt;10.0&lt;/td&gt;&lt;td&gt;9.14&lt;/td&gt;&lt;td&gt;10.0&lt;/td&gt;&lt;td&gt;7.46&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;6.58&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;6.95&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;8.14&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;6.77&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;5.76&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;13.0&lt;/td&gt;&lt;td&gt;7.58&lt;/td&gt;&lt;td&gt;13.0&lt;/td&gt;&lt;td&gt;8.74&lt;/td&gt;&lt;td&gt;13.0&lt;/td&gt;&lt;td&gt;12.74&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;7.71&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;9.0&lt;/td&gt;&lt;td&gt;8.81&lt;/td&gt;&lt;td&gt;9.0&lt;/td&gt;&lt;td&gt;8.77&lt;/td&gt;&lt;td&gt;9.0&lt;/td&gt;&lt;td&gt;7.11&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;8.84&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;11.0&lt;/td&gt;&lt;td&gt;8.33&lt;/td&gt;&lt;td&gt;11.0&lt;/td&gt;&lt;td&gt;9.26&lt;/td&gt;&lt;td&gt;11.0&lt;/td&gt;&lt;td&gt;7.81&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;8.47&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;14.0&lt;/td&gt;&lt;td&gt;9.96&lt;/td&gt;&lt;td&gt;14.0&lt;/td&gt;&lt;td&gt;8.10&lt;/td&gt;&lt;td&gt;14.0&lt;/td&gt;&lt;td&gt;8.84&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;7.04&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;6.0&lt;/td&gt;&lt;td&gt;7.24&lt;/td&gt;&lt;td&gt;6.0&lt;/td&gt;&lt;td&gt;6.13&lt;/td&gt;&lt;td&gt;6.0&lt;/td&gt;&lt;td&gt;6.08&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;5.25&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;4.0&lt;/td&gt;&lt;td&gt;4.26&lt;/td&gt;&lt;td&gt;4.0&lt;/td&gt;&lt;td&gt;3.10&lt;/td&gt;&lt;td&gt;4.0&lt;/td&gt;&lt;td&gt;5.39&lt;/td&gt;&lt;td&gt;19.0&lt;/td&gt;&lt;td&gt;12.50&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;12.0&lt;/td&gt;&lt;td&gt;10.84&lt;/td&gt;&lt;td&gt;12.0&lt;/td&gt;&lt;td&gt;9.13&lt;/td&gt;&lt;td&gt;12.0&lt;/td&gt;&lt;td&gt;8.15&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;5.56&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;7.0&lt;/td&gt;&lt;td&gt;4.82&lt;/td&gt;&lt;td&gt;7.0&lt;/td&gt;&lt;td&gt;7.26&lt;/td&gt;&lt;td&gt;7.0&lt;/td&gt;&lt;td&gt;6.42&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;7.91&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5.0&lt;/td&gt;&lt;td&gt;5.68&lt;/td&gt;&lt;td&gt;5.0&lt;/td&gt;&lt;td&gt;4.74&lt;/td&gt;&lt;td&gt;5.0&lt;/td&gt;&lt;td&gt;5.73&lt;/td&gt;&lt;td&gt;8.0&lt;/td&gt;&lt;td&gt;6.89&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;div class="col-md-6"&gt;
Simple summary statistics are all identical for four datasets
&lt;img src="images/stats.png"&gt;
However, the four datasets vary considerably when graphed
&lt;img src="images/anscombe.png"&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Data visualization process&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Classify datatypes&lt;ul&gt;
&lt;li&gt;Nominal (ex: fruits - apples, oranges, ...)&lt;ul&gt;
&lt;li&gt;Operations: ==, !=&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Ordinal (ex: quality of meat - grade A, AA, AAA, ...)&lt;ul&gt;
&lt;li&gt;Operations: ==, !=, &amp;lt;=, &amp;gt;=&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Quantitative&lt;ul&gt;
&lt;li&gt;Interval (ex: dates - May 1st, 2015, location - LAT 38.9 LON 127)&lt;ul&gt;
&lt;li&gt;Only differences may compared&lt;/li&gt;
&lt;li&gt;Operations: ==, !=, &amp;lt;=, &amp;gt;=, -&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Ratio (ex: length - 160cm)&lt;ul&gt;
&lt;li&gt;Origin is meaningful&lt;/li&gt;
&lt;li&gt;Operations: ==, !=, &amp;lt;=, &amp;gt;=, -, /&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Map datasets to visual attributes that represent data types most effectively (also known as &lt;em&gt;data encoding&lt;/em&gt;)&lt;ul&gt;
&lt;li&gt;Bertin's visual variables (Bertin, &lt;em&gt;Semiology of Graphics&lt;/em&gt;, 1967|1983)
    &lt;div class="row"&gt;
    &lt;div class="col-md-8"&gt;&lt;ul&gt;
&lt;li&gt;Position&lt;/li&gt;
&lt;li&gt;Size&lt;/li&gt;
&lt;li&gt;Value&lt;/li&gt;
&lt;li&gt;Texture&lt;/li&gt;
&lt;li&gt;Color&lt;/li&gt;
&lt;li&gt;Orientation&lt;/li&gt;
&lt;li&gt;Shape
&lt;/div&gt;
&lt;div class="col-md-4"&gt;
&lt;img src="images/bertin.png"&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Data encoding&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Objective&lt;ul&gt;
&lt;li&gt;Assume 7 visual encodings and n data attributes&lt;/li&gt;
&lt;li&gt;Pick the best encoding from the exponential number of possibilities&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Principle of Consistency&lt;ul&gt;
&lt;li&gt;The properties of the image (visual variables) should match the properties of the data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Principle of Importance Ordering&lt;ul&gt;
&lt;li&gt;Encode the most important information in the most effective way&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mackinlay’s expressiveness criteria&lt;ul&gt;
&lt;li&gt;A set of facts is expressible in a visual language if the sentences (i.e. the visualizations) in the language express all the facts in the set of data, and only the facts in the data. &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mackinlay’s effectiveness criteria&lt;ul&gt;
&lt;li&gt;A visualization is more effective than another visualization if the information conveyed by one visualization is more readily perceived than the information in the other visualization.&lt;br&gt;
&lt;img src="http://www.softviscollection.org/intro/a-thousand-words/images/ali-mackinlay.png" width="500px"&gt;
&lt;img src="images/viz-accuracy.png" width="400px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Bertin's visual variables and their syntactics. Figure derived from Bertin (1967|1983), MacEachren (1995), and MacEachren et al. (2012)&lt;br&gt;
&lt;img src="images/va.png" width="500px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Data combinations and dimensions&lt;/h2&gt;
&lt;h3&gt;Univariate data (1D)&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Line plot&lt;br&gt;&lt;img src="http://matplotlib.org/_images/spectrum_demo.png"&gt;&lt;/li&gt;
&lt;li&gt;Bar plot&lt;br&gt;&lt;img src="http://matplotlib.org/_images/xcorr_demo.png"&gt;&lt;/li&gt;
&lt;li&gt;Box-and-whisker plot&lt;br&gt;&lt;img src="images/baw.gif" alt="http://www.statgraphics.com/eda.htm"&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Bivariate data (2D)&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;2D scatter plot&lt;br&gt;&lt;img src="http://upload.wikimedia.org/wikipedia/commons/0/0f/Oldfaithful3.png"&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Trivariate data (3D)&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Use 3D scatter plot&lt;br&gt;&lt;img src="http://scikit-learn.org/stable/_images/plot_pca_iris_001.png"&gt;&lt;/li&gt;
&lt;li&gt;Map two variables [x, y] in 2D space + Map third variable [z] with another visual attribute (ex: color, shape, size)&lt;br&gt;&lt;img src="images/trivariate.png" width="200px"&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Multivariate data (&amp;gt;3D)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;How many variables can be depicted in a image?&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;"With up to three rows, a data table can be constructed directly as a single image. However, an image has only three dimensions. And this barrier is impassible." -- Bertin&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Examples&lt;/h2&gt;
&lt;h3&gt;&lt;a href="http://en.wikipedia.org/wiki/Iris_flower_data_set"&gt;Iris dataset&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img src="images/irisdata.png" width="400px"&gt;
&lt;img src="http://www.nature.com/nmeth/journal/v9/n10/images/nmeth.2186-F1.jpg" width="400px"&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a href="http://data.heapanalytics.com/how-to-lie-with-data-visualization/"&gt;How to lie with visualization&lt;/a&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Truncated Y-Axis&lt;br&gt;&lt;img src="images/lie1.png" width="400px"&gt;&lt;/li&gt;
&lt;li&gt;Cumulative graphs&lt;br&gt;&lt;img src="images/lie2-1.png" width="300px"&gt;&lt;img src="images/lie2-2.png" width="300px"&gt;&lt;/li&gt;
&lt;li&gt;Ignoring conventions&lt;br&gt;&lt;img src="https://s3.amazonaws.com/heapdatablog/misleading3_pie.png" width="400px"&gt;&lt;img src="https://s3.amazonaws.com/heapdatablog/misleading3_deaths.jpg" width="400px"&gt;&lt;/li&gt;
&lt;li&gt;For more, see &lt;a href="http://viz.wtf/"&gt;WTF visualizations&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Awesome visualization examples&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Words&lt;br&gt;&lt;img src="http://i2.wp.com/flowingdata.com/wp-content/uploads/2008/12/wordle.png?zoom=2&amp;resize=545%2C333" width="400px"&gt;&lt;/li&gt;
&lt;li&gt;Web pages&lt;ul&gt;
&lt;li&gt;&lt;a href="http://internet-map.net/"&gt;http://internet-map.net/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;World refugees&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.therefugeeproject.org/"&gt;http://www.therefugeeproject.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Movie revenues&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.nytimes.com/interactive/2008/02/23/movies/20080223_REVENUE_GRAPHIC.html"&gt;http://www.nytimes.com/interactive/2008/02/23/movies/20080223_REVENUE_GRAPHIC.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Others&lt;ul&gt;
&lt;li&gt;&lt;a href="http://infosthetics.com/"&gt;http://infosthetics.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.visualcomplexity.com/"&gt;http://www.visualcomplexity.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://datavisualization.ch/showcases/"&gt;http://datavisualization.ch/showcases/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;In-class Practice: Worldwide Disasters (1900-2008)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Visualize with the data below&lt;br&gt;&lt;img src="images/assign.png"&gt;&lt;/li&gt;
&lt;li&gt;Evaluation&lt;ul&gt;
&lt;li&gt;Expressiveness&lt;ul&gt;
&lt;li&gt;Do the mappings show the facts and only the facts?&lt;/li&gt;
&lt;li&gt;Are visual mappings consistent? (e.g., respect color mappings)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Effectiveness&lt;ul&gt;
&lt;li&gt;Are perceptually effective encodings used?&lt;/li&gt;
&lt;li&gt;Are the most important data mapped to the most effective visual variables?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cognitive Load (Efficiency)&lt;ul&gt;
&lt;li&gt;Are there extraneous (unmapped) visual elements?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data Transformation&lt;ul&gt;
&lt;li&gt;Are transformations (filter, sort, derive, aggregate) appropriate?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Guides (Non-Data Elements)&lt;ul&gt;
&lt;li&gt;Descriptive, consistent: Title, Label, Caption, Source, Annotations&lt;/li&gt;
&lt;li&gt;Meaningful references: Gridlines, Legend &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;http://selection.datavisualization.ch/&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.computerworld.com/article/2506820/business-intelligence-chart-and-image-gallery-30-free-tools-for-data-visualization-and-analysis.html"&gt;Chart and image gallery: 30+ free tools for data visualization and analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.nytimes.com/interactive/2012/12/30/multimedia/2012-the-year-in-graphics.html"&gt;NYT the year in graphics: 2012&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.nytimes.com/interactive/2014/12/29/us/year-in-interactive-storytelling.html"&gt;NYT the year in graphics: 2014&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Many contents in courtesy of &lt;a href="https://faculty.washington.edu/aragon/"&gt;Cecilia Aragon&lt;/a&gt; and &lt;a href="http://vis.berkeley.edu/~maneesh/"&gt;Maneesh Agrawala&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="lectures"></category></entry><entry><title>Bash</title><link href="//www.lucypark.kr/courses/2015-ba/bash.html" rel="alternate"></link><published>2015-04-02T00:00:00+09:00</published><updated>2015-04-02T00:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:www.lucypark.kr,2015-04-02:courses/2015-ba/bash.html</id><summary type="html">&lt;h2&gt;What is an OS?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;DOS, Windows, Linux, Mac OS, iOS, Android, ...&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Linux?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;OS&lt;/li&gt;
&lt;li&gt;Made by Linus Torvalds&lt;/li&gt;
&lt;li&gt;Inspired by Unix&lt;/li&gt;
&lt;li&gt;Debian, CentOS, Ubuntu, Fedora, Redhat Linux, Gentoo, Arch, Suse, Slackware, Mandriva, PintOS, ...&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Why Linux?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Custom&lt;/li&gt;
&lt;li&gt;Free (in some sense)&lt;/li&gt;
&lt;li&gt;Open source&lt;/li&gt;
&lt;li&gt;Supports multiple users&lt;/li&gt;
&lt;li&gt;Has compatibility with Unix-like OSs&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Files&lt;/h2&gt;
&lt;h3&gt;Directories&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;.&lt;/code&gt;: current directory&lt;/li&gt;
&lt;li&gt;&lt;code&gt;..&lt;/code&gt;: parent directory&lt;/li&gt;
&lt;li&gt;&lt;code&gt;~/&lt;/code&gt;: home directory&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/&lt;/code&gt;: root directory&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/some/absolute/path&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;some/relative/path&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/bash.jpg" width="350px"&gt;&lt;/p&gt;
&lt;h3&gt;Permissions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Read, Write, eXecute&lt;/li&gt;
&lt;li&gt;Owner, Owner group, Others&lt;/li&gt;
&lt;li&gt;rwxrwxrwx&lt;ul&gt;
&lt;li&gt;All permissions for everyone&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- GNU linux history --&gt;

&lt;h2&gt;&lt;a href="https://www.gnu.org/software/bash/manual/html_node/What-is-Bash_003f.html"&gt;What is Bash?&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Bash is a "shell" for the GNU operating system&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/bash.png" width="500px"&gt;&lt;/p&gt;
&lt;h3&gt;Then &lt;a href="https://www.gnu.org/software/bash/manual/html_node/What-is-a-shell_003f.html###What-is-a-shell_003f"&gt;what is a shell?&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A shell is a macro processor that executes commands&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/kernel.png" width="500px"&gt;&lt;/p&gt;
&lt;h3&gt;Is Bash the only shell available?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;No.&lt;/li&gt;
&lt;li&gt;There are many many alternatives, such as &lt;code&gt;sh&lt;/code&gt;, &lt;code&gt;ksh&lt;/code&gt;, &lt;code&gt;csh&lt;/code&gt; or &lt;code&gt;zsh&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;However, &lt;code&gt;bash&lt;/code&gt; is the default shell in GNU systems&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Can I use &lt;code&gt;bash&lt;/code&gt; in GNU systems only?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;No.&lt;/li&gt;
&lt;li&gt;You can also use bash in Windows and other platforms, using portable versions&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Why should I use Bash?&lt;/h2&gt;
&lt;h3&gt;Package managing&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What is a package?&lt;/li&gt;
&lt;li&gt;What is it to manage a package?&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;What kind of package managers are there?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Windows: ???&lt;/li&gt;
&lt;li&gt;Mac: Homebrew&lt;/li&gt;
&lt;li&gt;Ubuntu: apt-get&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!--
Some jokes about package managing:
- https://twitter.com/gardaud/status/357638468572151808
- https://twitter.com/ddprrt/status/529909875347030016
--&gt;

&lt;h3&gt;Data science&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.ecogwiki.com/Hash-based_sampling"&gt;Data sampling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;...&lt;a href="http://jeroenjanssens.com/2013/09/19/seven-command-line-tools-for-data-science.html"&gt;and more&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="programming"></category><category term="seoultech"></category><category term="lectures"></category></entry><entry><title>Mining English and Korean text with Python</title><link href="//www.lucypark.kr/courses/2015-ba/text-mining.html" rel="alternate"></link><published>2015-03-27T15:00:00+09:00</published><updated>2015-03-27T15:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:www.lucypark.kr,2015-03-27:courses/2015-ba/text-mining.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;We use Python 3 in this tutorial, but provide minimal guidelines for Python 2.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Terminologies&lt;/h2&gt;
&lt;p&gt;&lt;table class="table"&gt;&lt;tr&gt;&lt;th&gt;English&lt;/th&gt;&lt;th&gt;한국어&lt;/th&gt;&lt;th&gt;Description&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Document&lt;/td&gt;&lt;td&gt;문서&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Corpus&lt;/td&gt;&lt;td&gt;말뭉치&lt;/td&gt;&lt;td&gt;A set of documents&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Token&lt;/td&gt;&lt;td&gt;토큰&lt;/td&gt;&lt;td&gt;Meaningful elements in a text such as words or phrases or symbols&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Morphemes&lt;/td&gt;&lt;td&gt;형태소&lt;/td&gt;&lt;td&gt;Smallest meaningful unit in a language&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;POS&lt;/td&gt;&lt;td&gt;품사&lt;/td&gt;&lt;td&gt;Part-of-speech (ex: Nouns)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Classification&lt;/td&gt;&lt;td&gt;분류&lt;/td&gt;&lt;td&gt;A supervised learning task where $X$ and $y$ are given and $y$ is a set of discrete classes&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Clustering&lt;/td&gt;&lt;td&gt;군집화&lt;/td&gt;&lt;td&gt;An unsupervised learning task where $X$ is given&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/p&gt;
&lt;h2&gt;Text analysis process&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Load text&lt;/li&gt;
&lt;li&gt;Tokenize text (ex: stemming, morph analyzing)&lt;/li&gt;
&lt;li&gt;Tag tokens (ex: POS, NER)&lt;/li&gt;
&lt;li&gt;Token(Feature) selection and/or filter/rank tokens (ex: stopword removal, TF-IDF)&lt;/li&gt;
&lt;li&gt;...and so on (ex: calculate word/document similarities, cluster documents)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Python Packages for Text Mining and NLP&lt;/h2&gt;
&lt;p&gt;...that we use in this tutorial.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://nltk.org"&gt;NLTK&lt;/a&gt;: Provides modules for text analysis (mostly language independent)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install nltk
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.nltk.org/book/ch02.html"&gt;Text corpora&lt;/a&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;gutenberg&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;maxent_treebank_pos_tagger&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.nltk.org/api/nltk.tag.html"&gt;Word POS, NER classification&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.nltk.org/book/ch06.html"&gt;Document classification&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://konlpy.org"&gt;KoNLPy&lt;/a&gt;: Provides modules for Korean text analysis&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install konlpy
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;&lt;a href="http://konlpy.org/en/latest/data/#corpora"&gt;Text corpora&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://konlpy.org/en/latest/api/konlpy.tag/"&gt;Word POS classification&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Hannanum&lt;/li&gt;
&lt;li&gt;Kkma&lt;/li&gt;
&lt;li&gt;Mecab&lt;/li&gt;
&lt;li&gt;Komoran&lt;/li&gt;
&lt;li&gt;Twitter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http//radimrehurek.com/gensim/"&gt;Gensim&lt;/a&gt;: Provides modules for topic modeling and calculating similarities among documents&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install -U gensim
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Topic modeling&lt;ul&gt;
&lt;li&gt;&lt;a href="http://radimrehurek.com/gensim/models/ldamodel.html"&gt;Latent Dirichlet allocation (LDA)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://radimrehurek.com/gensim/models/lsimodel.html"&gt;Latent semantic indexing (LSI)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://radimrehurek.com/gensim/models/hdpmodel.html"&gt;Hierarchical Dirichlet process (HDP)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Word embedding&lt;ul&gt;
&lt;li&gt;&lt;a href="radimrehurek.com/gensim/models/word2vec.html"&gt;word2vec&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/ryanmcgrath/twython"&gt;Twython&lt;/a&gt;: Provides easy access to Twitter API&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install twython
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Example: Getting "Samsung (삼성)" related tweets&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;twython&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twython&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;settings&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;s&lt;/span&gt;    &lt;span class="c1"&gt;# Create a file named settings.py, and put oauth KEY values inside&lt;/span&gt;
&lt;span class="n"&gt;twitter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twython&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;APP_KEY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;APP_SECRET&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OAUTH_TOKEN&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OAUTH_TOKEN_SECRET&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tweets&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;twitter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;삼성&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;user&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;screen_name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;created_at&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tweets&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;statuses&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Text exploration&lt;/h2&gt;
&lt;h3&gt;1. Read document&lt;/h3&gt;
&lt;p&gt;As example documents, we select
&lt;a href="http://www.gutenberg.org/ebooks/158"&gt;Jane Austen's Emma&lt;/a&gt; for English,
and &lt;a href="http://pokr.kr/bill/1809890"&gt;Korea National Assembly's bill number 1809890&lt;/a&gt; for Korean.
Otherwise, you can use a document of your own with &lt;code&gt;open('some_file.txt').read()&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;gutenberg&lt;/span&gt;   &lt;span class="c1"&gt;# Docs from project gutenberg.org&lt;/span&gt;
&lt;span class="n"&gt;files_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gutenberg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;      &lt;span class="c1"&gt;# Get file ids&lt;/span&gt;
&lt;span class="n"&gt;doc_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gutenberg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;austen-emma.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;    &lt;span class="c1"&gt;# Docs from pokr.kr/bill&lt;/span&gt;
&lt;span class="n"&gt;files_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;         &lt;span class="c1"&gt;# Get file ids&lt;/span&gt;
&lt;span class="n"&gt;doc_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;1809890.txt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2. Tokenize&lt;/h3&gt;
&lt;p&gt;There are numerous ways to tokenize a document.&lt;/p&gt;
&lt;p&gt;Here, we use &lt;code&gt;nltk.regexp_tokenize&lt;/code&gt; for English,
&lt;code&gt;konlpy.tag.Twitter.morph&lt;/code&gt; for Korean text.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;regexp_tokenize&lt;/span&gt;
&lt;span class="n"&gt;pattern&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;r&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&amp;#39;&amp;#39;(?x) ([A-Z]\.)+ | \w+(-\w+)* | \$?\d+(\.\d+)?%? | \.\.\. | [][.,;&amp;quot;&amp;#39;?():-_`]&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;tokens_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;regexp_tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pattern&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.tag&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;tokens_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;morphs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;3. Load tokens with &lt;code&gt;nltk.Text()&lt;/code&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt;
&lt;span class="n"&gt;en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;nltk&lt;/span&gt;
&lt;span class="n"&gt;ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;대한민국 국회 의안 제 1809890호&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# For Python 2, input `name` as u&amp;#39;유니코드&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;nltk.Text()&lt;/code&gt; is a convenient way to explore a current document.
For Python 2, &lt;code&gt;name&lt;/code&gt; has to be input as u'유니코드'.
If you are using Python 2, use u'유니코드' for input of all following Korean text.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Tokens&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;       &lt;span class="c1"&gt;# returns number of tokens (document length)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;  &lt;span class="c1"&gt;# returns number of unique tokens&lt;/span&gt;
&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;                  &lt;span class="c1"&gt;# returns frequency distribution&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
191061
7927
FreqDist({',': 12018, '.': 8853, 'to': 5127, 'the': 4844, 'and': 4653, 'of': 4278, '"': 4187, 'I': 3177, 'a': 3000, 'was': 2385, ...})
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;       &lt;span class="c1"&gt;# returns number of tokens (document length)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;  &lt;span class="c1"&gt;# returns number of unique tokens&lt;/span&gt;
&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;                  &lt;span class="c1"&gt;# returns frequency distribution&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
1707
476
FreqDist({'.': 61, '의': 46, '육아휴직': 38, '을': 34, '(': 27, ',': 26, '이': 26, ')': 26, '에': 24, '자': 24, ...})
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Plot frequency distributions&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;     &lt;span class="c1"&gt;# Plot sorted frequency of top 50 tokens&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/fdist_en.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;     &lt;span class="c1"&gt;# Plot sorted frequency of top 50 tokens&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/fdist_ko.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: To save a plot programmably, and not through the GUI, overwrite &lt;code&gt;pylab.show&lt;/code&gt; with &lt;code&gt;pylab.savefig&lt;/code&gt; before drawing the plot (&lt;a href="http://stackoverflow.com/questions/27392390/how-do-i-send-nltk-plots-to-files"&gt;reference&lt;/a&gt;):
&lt;pre&gt;
from matplotlib import pylab
pylab.show = lambda: pylab.savefig('some_filename.png')
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Troubleshooting&lt;/strong&gt;: For those who see rectangles instead of letters in the saved plot file, include the following configurations before drawing the plot:
&lt;pre&gt;
from matplotlib import font_manager, rc
font_fname = 'c:/windows/fonts/gulim.ttc'     # A font of your choice
font_name = font_manager.FontProperties(fname=font_fname).get_name()
rc('font', family=font_name)
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;Some example fonts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mac OS: &lt;code&gt;/Library/Fonts/AppleGothic.ttf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Count&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;        &lt;span class="c1"&gt;# Counts occurrences&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
865
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;초등학교&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# Counts occurrences&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
6
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dispersion plot&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dispersion_plot&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Frank&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Jane&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/disp_en.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dispersion_plot&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;육아휴직&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;초등학교&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;공무원&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/disp_ko.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Concordance&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concordance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lines&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
Displaying 5 of 865 matches:
                                     Emma by Jane Austen 1816 ] VOLUME I CHAPT
                                     Emma Woodhouse , handsome , clever , and 
both daughters , but particularly of Emma . Between &lt;em&gt;them&lt;/em&gt; it was more the int
 friend very mutually attached , and Emma doing just what she liked ; highly e
r own . The real evils , indeed , of Emma ' s situation were the power of havi
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean (or, use &lt;a href="http://konlpy.org/en/v0.4.3/api/konlpy/#konlpy.utils.concordance"&gt;konlpy.utils.concordance&lt;/a&gt;)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concordance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;초등학교&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
Displaying 6 of 6 matches:
 ․ 김정훈 김학송 의원 ( 10 인 ) 제안 이유 및 주요 내용 초등학교 저학년 의 경우 에도 부모 의 따뜻한 사랑 과 보살핌 이 필요 한
 을 할 수 있는 자녀 의 나이 는 만 6 세 이하 로 되어 있어 초등학교 저학년 인 자녀 를 돌보기 위해서 는 해당 부모님 은 일자리 를 
 다 . 제 63 조제 2 항제 4 호 중 “ 만 6 세 이하 의 초등학교 취학 전 자녀 를 ” 을 “ 만 8 세 이하 ( 취학 중인 경우 
 전 자녀 를 ” 을 “ 만 8 세 이하 ( 취학 중인 경우 에는 초등학교 2 학년 이하 를 말한 다 ) 의 자녀 를 ” 로 한 다 . 부 
 . ∼ 3 . ( 현행 과 같 음 ) 4 . 만 6 세 이하 의 초등학교 취 4 . 만 8 세 이하 ( 취학 중인 경우 학 전 자녀 를 양
세 이하 ( 취학 중인 경우 학 전 자녀 를 양육 하기 위하 에는 초등학교 2 학년 이하 를 여 필요하거 나 여자 공무원 이 말한 다 ) 의
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find similar words&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Emma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Frank&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
she it he i harriet you her jane him that me and all they them there herself was hartfield be
mr mrs emma harriet you it her she he him hartfield them jane that isabella all herself look i me
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;자녀&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;육아휴직&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
논의
None
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Collocations&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;collocations&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
Frank Churchill; Miss Woodhouse; Miss Bates; Jane Fairfax; Miss
Fairfax; every thing; young man; every body; great deal; dare say;
John Knightley; Maple Grove; Miss Smith; Miss Taylor; Robert Martin;
Colonel Campbell; Box Hill; said Emma; Harriet Smith; William Larkins
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;collocations&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
초등학교 저학년; 육아휴직 대상
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;!--
1. Common contexts
    - English

            :::python
            en.common_contexts(['Emma', 'Frank'])

        &lt;pre class="result"&gt;
        that_could that_s for_i and_and and_was between_and on_s of_s to_it in_s
        &lt;/pre&gt;

    - Korean

            :::python
            ko.common_contexts(['육아휴직'])

        &lt;pre class="result"&gt;
        따라서_이 에서_급 p_대상자 받는_자 경우_급여 으로_기간 n_급 위하여_을 인_자 대비하여_자 와_자 따라_신청 표_급여
        에게_자 에는_자 근로자_가능 평균_급여 이며_에 에_자 가_을
        &lt;/pre&gt;
--&gt;

&lt;p&gt;For more information on &lt;code&gt;nltk.Text()&lt;/code&gt;, see the &lt;a href="http://www.nltk.org/_modules/nltk/text.html#Text"&gt;source code&lt;/a&gt; or &lt;a href="http://www.nltk.org/api/nltk.html#nltk.text.Text"&gt;API&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Tagging and chunking&lt;/h2&gt;
&lt;p&gt;Until now, we used delimited text, namely &lt;em&gt;tokens&lt;/em&gt;, to explore our sample document.
Now let's classify words into given classes, namely &lt;em&gt;part-of-speech tags&lt;/em&gt;, and chunk text into larger pieces.&lt;/p&gt;
&lt;h3&gt;1. POS tagging&lt;/h3&gt;
&lt;p&gt;There are numerous ways of tagging a text.
Among them, the most frequently used, and developed way of tagging is arguably POS tagging.&lt;/p&gt;
&lt;p&gt;Since one document is too long to observe a parsed structure,
lets use one short sentence for each language.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;The little yellow dog barked at the Persian cat&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;tags_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[('The', 'DT'),
 ('little', 'JJ'),
 ('yellow', 'NN'),
 ('dog', 'NN'),
 ('barked', 'VBD'),
 ('at', 'IN'),
 ('the', 'DT'),
 ('Persian', 'NNP'),
 ('cat', 'NN')]
&lt;/pre&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is also possible to use the famous &lt;a href="http://www.nltk.org/api/nltk.tag.html#module-nltk.tag.stanford"&gt;Stanford POS tagger with NLTK&lt;/a&gt;, with &lt;code&gt;from nltk.tag.stanford import POSTagger&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.tag&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;tags_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;작고 노란 강아지가 페르시안 고양이에게 짖었다&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[('작고', 'Noun'),
 ('노란', 'Adjective'),
 ('강아지', 'Noun'),
 ('가', 'Josa'),
 ('페르시안', 'Noun'),
 ('고양이', 'Noun'),
 ('에게', 'Josa'),
 ('짖었', 'Noun'),
 ('다', 'Josa')]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2. Noun phrase chunking&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.nltk.org/api/nltk.chunk.html#nltk.chunk.regexp.RegexpParser"&gt;&lt;code&gt;nltk.RegexpParser()&lt;/code&gt;&lt;/a&gt; is a great way to start chunking.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;parser_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RegexpParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;NP: {&amp;lt;DT&amp;gt;?&amp;lt;JJ&amp;gt;?&amp;lt;NN.*&amp;gt;*}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tags_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;draw&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/tree_en.png" width="500px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;parser_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nltk&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RegexpParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;NP: {&amp;lt;Adjective&amp;gt;*&amp;lt;Noun&amp;gt;*}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tags_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;chunks_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;draw&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="images/tree_ko.png" width="700px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information on chunking, refer to &lt;a href="http://www.nltk.org/book/ch07.html"&gt;Extracting Information from Text&lt;/a&gt; for English, and &lt;a href="http://konlpy.org/en/v0.4.3/examples/chunking/"&gt;Chunking&lt;/a&gt; for Korean.&lt;/p&gt;
&lt;h2&gt;Topic modeling&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Topic modeling in a nutshell&lt;br&gt;
    &lt;img src="images/topic-modeling.png" width="600px"&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;History&lt;br&gt;
    &lt;img src="images/tm-history.png" width="600px"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LSI: Learns latent topics by performing a matrix decomposition (SVD) on the term-document matrix&lt;/li&gt;
&lt;li&gt;LDA: A generative probabilistic model, that assumes a Dirichelt prior over the latent topics&lt;/li&gt;
&lt;li&gt;HDP: A natural nonparametric generalization of LDA, where the number of topics can be unbounded ant learnt from data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;1. Preprocessing&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Load documents&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;reuters&lt;/span&gt;
&lt;span class="n"&gt;docs_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;reuters&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;reuters&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;
&lt;span class="n"&gt;docs_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tokenize&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;docs_en&lt;/span&gt; &lt;span class="c1"&gt;# because we loaded tokenized documents in step 1&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', ...]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.tag&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;pos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stem&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;norm&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;texts_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;docs_ko&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['지방공무원법/Noun', '일부/Noun', '개정/Noun', '법률/Noun', '안/Noun', '(/Punctuation', '정의화/Noun', '의원/Noun', ...]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Encode tokens to integers&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gensim&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;corpora&lt;/span&gt;
&lt;span class="n"&gt;dictionary_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;corpora&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dictionary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;en.dict&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# save dictionary to file for future use&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gensim&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;corpora&lt;/span&gt;
&lt;span class="n"&gt;dictionary_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;corpora&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dictionary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ko.dict&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# save dictionary to file for future use&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Calculate TF-IDF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gensim&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;
&lt;span class="n"&gt;tf_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;doc2bow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;texts_en&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;tfidf_model_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TfidfModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tfidf_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_model_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tf_en&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;corpora&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MmCorpus&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;serialize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;en.mm&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tfidf_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# save corpus to file for future use&lt;/span&gt;

&lt;span class="c1"&gt;# print first 10 elements of first document&amp;#39;s tf-idf vector&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="c1"&gt;# print top 10 elements of first document&amp;#39;s tf-idf vector&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="c1"&gt;# print token of most frequent element&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[(0, 7), (1, 3), (2, 13), (3, 2), (4, 1), (5, 1), (6, 20), (7, 6), (8, 10), (9, 62)]
[(9, 62), (363, 32), (276, 30), (371, 26), (6, 20), (96, 19), (112, 19), (326, 16), (118, 14), (2, 13)]
'.'
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gensim&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;
&lt;span class="n"&gt;tf_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;doc2bow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;texts_ko&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;tfidf_model_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TfidfModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tfidf_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_model_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tf_ko&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;corpora&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MmCorpus&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;serialize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ko.mm&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tfidf_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# save corpus to file for future use&lt;/span&gt;

&lt;span class="c1"&gt;# print first 10 elements of first document&amp;#39;s tf-idf vector&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="c1"&gt;# print top 10 elements of first document&amp;#39;s tf-idf vector&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="c1"&gt;# print token of most frequent element&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;414&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[(0, 10), (1, 27), (2, 1), (3, 26), (4, 3), (5, 26), (6, 4), (7, 2), (8, 1), (9, 1)]
[(414, 71), (14, 61), (309, 38), (314, 38), (313, 28), (1, 27), (3, 26), (5, 26), (353, 22), (13, 21)]
'하다/Verb'
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;2. Train topic models&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;LSI&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nwords&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;lsi_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lsimodel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LsiModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id2word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lsi_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_topics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nwords&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['0.509*"vs" + 0.272*"000" + 0.258*"cts" + 0.243*"loss" + 0.238*"mln"',
'-0.294*"the" + 0.237*"vs" + -0.176*"to" + -0.148*"in" + -0.137*"pct"',
'0.331*"Record" + 0.316*"div" + 0.312*"Pay" + 0.303*"Qtly" + 0.268*"prior"']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nwords&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;lsi_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lsimodel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LsiModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id2word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lsi_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_topics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nwords&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['0.518*"육아휴직/Noun" + 0.257*"만/Noun" + 0.227*"×/Foreign" + 0.214*"대체/Noun" + 0.201*"고용/Noun"',
 '0.449*"파견/Noun" + 0.412*"부대/Noun" + 0.267*"UAE/Alpha" + 0.243*"○/Foreign" + 0.192*"국군/Noun"',
 '0.326*"결혼/Noun" + 0.315*"예고/Noun" + 0.285*"손해/Noun" + 0.205*"ㆍ/Foreign" + 0.197*"원사/Noun"']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LDA&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# optional&lt;/span&gt;
&lt;span class="n"&gt;lda_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ldamodel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LdaModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id2word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lda_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_topics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nwords&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['0.005*the + 0.003*to + 0.003*pct + 0.002*of + 0.002*said',
 '0.005*cts + 0.005*Record + 0.005*div + 0.004*Pay + 0.004*Qtly',
 '0.010*vs + 0.006*mln + 0.006*000 + 0.005*loss + 0.004*cts']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# optional&lt;/span&gt;
&lt;span class="n"&gt;lda_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ldamodel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LdaModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id2word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lda_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_topics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nwords&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['0.001*학위/Noun + 0.001*파견/Noun + 0.001*손해/Noun + 0.001*간호/Noun + 0.001*소말리아/Noun',
 '0.002*파견/Noun + 0.002*부대/Noun + 0.001*UAE/Alpha + 0.001*손해/Noun + 0.001*○/Foreign',
 '0.003*육아휴직/Noun + 0.002*만/Noun + 0.002*×/Foreign + 0.002*대체/Noun + 0.002*고용/Noun']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;HDP&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# optional&lt;/span&gt;
&lt;span class="n"&gt;hdp_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hdpmodel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HdpModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id2word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hdp_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_topics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;topn&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nwords&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['topic 0: 0.005*the + 0.003*to + 0.002*in + 0.002*a + 0.002*of',
 'topic 1: 0.008*vs + 0.005*000 + 0.004*loss + 0.004*mln + 0.004*cts',
 'topic 2: 0.001*the + 0.001*vs + 0.001*in + 0.001*to + 0.001*mln']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# optional&lt;/span&gt;
&lt;span class="n"&gt;hdp_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hdpmodel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HdpModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tfidf_ko&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id2word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hdp_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_topics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;topics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ntopics&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;topn&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nwords&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
['topic 0: 0.004*소집/Noun + 0.004*도/Josa + 0.004*’/Foreign + 0.004*｢/Foreign + 0.004*9892/Number',
 'topic 1: 0.004*이애주/Noun + 0.004*年/Foreign + 0.004*意思/Foreign + 0.004*마찰/Noun + 0.004*고 려/Noun',
 'topic 2: 0.005*명시/Noun + 0.004*영업정지/Noun + 0.004*세로/Noun + 0.004*중개업/Noun + 0.004*다양하다/Adjective']
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;3. Scoring documents&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_model_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;doc2bow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lsi_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lda_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hdp_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[(0, 0.1336800876240628),
 (2, -0.030832981664564624),
 (1, -0.39895210562646022)]&lt;/p&gt;
&lt;p&gt;[(2, 0.84087091284115845),
 (0, 0.13882114432084294),
 (1, 0.020307942837998694)]&lt;/p&gt;
&lt;p&gt;[(0, 0.95369717052959579)]
&lt;/pre&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_model_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dictionary_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;doc2bow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lsi_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lda_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hdp_en&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[(0, 0.072924758682943097),
 (2, -0.0029545572070390153),
 (1, -0.13195370933374836)]&lt;/p&gt;
&lt;p&gt;[(0, 0.62957273636869904),
 (2, 0.3270007771486681),
 (1, 0.043426486482632851)]&lt;/p&gt;
&lt;p&gt;[(0, 0.90574410236561731),
 (1, 0.010409702375525492)]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_model_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;doc2bow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lsi_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lda_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hdp_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[(0, 0.97829017893328929),
 (1, -0.016909513239922121),
 (2, -0.020121561014425089)]&lt;/p&gt;
&lt;p&gt;[(2, 0.93880436704581616),
 (0, 0.030626827732744354),
 (1, 0.030568805221439507)]&lt;/p&gt;
&lt;p&gt;[(0, 0.94848723192042672),
 (1, 0.014364056233061516),
 (2, 0.010285449586192942)]
&lt;/pre&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf_model_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dictionary_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;doc2bow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lsi_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lda_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hdp_ko&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bow&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[(0, 0.97829017893328929),
 (1, -0.016909513239922121),
 (2, -0.020121561014425089)]&lt;/p&gt;
&lt;p&gt;[(2, 0.93881674048370278),
 (0, 0.0306176131467021),
 (1, 0.030565646369595065)]&lt;/p&gt;
&lt;p&gt;[(0, 0.94848723192042672),
 (1, 0.014364056233061516),
 (2, 0.010285449586192942)]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- Add document/query similarities http://radimrehurek.com/gensim/tut3.html#similarity-interface --&gt;

&lt;blockquote&gt;
&lt;p&gt;Confident with topic modeling? Try a bigger dataset: &lt;a href="http://radimrehurek.com/gensim/wiki.html"&gt;Experiments on the English Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Word embedding&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Objective: Learn feature vectors from documents&lt;ul&gt;
&lt;li&gt;Text is normally represented with one-hot encoding + hand crafted features&lt;/li&gt;
&lt;li&gt;Ex: [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 ]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Word embedding&lt;/strong&gt;: A set of feature unsupervised learning techniques where words are mapped to n-dimensional vectors of real numbers (the continuous space)&lt;ul&gt;
&lt;li&gt;Use local context to get a more syntactic or semantic representation&lt;/li&gt;
&lt;li&gt;Ex: v("cat") = [0.2, -0.4, ..., 0.7], v("mat") = [-0.0, -0.2, ..., -0.1]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Approaches&lt;ul&gt;
&lt;li&gt;Neural networks (Bengio et al., 2001, Mikolov et al., 2013)&lt;/li&gt;
&lt;li&gt;Dimensionality reduction (Lebret et al., 2013)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;word2vec (Mikolov et al., 2013)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A neural network based embedding method for learning distributed vector representations of words&lt;ul&gt;
&lt;li&gt;No hidden layers!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;"an optimized single-machine  can train 100B+ words in one day"&lt;/li&gt;
&lt;li&gt;CBOW &amp;amp; Skip-gram: Two ways of creating the "task" for the neural network&lt;br&gt;
    &lt;img src="images/cbow-skip.png" width="600px"&gt;&lt;/li&gt;
&lt;li&gt;Characteristics&lt;ul&gt;
&lt;li&gt;Places similar words next to each other in a vector space&lt;/li&gt;
&lt;li&gt;Places similar relations in parallel (preserve linguistic regularities)&lt;ul&gt;
&lt;li&gt;ex: France: Paris = Germany: Berlin != Italy: Madrid&lt;br&gt;
    &lt;img src="images/countries.png" width="400px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Linguistic regularities&lt;ul&gt;
&lt;li&gt;v(KING) – v(MAN) + v(WOMAN) = v(QUEEN)&lt;/li&gt;
&lt;li&gt;v(KINGS) – v(KING) + v(QUEEN) = v(QUEENS)&lt;/li&gt;
&lt;li&gt;v(MADRID) – v(SPAIN) + v(FRANCE) = v(PARIS)&lt;/li&gt;
&lt;li&gt;&lt;img src="images/regularities.png" width="400px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Applications&lt;ul&gt;
&lt;li&gt;Machine translation (Socher et al., 2013)&lt;br&gt;
    &lt;img src="images/embedding-mt.png" width="400px"&gt;&lt;/li&gt;
&lt;li&gt;Jointly embedding images and text (Frome et al., 2013, &lt;a href="http://googleresearch.blogspot.co.uk/2014/11/a-picture-is-worth-thousand-coherent.html"&gt;link&lt;/a&gt;)&lt;br&gt;
    &lt;img src="images/google-text.png" width="600px"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Some good references to begin with in case you are interested:&lt;ul&gt;
&lt;li&gt;http://radimrehurek.com/2014/02/word2vec-tutorial/&lt;/li&gt;
&lt;li&gt;http://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let's go for it.&lt;/p&gt;
&lt;h3&gt;word2vec toy problem&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Load documents&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;reuters&lt;/span&gt;
&lt;span class="n"&gt;docs_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;reuters&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;reuters&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;
&lt;span class="n"&gt;docs_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;kobill&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fileids&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tokenize&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;docs_en&lt;/span&gt; &lt;span class="c1"&gt;# because we loaded tokenized documents in step 1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;konlpy.tag&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twitter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;pos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;texts_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;docs_ko&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Train&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gensim.models&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;word2vec&lt;/span&gt;
&lt;span class="n"&gt;wv_model_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;word2vec&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Word2Vec&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;wv_model_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;init_sims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;wv_model_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;en_word2vec.model&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gensim.models&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;word2vec&lt;/span&gt;
&lt;span class="n"&gt;wv_model_ko&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;word2vec&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Word2Vec&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;texts_ko&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;wv_model_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;init_sims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;wv_model_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ko_word2vec.model&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Test&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;English&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;wv_model_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;president&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;wv_model_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;secretary&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;wv_model_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;country&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[('chairman', 0.8655247688293457),
 ('vice', 0.8160154819488525),
 ('executive', 0.8094440698623657),
 ('officer', 0.7894954085350037),
 ('Kjell', 0.7766541838645935),
 ('former', 0.7680522203445435),
 ('chief', 0.7660256028175354),
 ('Robert', 0.7623487114906311),
 ('director', 0.7434573173522949),
 ('Roger', 0.7231118679046631)]&lt;/p&gt;
&lt;p&gt;[('assistant', 0.8573123812675476),
 ('Carlos', 0.796258807182312),
 ('Daniel', 0.7900130748748779),
 ('undersecretary', 0.7888025045394897),
 ('representative', 0.7878221273422241),
 ('Deputy', 0.7847912311553955),
 ('NAWG', 0.7829214930534363),
 ('Republican', 0.7773356437683105),
 ('Greek', 0.7752739191055298),
 ('Papandreou', 0.7684933543205261)]&lt;/p&gt;
&lt;p&gt;[('kingdom', 0.8003361225128174),
 ('biggest', 0.765742301940918),
 ('island', 0.7639101147651672),
 ('founding', 0.7143765687942505),
 ('nation', 0.7080289125442505),
 ('fortunes', 0.7054018974304199),
 ('strength', 0.6875098943710327),
 ('challenging', 0.6863174438476562),
 ('actions', 0.6835225820541382),
 ('departure', 0.6834459900856018)]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Korean&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;wv_model_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;정부&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;wv_model_ko&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;초등학교&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;pre class="result"&gt;
[('경비/Noun', 0.9357226490974426),
 ('선박/Noun', 0.9204540252685547),
 ('연장/Noun', 0.9183653593063354),
 ('임무/Noun', 0.9179578423500061),
 ('우리/Noun', 0.9015840291976929),
 ('목적/Noun', 0.8871368169784546),
 ('기타/Noun', 0.875058650970459),
 ('화/Suffix', 0.8669425249099731),
 ('해역/Noun', 0.8575668334960938),
 ('한국/Noun', 0.8549510836601257)]&lt;/p&gt;
&lt;p&gt;[('취학/Noun', 0.9686248898506165),
 ('중인/Noun', 0.9336546659469604),
 ('하더/Verb', 0.8985729217529297),
 ('정의화/Noun', 0.8843945860862732),
 ('김정훈/Noun', 0.8682949542999268),
 ('지방/Noun', 0.8677719831466675),
 ('조정함/Verb', 0.8617256879806519),
 ('44/Number', 0.8445801734924316),
 ('세/Noun', 0.8318654298782349),
 ('第/Foreign', 0.8222816586494446)]
&lt;/pre&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;word2vec in the real world&lt;/h3&gt;
&lt;p&gt;Not enough? Let's see a real life example.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data source: Naver News &amp;amp; Naver blog&lt;br&gt;
    &lt;img src="images/experiment.png" width="500px"&gt;&lt;/li&gt;
&lt;li&gt;Questions&lt;br&gt;
    &lt;img src="images/questions.png" width="500px"&gt;&lt;/li&gt;
&lt;li&gt;Matching pairs: 그/Noun:남자/Noun = 그녀/Noun:?&lt;br&gt;
    &lt;img src="images/pairs.png" width="500px"&gt;&lt;/li&gt;
&lt;li&gt;Visualization&lt;br&gt;
    &lt;img src="images/tsne1.png" width="600px"&gt;&lt;br&gt;
    &lt;img src="images/tsne2.png" width="600px"&gt;&lt;br&gt;
    &lt;img src="images/tsne3.png" width="600px"&gt;&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!--

## Text classification
### Sentiment analysis
- https://github.com/nltk/nltk/wiki/Sentiment-Analysis

## Machine translation
- http://www.statmt.org/

## Deep learning
- https://github.com/nltk/nltk/wiki/Installing-Third-Party-Software#senna-for-various-nlp-tasks
    - http://ml.nec-labs.com/senna/
--&gt;</summary><category term="text"></category><category term="lectures"></category></entry><entry><title>Scraping from the Web</title><link href="//www.lucypark.kr/courses/2015-ba/crawling.html" rel="alternate"></link><published>2015-03-20T15:00:00+09:00</published><updated>2015-03-20T15:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:www.lucypark.kr,2015-03-20:courses/2015-ba/crawling.html</id><summary type="html">&lt;p&gt;Choose a target of your choice:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Target 1: &lt;a href="http://land.naver.com/article/articleList.nhn?rletTypeCd=A01&amp;amp;tradeTypeCd=&amp;amp;hscpTypeCd=&amp;amp;cortarNo=1162010200&amp;amp;mapLevel=10"&gt;Naver 부동산&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Target 2: &lt;a href="http://www.imdb.com/search/title?count=100&amp;amp;start=101"&gt;IMDB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Target 3: &lt;a href="http://www.ted.com/talks"&gt;TED.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Method 1: ctrl + c / ctrl + v&lt;/h2&gt;
&lt;p&gt;&lt;img src="images/excel.png"&gt;&lt;/p&gt;
&lt;h2&gt;Method 2: Google spreadsheet&lt;/h2&gt;
&lt;p&gt;&lt;img src="images/google-spreadsheet.png"&gt;&lt;/p&gt;
&lt;h2&gt;Method 3: import.io (or some other scraping service)&lt;/h2&gt;
&lt;p&gt;&lt;img src="images/importio.png"&gt;&lt;/p&gt;
&lt;h2&gt;Method 4: Being the programmer&lt;/h2&gt;
&lt;p&gt;Let's try programming a crawler ourselves.&lt;/p&gt;
&lt;h3&gt;1. Identify Web page URL&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;First find a Web page where you can find item lists&lt;/li&gt;
&lt;li&gt;Let's understand the URL (cf. &lt;a href="http://meyerweb.com/eric/tools/dencoder/"&gt;Online URL decoder/encoder&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;It is best to find a page where the URL is has an iterable parameter (ex: page numbers, item IDs)&lt;ul&gt;
&lt;li&gt;TED.com talks: http://www.ted.com/talks?page=1&lt;ul&gt;
&lt;li&gt;&lt;code&gt;page&lt;/code&gt; is iterable from 1 to 54&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Amazon.com TVs: &lt;code&gt;http://www.amazon.com/s/?rh=n:172282,n:!493964,n:1266092011,n:172659&amp;amp;page=1&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;page&lt;/code&gt; is iterable from 1 to 143&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Set the variables &lt;code&gt;npages&lt;/code&gt;, &lt;code&gt;url_base&lt;/code&gt;, and also a &lt;code&gt;file_base&lt;/code&gt; to name download files. Normally, you want to set npages to a smaller number (ex: 3), rather than the actuall value (i.e., 54) to test the code before actually executing it.&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;npages&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;54&lt;/span&gt;
&lt;span class="n"&gt;url_base&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;http://www.ted.com/talks?page=&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;file_base&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;ted_talks_&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;.html&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2. Download Web pages&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;First define a function named &lt;code&gt;save_text&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;save_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then using the list URL found on step 1, download list pages. We will use the package &lt;code&gt;requests&lt;/code&gt; for this task&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;page_num&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;npages&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;page_num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url_base&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;page_num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;save_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;file_base&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;page_num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check whether the pages have downloaded succesfully&lt;br&gt;
    &lt;img src="images/download_ted.png"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;3. Parse downloaded Web pages&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Before we go any further, let's recall how an html document looks like. Take a look at one of the downloaded html docs as well.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;html&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;head&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;meta&lt;/span&gt; &lt;span class="na"&gt;charset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;link&lt;/span&gt; &lt;span class="na"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;stylesheet&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;...&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt; &lt;span class="na"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;text/javascript&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;src&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;...&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;head&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="c"&gt;&amp;lt;!-- This is a comment --&amp;gt;&lt;/span&gt;
    ... and this is where the visible contents go ...
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;html&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now, let's set the &lt;code&gt;page_num&lt;/code&gt; to 1 for detailed investigation, rather than creating a &lt;code&gt;for&lt;/code&gt; loop for all pages&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;page_num&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For parsing, we'll be using &lt;a href="http://lxml.de/lxmlhtml.html"&gt;&lt;code&gt;lxml.html&lt;/code&gt;&lt;/a&gt;. Many people also use &lt;a href="https://docs.python.org/3/library/re.html"&gt;regex&lt;/a&gt;. There are various many other options (ex: bs4), so feel free to Google them up.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;lxml&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;html&lt;/span&gt;
&lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_base&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;page_num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With &lt;code&gt;root&lt;/code&gt;, we can easily parse a given text using &lt;a href="http://lxml.de/xpathxslt.html#xpath"&gt;xpath&lt;/a&gt;s, just by identifying the &lt;em&gt;tag&lt;/em&gt;, &lt;em&gt;class&lt;/em&gt;, or &lt;em&gt;id&lt;/em&gt; of an html element. Why don't we try extracting all the text from the &lt;code&gt;&amp;lt;body&amp;gt;&lt;/code&gt; tag? Try this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;//body//text()&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cool, huh? Now, let's think of what we want to extract from our downloaded html, and picture what we want as a result. From our html page, we probably want to extract the title, speaker, view count, date, and url of all TED talks, resulting in a spreadsheet format as follows:
    &lt;div class="row"&gt;
    &lt;div class="col-md-3"&gt;
    &lt;img src="images/ted.png"&gt;
    &lt;/div&gt;
    &lt;div class="col-md-9"&gt;
    &lt;table class="table"&gt;&lt;tr&gt;&lt;th&gt;    title&lt;/th&gt;&lt;th&gt;speaker&lt;/th&gt;&lt;th&gt;views&lt;/th&gt;&lt;th&gt;date&lt;/th&gt;&lt;th&gt;url&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;    The price of shame&lt;/td&gt;&lt;td&gt;Monica Lewinsky&lt;/td&gt;&lt;td&gt;83K&lt;/td&gt;&lt;td&gt;Mar 2015&lt;/td&gt;&lt;td&gt;http://...&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;    What if 3D printing was 100x faster?&lt;/td&gt;&lt;td&gt;Joseph DeSimone&lt;/td&gt;&lt;td&gt;212K&lt;/td&gt;&lt;td&gt;Mar 2015&lt;/td&gt;&lt;td&gt;http://...&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;    Can we create new senses for humans?&lt;/td&gt;&lt;td&gt;David Eagleman&lt;/td&gt;&lt;td&gt;215K&lt;/td&gt;&lt;td&gt;Mar 2015&lt;/td&gt;&lt;td&gt;http://...&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;    The good news about PMS&lt;/td&gt;&lt;td&gt;Robyn Stein DeLuca&lt;/td&gt;&lt;td&gt;248K&lt;/td&gt;&lt;td&gt;Mar 2015&lt;/td&gt;&lt;td&gt;http://...&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;    ...&lt;/td&gt;&lt;td&gt;...&lt;/td&gt;&lt;td&gt;...&lt;/td&gt;&lt;td&gt;...&lt;/td&gt;&lt;td&gt;... &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
    &lt;/div&gt;
    &lt;/div&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;So, in order to find what &lt;em&gt;tag&lt;/em&gt;, &lt;em&gt;class&lt;/em&gt;, or &lt;em&gt;id&lt;/em&gt; we need to exact such elements, let's go back to &lt;a href="http://www.ted.com/talks?page=1"&gt;www.ted.com/talks?page=1&lt;/a&gt;, right click, and "Inspect Element"s.&lt;br&gt;
    &lt;img src="images/parse-1.png" width="400px"&gt;
    &lt;img src="images/parse-2.png" width="400px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;By navigating with the DOM, we can see that the &lt;code&gt;div&lt;/code&gt; tag with &lt;code&gt;id=browse-results&lt;/code&gt; contains all the talk items in &lt;code&gt;div&lt;/code&gt; tags with &lt;code&gt;class=col&lt;/code&gt;, each containing a talk item. (When identifying and html element, using &lt;em&gt;id&lt;/em&gt; is better than using a &lt;em&gt;class&lt;/em&gt;, because normally &lt;em&gt;id&lt;/em&gt;s are unique within a html page.)&lt;br&gt;
    &lt;img src="images/parse-3.png" width="400px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now, let's use xpath to get the talk items.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;//div[@id=&amp;quot;browse-results&amp;quot;]//div[@class=&amp;quot;col&amp;quot;]&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;   &lt;span class="c1"&gt;# returns 36, the number of talk items in the page&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dig into one of the &lt;code&gt;&amp;lt;div class="col"&amp;gt;&lt;/code&gt;s, to further investigate the identifiers of talk information.&lt;br&gt;
    &lt;img src="images/parse-4.png" width="400px"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Choose one item and extract relevant data.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.//h4[@class=&amp;quot;h12 talk-link__speaker&amp;quot;]/text()&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.//h4[@class=&amp;quot;h9 m5&amp;quot;]/a/text()&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.//h4[@class=&amp;quot;h9 m5&amp;quot;]/a/@href&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.//span[@class=&amp;quot;meta__val&amp;quot;]/text()&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;All the items are contained in a list, and it would be better if we could strip the new lines(&lt;code&gt;\n&lt;/code&gt;) from the strings. Additionally, rather than handling each info separately, let's put the extracted info into one dictionary, and make that a function named &lt;code&gt;parse_item()&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse_item&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;speaker&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.//h4[@class=&amp;quot;h12 talk-link__speaker&amp;quot;]/text()&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;title&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.//h4[@class=&amp;quot;h9 m5&amp;quot;]/a/text()&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;href&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.//h4[@class=&amp;quot;h9 m5&amp;quot;]/a/@href&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;views&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.//span[@class=&amp;quot;meta__val&amp;quot;]/text()&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.//span[@class=&amp;quot;meta__val&amp;quot;]/text()&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Perfect. Now let's iterate through the items on page 1.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parse_item&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;    &lt;span class="c1"&gt;# returns 36&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Great. Now we're ready to iterate through all 54 web pages.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;page_num&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;npages&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

&lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_base&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;page_num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;items&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;//div[@id=&amp;quot;browse-results&amp;quot;]//div[@class=&amp;quot;col&amp;quot;]&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parse_item&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;    &lt;span class="c1"&gt;# returns 1943 or a similar number&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;4. Save the parsed data to file&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;We currently have our data in a dictionary format.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Normally, it's enough to save this data directly into a json file.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data.json&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dump&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;&lt;a href="https://chrome.google.com/webstore/detail/jsonview/chklaanhfefbnpoihckbnefhakgolnmc?hl=en"&gt;JSONView&lt;/a&gt; is a nice way to pretty print your json.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;However, sometimes it's better to convert this data into a spreadsheet. If so, try this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;csv&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;data.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;writer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;csv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DictWriter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fieldnames&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;writer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;writeheader&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;writer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;writerows&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;5. What's next?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;You can see a refactored, cleaner code of the crawler above &lt;a href="https://gist.github.com/e9t/43f986a915c4059d75af"&gt;here&lt;/a&gt;. Try to understand the syntax yourself.&lt;/li&gt;
&lt;li&gt;Furthermore, you can traverse into the individual talk urls you have just acquired from the list pages.&lt;/li&gt;
&lt;li&gt;Concurrent crawling may come of use. Consult &lt;a href="http://www.slideshare.net/cornchz/pyconkr-2014-30"&gt;this presentation material&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Try crawling some other website of interest.&lt;/li&gt;
&lt;li&gt;If you already have enough data to crunch, go ahead and crunch 'em!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;Below are some Web crawler examples. Most are for Python 2, so be careful.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/e9t/95df9b68ff829a557cfb"&gt;TED.com crawler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/e9t/9680106"&gt;Naver OnStage crawler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://github.com/teampopong/crawlers"&gt;Team POPONG crawlers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/e9t/551f9647f58800273025"&gt;Korean National Assembly bill crawler&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="lectures"></category><category term="crawling"></category></entry><entry><title>Course Introduction</title><link href="//www.lucypark.kr/courses/2015-ba/course-logistics.html" rel="alternate"></link><published>2015-03-06T15:00:00+09:00</published><updated>2015-03-06T15:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:www.lucypark.kr,2015-03-06:courses/2015-ba/course-logistics.html</id><summary type="html">&lt;h2&gt;About the instructor&lt;/h2&gt;
&lt;p&gt;&lt;img src="//www.lucypark.kr/courses/images/me.jpg" width="150px" class="pull-right"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Eunjeong (Lucy) Park&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dm.snu.ac.kr/~epark"&gt;PhDc for data mining&lt;/a&gt; at Seoul National University&lt;/li&gt;
&lt;li&gt;You can call me &lt;a href="http://www.phdcomics.com/comics/archive.php?comicid=1153"&gt;"Ms. Park"&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Normally to professors, using "Dr." is a better idea&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;a.k.a., &lt;a href="http://lucypark.kr"&gt;lucypark&lt;/a&gt;, &lt;a href="http://twitter.com/echojuliett"&gt;echojuliett&lt;/a&gt;, &lt;a href="http://github.com/e9t"&gt;e9t&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Course logistics&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Course objective: &lt;strong&gt;Pragmatic data mining on real data&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Work for the course&lt;ul&gt;
&lt;li&gt;Class meets every Friday 15:00-18:00&lt;/li&gt;
&lt;li&gt;Most classes will be consisted of two parts&lt;ol&gt;
&lt;li&gt;Lectures and/or tutorials&lt;/li&gt;
&lt;li&gt;Short presentations by students&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Course website: &lt;a href="http://lucypark.kr/courses/2015-ba"&gt;http://lucypark.kr/courses/2015-ba&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Lecture notes&lt;/li&gt;
&lt;li&gt;Schedule/Announcements&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Schedule: &lt;a href="http://lucypark.kr/courses/2015-ba/#schedule"&gt;http://lucypark.kr/courses/2015-ba/#schedule&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Office hours&lt;ul&gt;
&lt;li&gt;Right before every class&lt;/li&gt;
&lt;li&gt;You are welcome to ask any kind of questions&lt;/li&gt;
&lt;li&gt;You are also encouraged to &lt;a href="mailto:2015-ba@dm.snu.ac.kr"&gt;book ahead&lt;/a&gt;, or your meeting may have to be deferred to another time&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Grading&lt;ul&gt;
&lt;li&gt;Assignments (20%): Two graded assignments related to your project, and two reading assignments during the semester&lt;/li&gt;
&lt;li&gt;Mid-term exam (20%): In-class exam covering the first half of the semester&lt;/li&gt;
&lt;li&gt;Finals (60%): Finals consist of an in-class exam and a project presentation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Term Project&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;You will be conducting a term project throughout the semester&lt;/li&gt;
&lt;li&gt;Term projects will be done as individual work&lt;/li&gt;
&lt;li&gt;There will be two designated assigments according to the project, and one graded presentation at the end of the semester&lt;/li&gt;
&lt;li&gt;Extra credit will be given to those who submit and/or rank in public tournaments (ex: &lt;a href="http://kaggle.com"&gt;Kaggle&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Reading assignments&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Charles Wheelan, &lt;a href="http://www.amazon.com/gp/product/039334777X"&gt;Naked Statistics: Stripping the Dread from the Data&lt;/a&gt; (There's also a &lt;a href="http://www.yes24.com/24/goods/11257680"&gt;Korean version&lt;/a&gt;, so pick a version that suits you)&lt;/li&gt;
&lt;li&gt;You will be picking two chapters&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Advice on your projects&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;The best topics are the &lt;em&gt;topics you are actually interested in&lt;/em&gt;&lt;ul&gt;
&lt;li&gt;You should be able to "&lt;a href="http://en.wikipedia.org/wiki/Eating_your_own_dog_food"&gt;dogfood&lt;/a&gt;" your own analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Don't be afraid to shift the project's direction&lt;ul&gt;
&lt;li&gt;However, shifting too much will give you less time for real work -- balance!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Feel free to use project results in your graduation project or paper&lt;ul&gt;
&lt;li&gt;Grab two rabbits at once!&lt;/li&gt;
&lt;li&gt;These projects have potential to become something in your portfolio&lt;/li&gt;
&lt;li&gt;May be a plus when you get a job, or apply for grad school&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Presenting project progress&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Update your progress (Max. 10 minutes)&lt;ol&gt;
&lt;li&gt;Prepare printouts (for the whole class) or slides or whatever format that best conveys your work&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Please share your materials at the forum before class&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Be brief yet clear&lt;ul&gt;
&lt;li&gt;Note: &lt;a href="http://echojuliett.tumblr.com/post/32108001510/clarity-brevity"&gt;Clarity wins brevity&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Take notes&lt;ul&gt;
&lt;li&gt;Keep precise research progress and feedback notes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;A good presentation contains the following:&lt;ol&gt;
&lt;li&gt;What questions you had&lt;/li&gt;
&lt;li&gt;What approach you chose to alleviate such questions&lt;/li&gt;
&lt;li&gt;What results you achieved&lt;/li&gt;
&lt;li&gt;What questions you further got and what you plan to do next&lt;/li&gt;
&lt;li&gt;(Optional) Tricks and tips you want to share with the class&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Asking questions&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Never hesitate in asking questions&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Private questions: &lt;a href="mailto:2015-ba@dm.snu.ac.kr"&gt;2015-ba@dm.snu.ac.kr&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Personal questions and/or requests&lt;/li&gt;
&lt;li&gt;Assignment submissions that regard privacy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Public questions: &lt;a href="mailto:2015-ba@googlegroups.com"&gt;2015-ba@googlegroups.com&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;This is the class forum&lt;/li&gt;
&lt;li&gt;Everything else you want to ask goes here&lt;/li&gt;
&lt;li&gt;Using any language of your choice (ex: English, Korean, Java, ...)&lt;/li&gt;
&lt;li&gt;Asking good questions at the class forum&lt;ul&gt;
&lt;li&gt;Provide as much details as you can&lt;/li&gt;
&lt;li&gt;However, be "brief" and "clear"&lt;/li&gt;
&lt;li&gt;In case of programming questions, explicitly list versions of software being used (including packages and OSs)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Academic integrity&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/Academic_integrity"&gt;Academic integrity is the moral code or ethical policy of academia&lt;/a&gt;.
There may be times you are tempted to be dishonest, cheat, or plagarize other work,
but in this course (and undoubtfully in all other classes),
we encourage you to approach your work with honesty and integrity.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is disallowed&lt;ul&gt;
&lt;li&gt;Don't ask another student to do the work for you&lt;/li&gt;
&lt;li&gt;Don't fabricate experimental results&lt;/li&gt;
&lt;li&gt;Don't cheat on exams, and don't let anothers copy your answers&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;What is allowed&lt;ul&gt;
&lt;li&gt;Do trust your ability&lt;/li&gt;
&lt;li&gt;Do give credit to others' work (Mind your citations!)&lt;/li&gt;
&lt;li&gt;Do brag about your acheivements&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!--
### Plagarism

- It is *critically important* that you give proper credit to people/sources when you use their words or ideas.

&gt; Some sources on plagarism
&gt; - [Student Handbook on Referencing](http://www.jhsph.edu/academics/degree-programs/master-of-public-health/current-students/JHSPH-ReferencingHandbook.pdf), Johns Hopkins U, 2010.

### Honor code for BA 2015

*My answers to homework, quizzes and exams will be my own work (except for assignments that explicitly permit collaboration). I will not make solutions to homework, quizzes or exams available to anyone else. This includes both solutions written by me, as well as any official solutions provided by the course staff. I will not engage in any other activities that will dishonestly improve my results or dishonestly improve/hurt the results of others.*

## Tips

1. Writing a good CV
    - http://tex.stackexchange.com/questions/80/latex-template-for-resume-curriculum-vitae
1. Writing a good self-introduction
    - Use positive words.
    - Divide an conquer!
        - Step 1. Focus only on the contents! (Using a basic text editor or plain paper might be a good idea)
        - Step 2. Do the formatting. Formatting matters. (ex: fonts, layouts, tenses, etc.)
1. Performing data analysis
    - https://twitter.com/echojuliett/status/491256372726480896
    m Traditional battles in CS and DM https://twitter.com/echojuliett/status/491564823096737794
1. How to find good resources (cf. What is "good"?)
    - If it's a book, author &amp; publisher
    - If it's an academic paper, author &amp; publisher &amp; year of publish
    - If it's a Web document, author &amp; date of publish, popularity among your friends
1. Using great tools: The key to research is search, using great tools.
    - Stackoverflow
    - Google Scholar
    - Markdown, pandoc
    - Coursera, Quora, Kaggle
    - Facebook Groups
--&gt;</summary><category term="lectures"></category><category term="intro"></category></entry><entry><title>Business Analytics (Spring 2015)</title><link href="//www.lucypark.kr/courses/2015-ba/index.html" rel="alternate"></link><published>2015-03-02T00:00:00+09:00</published><updated>2015-03-02T00:00:00+09:00</updated><author><name>Lucy Park</name></author><id>tag:www.lucypark.kr,2015-03-02:courses/2015-ba/index.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;Welcome to Business Analytics class of 2015!
Here you'll find all course materials, guides and schedules.
In case you have questions, feel free to send an email to &lt;a href="mailto:2015-ba@googlegroups.com"&gt;2015-ba@googlegroups.com&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Data mining and analytical skills are at the heart of solving many important problems in our world.
In this course, we aim to derive technology-based solutions to such problems, and develop strategical decision making abilities based on data.&lt;/p&gt;
&lt;p&gt;Specifically, we discuss technologies, applications, practices, and skills for continuous iterative exploration and investigation of business performance with external data collected from diverse sources such as the Web, in order to gain insights and drive business planning.
Topics include statistical and quantitative analysis, explanatory and predictive modeling, as well as text analytics with visualization.
Students are required to present progress on their work during the semester, and are assessed by a set of assignments, quizzes and exams.&lt;/p&gt;
&lt;p&gt;Note that this course is the second part of a two part sequence.
We assume you have already taken
Data Mining (ex: &lt;a href="//www.lucypark.kr/courses/2015-dm/index.html"&gt;IISE113503&lt;/a&gt;),
the first part of the sequence, where methods and algorithms for mining data were discussed.
This course is the latter part of the sequence, and will be more advanced and project-focused.&lt;/p&gt;
&lt;h3&gt;Prerequisites&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Familiarity in data mining algorithms&lt;/li&gt;
&lt;li&gt;Good knowledge with at least one programming language (ex: R, Python, Java, etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;What you will learn&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Use algorithms to extract meaningful insight from large datasets&lt;/li&gt;
&lt;li&gt;Understand the usage of data mining in a domain of interest&lt;/li&gt;
&lt;li&gt;Develop analytical and data-based thinking&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Grading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Assignments (20%): You will be given four graded assignments during the semester.&lt;/li&gt;
&lt;li&gt;Mid-term Quiz (20%): A mid-term quiz.&lt;/li&gt;
&lt;li&gt;Final Exam (60%): A final exam and presentation.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Schedule&lt;/h2&gt;
&lt;p&gt;&lt;table id="schedule" class="table table-hover table-bordered"&gt;
&lt;tr&gt;&lt;th&gt;date&lt;/th&gt;&lt;th&gt;lecture&lt;/th&gt;&lt;th&gt;assignment&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/06&lt;/td&gt;&lt;td&gt;Course introduction&lt;ul&gt;&lt;li&gt;&lt;a href="course-logistics.html"&gt;Course logistics&lt;/a&gt;&lt;li&gt;GitHub&lt;li&gt;Having fun with Kaggle&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;&lt;a href='http://goo.gl/forms/fE7ZIeL8VK'&gt;Homework 0&lt;/a&gt; (Due: 3/11)&lt;ul&gt;&lt;li&gt;CV + Self-intro&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/13&lt;/td&gt;&lt;td&gt;Tools for pragmatic data mining&lt;ul&gt;&lt;li&gt;&lt;a href="bash.html"&gt;Bash&lt;/a&gt;&lt;li&gt;&lt;a href="../tips/introduction-to-python.html"&gt;Python&lt;/a&gt;&lt;li&gt;Statistical Summaries and Exploratory Data Analysis&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/20&lt;/td&gt;&lt;td&gt;&lt;a href="crawling.html"&gt;Scraping from the Web&lt;/a&gt;&lt;ul&gt;&lt;li&gt;Proposal presentations&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;Project proposals (300 words+)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3/27&lt;/td&gt;&lt;td&gt;&lt;a href="text-mining.html"&gt;Text mining 1: Text exploration&lt;/a&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/03&lt;/td&gt;&lt;td&gt;&lt;a href="text-mining.html#topic-modeling"&gt;Text mining 2: Topic modeling&lt;/a&gt;&lt;ul&gt;&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/10&lt;/td&gt;&lt;td&gt;Regression and Predictive modeling&lt;ul&gt;&lt;li&gt;Recommender systems&lt;li&gt;Share project progress&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/17&lt;/td&gt;&lt;td&gt;Mid-term Quiz&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4/24&lt;/td&gt;&lt;td&gt;Clustering and Dimensionality Reduction&lt;ul&gt;&lt;li&gt;Singular value decomposition (SVD)&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/01&lt;/td&gt;&lt;td&gt;&lt;a href="visualization1.html"&gt;Visualization and storytelling 1&lt;/a&gt;&lt;ul&gt;&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/08&lt;/td&gt;&lt;td&gt;&lt;a href="visualization2.html"&gt;Visualization and storytelling 2&lt;/a&gt;&lt;ul&gt;&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;Progress report (1K+ words)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/15&lt;/td&gt;&lt;td&gt;Going deep: Deep learning&lt;ul&gt;&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/22&lt;/td&gt;&lt;td&gt;Going big 1: Map/reduce&lt;ul&gt;&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5/29&lt;/td&gt;&lt;td&gt;Going big 2: Spark&lt;ul&gt;&lt;li&gt;Share reading assignment&lt;/ul&gt;&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;6/05&lt;/td&gt;&lt;td&gt;Final presentation&lt;/td&gt;&lt;td&gt;Project final report (3K+ words)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;6/12&lt;/td&gt;&lt;td&gt;Final exam&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/p&gt;
&lt;!--
Memos for next time:
- DM을 배우고 왔어도, 개념을 remind 해주는 class가 초반에 두 번 정도 있으면 좋을듯. 즉, 4/10, 4/24 2회를 강의 초반에 배치
--&gt;</summary><category term="data"></category><category term="seoultech"></category><category term="lecturer"></category><category term="syllabus"></category></entry></feed>