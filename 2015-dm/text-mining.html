<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<title>파이썬으로 영어와 한국어 텍스트 다루기 — Courses</title>
	<meta name="description" content="Title: 파이썬으로 영어와 한국어 텍스트 다루기; Date: 2015-04-10; Author: Lucy Park; Courseid: 2015-dm; Metainfo: ">
	<meta name="author" content="Lucy Park">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
	<!--[if lt IE 9]>
		<script src="//www.lucypark.kr/courses/theme/html5.js"></script>
		<![endif]-->
	<link href="//www.lucypark.kr/courses/theme/css/ipython.css" rel="stylesheet">
	<link href="//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css" rel="stylesheet">
	<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
	<link href="//maxcdn.bootstrapcdn.com/bootswatch/3.2.0/simplex/bootstrap.min.css" rel="stylesheet">
	<link href="//www.lucypark.kr/courses/theme/css/local.css" rel="stylesheet">
	<link href="//www.lucypark.kr/courses/theme/css/pygments.css" rel="stylesheet">
</head>
<body>
<div class="container">
	<div class="page-header">
		<h1 class="margin-bottom-30"><a href="//www.lucypark.kr/courses/">Courses</a></h1>
        <ul class="nav nav-tabs">
            <li role="presentation"><a href="//www.lucypark.kr/courses/2015-dm">2015-dm</a></li>
            <li role="presentation"><a href="//www.lucypark.kr/courses/2015-ba">2015-ba</a></li>
        </ul>
	</div>
	<div class="row">
		<div class="col-md-10 col-md-offset-1">
<div class="article" itemscope itemtype="http://schema.org/BlogPosting">
	<div class="article-header">
        <h1 itemprop="name headline">파이썬으로 영어와 한국어 텍스트 다루기</h1>
		<time datetime="2015-04-10T09:00:00+09:00" itemprop="datePublished">Fri 10 April 2015</time>
	</div>
    <div class="article-toc"><b>Contents</b><p></p></div>
    <div itemprop="articleBody" class="article-body">
        <blockquote>
<p>We use Python 3 in this tutorial, but provide minimal guidelines for Python 2.</p>
</blockquote>
<h2>지난 시간 복습</h2>
<h3>Terminologies</h3>
<p><table class="table"><tr><th>English</th><th>한국어</th><th>Description</th></tr><tr><td>Document</td><td>문서</td><td>-</td></tr><tr><td>Corpus</td><td>말뭉치</td><td>A set of documents</td></tr><tr><td>Token</td><td>토큰</td><td>Meaningful elements in a text such as words or phrases or symbols</td></tr><tr><td>Morphemes</td><td>형태소</td><td>Smallest meaningful unit in a language</td></tr><tr><td>POS</td><td>품사</td><td>Part-of-speech (ex: Nouns)</td></tr></table></p>
<h3>Text analysis process</h3>
<p><img src="images/text-process.png" width="200px"></p>
<p>전처리는 아래의 세부 과정으로 다시 한 번 나뉜다.</p>
<ol>
<li>Load text</li>
<li>Tokenize text (ex: stemming, morph analyzing)</li>
<li>Tag tokens (ex: POS, NER)</li>
<li>Token(Feature) selection and/or filter/rank tokens (ex: stopword removal, TF-IDF)</li>
<li>...and so on (ex: calculate word/document similarities, cluster documents)</li>
</ol>
<h2>Useful Python Packages for Text Mining and NLP</h2>
<ol>
<li>
<p><a href="http://nltk.org">NLTK</a>: Provides modules for text analysis (mostly language independent)</p>
<ul>
<li>
<p>설치하기</p>
<div class="highlight"><pre><span></span>pip install nltk
</pre></div>


</li>
<li>
<p>주요기능</p>
<ol>
<li>
<p><a href="http://www.nltk.org/book/ch02.html">Text corpora</a>: 특히, 이 튜토리얼에서는 아래의 두 가지 데이터가 필요하니 미리 다운 받아두자.</p>
<div class="highlight"><pre><span></span><span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;gutenberg&#39;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;maxent_treebank_pos_tagger&#39;</span><span class="p">)</span>
</pre></div>


</li>
<li>
<p><a href="http://www.nltk.org/api/nltk.tag.html">Word POS, NER classification</a></p>
</li>
<li><a href="http://www.nltk.org/book/ch06.html">Document classification</a></li>
</ol>
</li>
</ul>
</li>
<li>
<p><a href="http://konlpy.org">KoNLPy</a>: Provides modules for Korean text analysis</p>
<ul>
<li>
<p>설치하기</p>
<div class="highlight"><pre><span></span>pip install konlpy
</pre></div>


</li>
<li>
<p>주요기능</p>
<ol>
<li><a href="http://konlpy.org/en/latest/data/#corpora">Text corpora</a></li>
<li><a href="http://konlpy.org/en/latest/api/konlpy.tag/">Word POS classification</a><ul>
<li>Hannanum</li>
<li>Kkma</li>
<li>Mecab</li>
<li>Komoran</li>
<li>Twitter</li>
</ul>
</li>
</ol>
</li>
</ul>
</li>
<li>
<p><a href="http//radimrehurek.com/gensim/">Gensim</a>: Provides modules for topic modeling and calculating similarities among documents</p>
<ul>
<li>
<p>설치하기</p>
<div class="highlight"><pre><span></span>pip install -U gensim
</pre></div>


</li>
<li>
<p>주요기능</p>
<ol>
<li>Topic modeling<ul>
<li><a href="http://radimrehurek.com/gensim/models/ldamodel.html">Latent Dirichlet allocation (LDA)</a></li>
<li><a href="http://radimrehurek.com/gensim/models/lsimodel.html">Latent semantic indexing (LSI)</a></li>
<li><a href="http://radimrehurek.com/gensim/models/hdpmodel.html">Hierarchical Dirichlet process (HDP)</a></li>
</ul>
</li>
<li>Word embedding<ul>
<li><a href="radimrehurek.com/gensim/models/word2vec.html">word2vec</a></li>
</ul>
</li>
</ol>
</li>
</ul>
</li>
<li>
<p><a href="https://github.com/ryanmcgrath/twython">Twython</a>: Provides easy access to Twitter API</p>
<ul>
<li>
<p>설치하기</p>
<div class="highlight"><pre><span></span>pip install twython
</pre></div>


</li>
<li>
<p>사용예시: "Samsung (삼성)" 관련 트윗 받기</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">twython</span> <span class="kn">import</span> <span class="n">Twython</span>
<span class="kn">import</span> <span class="nn">settings</span> <span class="kn">as</span> <span class="nn">s</span>    <span class="c1"># Create a file named settings.py, and put oauth KEY values inside</span>
<span class="n">twitter</span> <span class="o">=</span> <span class="n">Twython</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">APP_KEY</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">APP_SECRET</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">OAUTH_TOKEN</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">OAUTH_TOKEN_SECRET</span><span class="p">)</span>
<span class="n">tweets</span> <span class="o">=</span> <span class="n">twitter</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="s1">&#39;삼성&#39;</span><span class="p">,</span> <span class="n">count</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="n">t</span><span class="p">[</span><span class="s1">&#39;user&#39;</span><span class="p">][</span><span class="s1">&#39;screen_name&#39;</span><span class="p">],</span> <span class="n">t</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span> <span class="n">t</span><span class="p">[</span><span class="s1">&#39;created_at&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tweets</span><span class="p">[</span><span class="s1">&#39;statuses&#39;</span><span class="p">]]</span>
</pre></div>


</li>
</ul>
</li>
</ol>
<h2>Text exploration</h2>
<h3>1. Read document</h3>
<p>이 튜토리얼에서는 NLTK, KoNLPy에서 제공하는 문서들을 사용한다.</p>
<ul>
<li>영어: <a href="http://www.gutenberg.org/ebooks/158">Jane Austen의 소설 Emma</a></li>
<li>한국어: <a href="http://pokr.kr/bill/1809890">대한민국 국회 제 1809890호 의안</a></li>
</ul>
<p>할 수 있는 사람은, 위의 문서 대신 다른 텍스트 데이터를 로딩하여 사용해보자.</p>
<ul>
<li>
<p>English</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">gutenberg</span>   <span class="c1"># Docs from project gutenberg.org</span>
<span class="n">files_en</span> <span class="o">=</span> <span class="n">gutenberg</span><span class="o">.</span><span class="n">fileids</span><span class="p">()</span>      <span class="c1"># Get file ids</span>
<span class="n">doc_en</span> <span class="o">=</span> <span class="n">gutenberg</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;austen-emma.txt&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</pre></div>


</li>
<li>
<p>Korean</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konlpy.corpus</span> <span class="kn">import</span> <span class="n">kobill</span>    <span class="c1"># Docs from pokr.kr/bill</span>
<span class="n">files_ko</span> <span class="o">=</span> <span class="n">kobill</span><span class="o">.</span><span class="n">fileids</span><span class="p">()</span>         <span class="c1"># Get file ids</span>
<span class="n">doc_ko</span> <span class="o">=</span> <span class="n">kobill</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;1809890.txt&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</pre></div>


</li>
</ul>
<h3>2. Tokenize</h3>
<p>문서를 토큰으로 나누는 방법은 다양하다.
여기서는 영어에는 <code>nltk.regexp_tokenize</code>, 한국어에는 <code>konlpy.tag.Twitter.morph</code>를 사용해보자.</p>
<ul>
<li>
<p>English</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nltk</span> <span class="kn">import</span> <span class="n">regexp_tokenize</span>
<span class="n">pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;&#39;&#39;(?x) ([A-Z]\.)+ | \w+(-\w+)* | \$?\d+(\.\d+)?%? | \.\.\. | [][.,;&quot;&#39;?():-_`]&#39;&#39;&#39;</span>
<span class="n">tokens_en</span> <span class="o">=</span> <span class="n">regexp_tokenize</span><span class="p">(</span><span class="n">doc_en</span><span class="p">,</span> <span class="n">pattern</span><span class="p">)</span>
</pre></div>


</li>
<li>
<p>Korean</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konlpy.tag</span> <span class="kn">import</span> <span class="n">Twitter</span><span class="p">;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">Twitter</span><span class="p">()</span>
<span class="n">tokens_ko</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">morphs</span><span class="p">(</span><span class="n">doc_ko</span><span class="p">)</span>
</pre></div>


</li>
</ul>
<h3>3. Load tokens with <code>nltk.Text()</code></h3>
<p><code>nltk.Text()</code>는 문서 하나를 편리하게 탐색할 수 있는 다양한 기능을 제공한다.</p>
<ul>
<li>
<p>English</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="n">en</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">Text</span><span class="p">(</span><span class="n">tokens_en</span><span class="p">)</span>
</pre></div>


</li>
<li>
<p>Korean (For Python 2, <code>name</code> has to be input as u'유니코드'. If you are using Python 2, use u'유니코드' for input of all following Korean text.)</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="n">ko</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">Text</span><span class="p">(</span><span class="n">tokens_ko</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;대한민국 국회 의안 제 1809890호&#39;</span><span class="p">)</span>   <span class="c1"># For Python 2, input `name` as u&#39;유니코드&#39;</span>
</pre></div>


</li>
</ul>
<p>지금부터 <code>nltk.Text()</code>가 제공하는 다양한 기능을 하나씩 살펴보자.
(참고링크: <a href="http://www.nltk.org/api/nltk.html#nltk.text.Text">class nltk.text.Text API 문서</a>)</p>
<ol>
<li>
<p>Tokens</p>
<ul>
<li>
<p>English</p>
<div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">en</span><span class="o">.</span><span class="n">tokens</span><span class="p">))</span>       <span class="c1"># returns number of tokens (document length)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">en</span><span class="o">.</span><span class="n">tokens</span><span class="p">)))</span>  <span class="c1"># returns number of unique tokens</span>
<span class="n">en</span><span class="o">.</span><span class="n">vocab</span><span class="p">()</span>                  <span class="c1"># returns frequency distribution</span>
</pre></div>


<p><pre class="result">
191061
7927
FreqDist({',': 12018, '.': 8853, 'to': 5127, 'the': 4844, 'and': 4653, 'of': 4278, '"': 4187, 'I': 3177, 'a': 3000, 'was': 2385, ...})
</pre></p>
</li>
<li>
<p>Korean</p>
<div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ko</span><span class="o">.</span><span class="n">tokens</span><span class="p">))</span>       <span class="c1"># returns number of tokens (document length)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">ko</span><span class="o">.</span><span class="n">tokens</span><span class="p">)))</span>  <span class="c1"># returns number of unique tokens</span>
<span class="n">ko</span><span class="o">.</span><span class="n">vocab</span><span class="p">()</span>                  <span class="c1"># returns frequency distribution</span>
</pre></div>


<p><pre class="result">
1707
476
FreqDist({'.': 61, '의': 46, '육아휴직': 38, '을': 34, '(': 27, ',': 26, '이': 26, ')': 26, '에': 24, '자': 24, ...})
</pre></p>
</li>
</ul>
</li>
<li>
<p>Plot frequency distributions</p>
<ul>
<li>
<p>English</p>
<div class="highlight"><pre><span></span><span class="n">en</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>     <span class="c1"># Plot sorted frequency of top 50 tokens</span>
</pre></div>


<p><img src="images/fdist_en.png" width="500px"></p>
</li>
<li>
<p>Korean</p>
<div class="highlight"><pre><span></span><span class="n">ko</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>     <span class="c1"># Plot sorted frequency of top 50 tokens</span>
</pre></div>


<p><img src="images/fdist_ko.png" width="500px"></p>
</li>
</ul>
<blockquote>
<p><strong>Tip</strong>: To save a plot programmably, and not through the GUI, overwrite <code>pylab.show</code> with <code>pylab.savefig</code> before drawing the plot (<a href="http://stackoverflow.com/questions/27392390/how-do-i-send-nltk-plots-to-files">reference</a>):
<pre>
from matplotlib import pylab
pylab.show = lambda: pylab.savefig('some_filename.png')
</pre></p>
<p><strong>Troubleshooting</strong>: For those who see rectangles instead of letters in the saved plot file, include the following configurations before drawing the plot:
<pre>
from matplotlib import font_manager, rc
font_fname = 'c:/windows/fonts/gulim.ttc'     # A font of your choice
font_name = font_manager.FontProperties(fname=font_fname).get_name()
rc('font', family=font_name)
</pre></p>
<p>Some example fonts:</p>
<ul>
<li>Mac OS: <code>/Library/Fonts/AppleGothic.ttf</code></li>
</ul>
</blockquote>
</li>
<li>
<p>Count</p>
<ul>
<li>
<p>English</p>
<div class="highlight"><pre><span></span><span class="n">en</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s1">&#39;Emma&#39;</span><span class="p">)</span>        <span class="c1"># Counts occurrences</span>
</pre></div>


<p><pre class="result">
865
</pre></p>
</li>
<li>
<p>Korean</p>
<div class="highlight"><pre><span></span><span class="n">ko</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s1">&#39;초등학교&#39;</span><span class="p">)</span>   <span class="c1"># Counts occurrences</span>
</pre></div>


<p><pre class="result">
6
</pre></p>
</li>
</ul>
</li>
<li>
<p>Dispersion plot</p>
<ul>
<li>
<p>English</p>
<div class="highlight"><pre><span></span><span class="n">en</span><span class="o">.</span><span class="n">dispersion_plot</span><span class="p">([</span><span class="s1">&#39;Emma&#39;</span><span class="p">,</span> <span class="s1">&#39;Frank&#39;</span><span class="p">,</span> <span class="s1">&#39;Jane&#39;</span><span class="p">])</span>
</pre></div>


<p><img src="images/disp_en.png" width="500px"></p>
</li>
<li>
<p>Korean</p>
<div class="highlight"><pre><span></span><span class="n">ko</span><span class="o">.</span><span class="n">dispersion_plot</span><span class="p">([</span><span class="s1">&#39;육아휴직&#39;</span><span class="p">,</span> <span class="s1">&#39;초등학교&#39;</span><span class="p">,</span> <span class="s1">&#39;공무원&#39;</span><span class="p">])</span>
</pre></div>


<p><img src="images/disp_ko.png" width="500px"></p>
</li>
</ul>
</li>
<li>
<p>Concordance</p>
<ul>
<li>
<p>English</p>
<div class="highlight"><pre><span></span><span class="n">en</span><span class="o">.</span><span class="n">concordance</span><span class="p">(</span><span class="s1">&#39;Emma&#39;</span><span class="p">,</span> <span class="n">lines</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>


<p><pre class="result">
Displaying 5 of 865 matches:
                                     Emma by Jane Austen 1816 ] VOLUME I CHAPT
                                     Emma Woodhouse , handsome , clever , and
both daughters , but particularly of Emma . Between <em>them</em> it was more the int
 friend very mutually attached , and Emma doing just what she liked ; highly e
r own . The real evils , indeed , of Emma ' s situation were the power of havi
</pre></p>
</li>
<li>
<p>Korean (or, use <a href="http://konlpy.org/en/v0.4.3/api/konlpy/#konlpy.utils.concordance">konlpy.utils.concordance</a>)</p>
<div class="highlight"><pre><span></span><span class="n">ko</span><span class="o">.</span><span class="n">concordance</span><span class="p">(</span><span class="s1">&#39;초등학교&#39;</span><span class="p">)</span>
</pre></div>


<p><pre class="result">
Displaying 6 of 6 matches:
 ․ 김정훈 김학송 의원 ( 10 인 ) 제안 이유 및 주요 내용 초등학교 저학년 의 경우 에도 부모 의 따뜻한 사랑 과 보살핌 이 필요 한
 을 할 수 있는 자녀 의 나이 는 만 6 세 이하 로 되어 있어 초등학교 저학년 인 자녀 를 돌보기 위해서 는 해당 부모님 은 일자리 를
 다 . 제 63 조제 2 항제 4 호 중 “ 만 6 세 이하 의 초등학교 취학 전 자녀 를 ” 을 “ 만 8 세 이하 ( 취학 중인 경우
 전 자녀 를 ” 을 “ 만 8 세 이하 ( 취학 중인 경우 에는 초등학교 2 학년 이하 를 말한 다 ) 의 자녀 를 ” 로 한 다 . 부
 . ∼ 3 . ( 현행 과 같 음 ) 4 . 만 6 세 이하 의 초등학교 취 4 . 만 8 세 이하 ( 취학 중인 경우 학 전 자녀 를 양
세 이하 ( 취학 중인 경우 학 전 자녀 를 양육 하기 위하 에는 초등학교 2 학년 이하 를 여 필요하거 나 여자 공무원 이 말한 다 ) 의
</pre></p>
</li>
</ul>
</li>
<li>
<p>Find similar words</p>
<ul>
<li>
<p>English</p>
<div class="highlight"><pre><span></span><span class="n">en</span><span class="o">.</span><span class="n">similar</span><span class="p">(</span><span class="s1">&#39;Emma&#39;</span><span class="p">)</span>
<span class="n">en</span><span class="o">.</span><span class="n">similar</span><span class="p">(</span><span class="s1">&#39;Frank&#39;</span><span class="p">)</span>
</pre></div>


<p><pre class="result">
she it he i harriet you her jane him that me and all they them there herself was hartfield be
mr mrs emma harriet you it her she he him hartfield them jane that isabella all herself look i me
</pre></p>
</li>
<li>
<p>Korean</p>
<div class="highlight"><pre><span></span><span class="n">ko</span><span class="o">.</span><span class="n">similar</span><span class="p">(</span><span class="s1">&#39;자녀&#39;</span><span class="p">)</span>
<span class="n">ko</span><span class="o">.</span><span class="n">similar</span><span class="p">(</span><span class="s1">&#39;육아휴직&#39;</span><span class="p">)</span>
</pre></div>


<p><pre class="result">
논의
None
</pre></p>
</li>
</ul>
</li>
<li>
<p>Collocations</p>
<ul>
<li>
<p>English</p>
<div class="highlight"><pre><span></span><span class="n">en</span><span class="o">.</span><span class="n">collocations</span><span class="p">()</span>
</pre></div>


<p><pre class="result">
Frank Churchill; Miss Woodhouse; Miss Bates; Jane Fairfax; Miss
Fairfax; every thing; young man; every body; great deal; dare say;
John Knightley; Maple Grove; Miss Smith; Miss Taylor; Robert Martin;
Colonel Campbell; Box Hill; said Emma; Harriet Smith; William Larkins
</pre></p>
</li>
<li>
<p>Korean</p>
<div class="highlight"><pre><span></span><span class="n">en</span><span class="o">.</span><span class="n">collocations</span><span class="p">()</span>
</pre></div>


<p><pre class="result">
초등학교 저학년; 육아휴직 대상
</pre></p>
</li>
</ul>
</li>
</ol>
<p>For more information on <code>nltk.Text()</code>, see the <a href="http://www.nltk.org/_modules/nltk/text.html#Text">source code</a> or <a href="http://www.nltk.org/api/nltk.html#nltk.text.Text">API</a>.</p>
<h2>Tagging and chunking</h2>
<p>Until now, we used delimited text, namely <em>tokens</em>, to explore our sample document.
Now let's classify words into given classes, namely <em>part-of-speech tags</em>, and chunk text into larger pieces.</p>
<h3>1. POS tagging</h3>
<p>There are numerous ways of tagging a text.
Among them, the most frequently used, and developed way of tagging is arguably POS tagging.</p>
<p>Since one document is too long to observe a parsed structure,
lets use one short sentence for each language.</p>
<ul>
<li>
<p>English</p>
<div class="highlight"><pre><span></span><span class="n">tokens</span> <span class="o">=</span> <span class="s2">&quot;The little yellow dog barked at the Persian cat&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="n">tags_en</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">pos_tag</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</pre></div>


<p><pre class="result">
[('The', 'DT'),
 ('little', 'JJ'),
 ('yellow', 'NN'),
 ('dog', 'NN'),
 ('barked', 'VBD'),
 ('at', 'IN'),
 ('the', 'DT'),
 ('Persian', 'NNP'),
 ('cat', 'NN')]
</pre></p>
<ul>
<li>It is also possible to use the famous <a href="http://www.nltk.org/api/nltk.tag.html#module-nltk.tag.stanford">Stanford POS tagger with NLTK</a>, with <code>from nltk.tag.stanford import POSTagger</code></li>
</ul>
</li>
<li>
<p>Korean</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konlpy.tag</span> <span class="kn">import</span> <span class="n">Twitter</span><span class="p">;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">Twitter</span><span class="p">()</span>
<span class="n">tags_ko</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">pos</span><span class="p">(</span><span class="s2">&quot;작고 노란 강아지가 페르시안 고양이에게 짖었다&quot;</span><span class="p">)</span>
</pre></div>


<p><pre class="result">
[('작고', 'Noun'),
 ('노란', 'Adjective'),
 ('강아지', 'Noun'),
 ('가', 'Josa'),
 ('페르시안', 'Noun'),
 ('고양이', 'Noun'),
 ('에게', 'Josa'),
 ('짖었', 'Noun'),
 ('다', 'Josa')]
</pre></p>
</li>
</ul>
<h3>2. Noun phrase chunking</h3>
<p><a href="http://www.nltk.org/api/nltk.chunk.html#nltk.chunk.regexp.RegexpParser"><code>nltk.RegexpParser()</code></a> is a great way to start chunking.</p>
<ul>
<li>
<p>English</p>
<div class="highlight"><pre><span></span><span class="n">parser_en</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">RegexpParser</span><span class="p">(</span><span class="s2">&quot;NP: {&lt;DT&gt;?&lt;JJ&gt;?&lt;NN.*&gt;*}&quot;</span><span class="p">)</span>
<span class="n">chunks_en</span> <span class="o">=</span> <span class="n">parser_en</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">tags_en</span><span class="p">)</span>
<span class="n">chunks_en</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</pre></div>


<p><img src="images/tree_en.png" width="500px"></p>
</li>
<li>
<p>Korean</p>
<div class="highlight"><pre><span></span><span class="n">parser_ko</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">RegexpParser</span><span class="p">(</span><span class="s2">&quot;NP: {&lt;Adjective&gt;*&lt;Noun&gt;*}&quot;</span><span class="p">)</span>
<span class="n">chunks_ko</span> <span class="o">=</span> <span class="n">parser_ko</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">tags_ko</span><span class="p">)</span>
<span class="n">chunks_ko</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</pre></div>


<p><img src="images/tree_ko.png" width="700px"></p>
</li>
</ul>
<p>For more information on chunking, refer to <a href="http://www.nltk.org/book/ch07.html">Extracting Information from Text</a> for English, and <a href="http://konlpy.org/en/v0.4.3/examples/chunking/">Chunking</a> for Korean.</p>
<h2>Drawing a word cloud</h2>
<ol>
<li>
<p>제 1809890호 의안의 빈도분포(frequency distribution)를 다시 살펴보자.</p>
<div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">ko</span><span class="o">.</span><span class="n">vocab</span><span class="p">())</span>
</pre></div>


<p><pre class="result">
FreqDist({'.': 61, '의': 46, '육아휴직': 38, '을': 34, '(': 27, ',': 26, '이': 26, ')': 26, '에': 24, '자': 24, ...})
</pre></p>
</li>
<li>
<p>이 빈도분포의 data type과 attribute 목록을 확인해보자.</p>
<div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">ko</span><span class="o">.</span><span class="n">vocab</span><span class="p">())</span>
</pre></div>


<p><pre class="result">
nltk.probability.FreqDist
</pre></p>
<div class="highlight"><pre><span></span><span class="nb">dir</span><span class="p">(</span><span class="n">ko</span><span class="o">.</span><span class="n">vocab</span><span class="p">())</span>
</pre></div>


<p><pre class="result">
['B',
 'N',
 ...
 'items',
 ...
 'pop',
 'popitem',
 'pprint',
 'r_Nr',
 'setdefault',
 'subtract',
 'tabulate',
 'unicode_repr',
 'update',
 'values']
</pre></p>
</li>
<li>
<p><code>items()</code>를 사용하면 빈도분포의 item 전체를 set의 형태로 볼 수 있다. 이를 <code>data</code>라는 이름의 변수에 저장한 후, data type을 관찰하자.</p>
<div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">ko</span><span class="o">.</span><span class="n">vocab</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
</pre></div>


<p><pre class="result">
dict_items([('명', 5), ('예상된', 3), ('하나', 1), ('11', 2), ('팀', 2), ...])
<code>&lt;class 'dict_items'&gt;</code>
</pre></p>
</li>
<li>
<p>이 set을 이제 <code>words.csv</code>라는 파일에 저장해보자. 데이터 header는 word,freq로 하면 된다.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">csv</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;words.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;word,freq</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">writer</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">writerows</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>


</li>
<li>
<p>다음으로 아래의 코드를 복사하여 <code>words.csv</code>가 있는 폴더 내에 <code>index.html</code>라는 이름으로 저장하자.<br>
    <script src="https://gist.github.com/e9t/e462f7462e9d83b03464.js?file=index.html" type="text/javascript"></script></p>
</li>
<li>
<p>위와 같은 폴더에서 아래를 실행하자.</p>
<div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">http</span><span class="o">.</span><span class="n">server</span> <span class="mi">8888</span>      <span class="c1"># for Python2, `python -m SimpleHTTPServer`</span>
</pre></div>


</li>
<li>
<p>마지막으로, 모던 브라우저(ex: 크롬)의 주소창에 <code>http://localhost:8888</code>를 입력하면 우리의 워드클라우드가 떠있을 것이다! (이미지를 클릭하면 interative 페이지로 이동합니다.)</p>
<p><a href="http://bl.ocks.org/e9t/raw/e462f7462e9d83b03464/"><img src="images/wordcloud.png" width="400px"></a></p>
</li>
<li>
<p>더 실험해보고 싶은 경우:</p>
<ol>
<li>위의 워드클라우드는 각종 특수문자, 조사 등도 포함되어 정보 전달력이 떨어진다. 워드클라우드에 명사만 표현되게 할 수 있을까?</li>
<li>다른 임의의 문서로도 워드클라우드를 그릴 수 있나? (ex: 내 데이터마이닝 프로젝트 제안서) 해당 문서를 파이썬으로 읽고, 문서에서 높은 빈도로 등장한 단어를 추출 후, 워드클라우드로 그려보자.</li>
<li>여러 개의 문서에 대한 워드클라우드를 그릴 수도 있나? 파이썬으로 여러 개의 문서를 한꺼번에 읽어들인 후, 높은 빈도로 등장한 단어를 추출해서 워드클라우드로 그려보자.</li>
</ol>
</li>
</ol>

    </div>
    <div class="footnote">
        <div class="social-links pull-right">
            <div id="facebook-like">
                <div id="fb-root"></div>
                <script>(function(d, s, id) {
                  var js, fjs = d.getElementsByTagName(s)[0];
                  if (d.getElementById(id)) return;
                  js = d.createElement(s); js.id = id;
                  js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=357567114353849";
                  fjs.parentNode.insertBefore(js, fjs);
                }(document, 'script', 'facebook-jssdk'));</script>
                <div class="fb-like" data-href="//www.lucypark.kr/courses/2015-dm/text-mining.html" data-send="false" data-layout="button_count" data-width="450" data-show-faces="false"></div>
            </div>
            <div id="twitter-tweet">
                <a href="https://twitter.com/share" class="twitter-share-button" data-lang="en"></a>
                <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="https://platform.twitter.com/widgets.js";fjs.parentNode.    insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
            </div>
        </div>
        <p>
            Author:
            <span itemprop="author" itemscope itemtype="http://schema.org/Person">
                <a href="http://dm.snu.ac.kr/~epark"><span itemprop="name">Lucy Park</span></a>
            </span>
        </p>
        <p>
            Category:
            <span itemprop="articleSection">
                <a href="//www.lucypark.kr/courses/category/2015-dm.html" rel="category">2015-dm</a>
            </span>
        </p>
        <p>
            Tags:
            <span itemprop="keywords">
                <a href="//www.lucypark.kr/courses/tag/text.html" rel="tag">text</a>
            </span>
            <span itemprop="keywords">
                <a href="//www.lucypark.kr/courses/tag/lectures.html" rel="tag">lectures</a>
            </span>
        </p>
    </div>
</div>
		</div>
	</div> 	<!-- <hr> -->
</div> <!-- /container -->
<footer class="aw-footer bg-danger">
	<div class="container"> <!-- footer -->
		<div class="center-block aw-bottom">
            Built by <a href="http://dm.snu.ac.kr/~epark">Lucy Park</a>.<br>
            Code licensed under <a href="http://www.apache.org/licenses/LICENSE-2.0">Apache License v2.0</a>, document under <a href="http://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>.<br>
 The code for this site is located at <a href="http://github.com/e9t/courses">GitHub</a>.             <span class="pull-right margin-top-30">
                <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a>
                <a href="//www.lucypark.kr/courses/feeds/all.atom.xml" type="application/atom+xml"><i class="fa fa-rss "></i> atom</a>
            </span>
		</div>
	</div>
</footer>
<div class="container">
	<div class="row">
	</div>
</div>
<!-- JavaScript -->
<script src="//code.jquery.com/jquery-2.1.1.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
<script type="text/javascript">
jQuery(document).ready(function($) {
	$("div.collapseheader").click(function () {
		$header = $(this).children("span").first();
		$codearea = $(this).children(".input_area");
		$codearea.slideToggle(500, function () {
			$header.text(function () {
				return $codearea.is(":visible") ? "Collapse Code" : "Expand Code";
			});
		});
	});
});

// add 'active' class to current menu
$(function(){
  if (document.location.hostname == "localhost") {
    var idx = 1;
    var activePage = location.pathname.split("/")[idx];
  } else {
    var idx = 4;
    var activePage = location.href.split("/")[idx];
  }
  $('.nav li a').each(function() {
    var currentPage = $(this).attr('href').split("/")[idx];
    if (activePage == currentPage) {
      $(this).parent().addClass('active');
    }
  });
});
</script>
<script>
    function hyphenate(str) {
        return str.toLowerCase().replace(/[?!:'"\[\]()%.,]/gi, '').replace(/\s/g, '-');
    }

    String.prototype.repeat = function(num) { return new Array(num + 1).join(this); }

    // create toc
    var t = '';
    var concat = '';
    var headers = $('.article-body :header');
    headers.each(function() {
        var hyphenated = hyphenate($(this).text());
            $(this).attr('id', hyphenated);
        }
    );
    for (var i=0; i<headers.length; i++) {
        depth = parseInt(headers[i].tagName.substr(-1));
        if (depth < 4) {
            t = headers[i].textContent;
            concat += '&nbsp;&nbsp;&nbsp;&nbsp;'.repeat(parseInt(depth)-2) + '- <a href="#' + hyphenate(t) + '">' + t + '</a><br>';
        }
    }
    $(".article-toc p").append(concat);

    // scroll animation
    $(document).ready(function(){
        $('a[href^="#"]').on('click',function (e) {
            e.preventDefault();

            var target = this.hash;
            var $target = $(target);

            $('html, body').stop().animate({
                'scrollTop': $target.offset().top
            }, 300, 'swing', function () {
                window.location.hash = target;
            });
        });
    });
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$', '$$'], ["\\[", "\\]"]],
    }});
</script>
<script type="text/javascript"
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-4510606-3');
ga('require', 'displayfeatures');
ga('require', 'linkid', 'linkid.js');
ga('send', 'pageview');

</script>
</body>
</html>